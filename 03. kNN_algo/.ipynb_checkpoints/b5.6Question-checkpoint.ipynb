{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1783c145",
   "metadata": {},
   "source": [
    "- This is a very important and very much common concept/question.\n",
    "\n",
    "#### **Ques.** What happens if we increase the value  k and when we decrease the value of k in k-NN algo?\n",
    "**Ans.** \n",
    "- If we take a small value of k, **it may lead to overfitting problem.**\n",
    "- If we take a very high value of k, it will take a lot time for testing. And accuracy will also keep on decreasing as we increase k to very high level. \n",
    "- So w eneed some intermediate value of k. Genreally if we have 'n' number of data points in 'X' array, then data scientists use value of k near to $\\sqrt{n}$.  We need to use Cross-validation to find a suitable value for k. \n",
    "\n",
    "k = $\\sqrt{n}$\n",
    "\n",
    "<hr>\n",
    "- Also small value of k increases the noise. So if data is noisy, then value of k must be increased.\n",
    "- And increasing value of k makes curve smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498707f4",
   "metadata": {},
   "source": [
    "### Pros and Cons of KNN:\n",
    "##### Pros:\n",
    "- As you can already tell from the previous section, one of the most attractive features of the K-nearest neighbor algorithm is that it is simple to understand and easy to implement. **With zero to little training time**, it can be a useful tool for off-the-bat analysis of some data set you are planning to run more complex algorithms on.\n",
    "\n",
    "##### Cons:\n",
    "- One of the obvious drawbacks of the KNN algorithm is **the computationally expensive testing phase which is impractical in industry settings**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa1c2d",
   "metadata": {},
   "source": [
    "**Generally value of k must be odd if number of classes are even. So that probability would not end up as 50-50 in end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef1111",
   "metadata": {},
   "source": [
    "#### Ques. About Distance formula in knn algo.\n",
    "**Ans.**\n",
    "\n",
    "If we have n features, then distance for that n-dimansion is difference between all the corresponding features, then squaring them and then sum of them all and then root of that sum.\n",
    "            \n",
    "        dist(x,z)=(∑i=1 tot d |x[i]−z[i]|**p)**1/p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
