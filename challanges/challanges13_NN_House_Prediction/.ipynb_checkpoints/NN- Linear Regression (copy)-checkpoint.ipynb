{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d1fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 12:49:59.179307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-20 12:49:59.179366: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0f419",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f102f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Train/Train_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90addd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67c1d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35caea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1100 non-null   int64  \n",
      " 1   MSSubClass     1100 non-null   int64  \n",
      " 2   MSZoning       1100 non-null   object \n",
      " 3   LotFrontage    908 non-null    float64\n",
      " 4   LotArea        1100 non-null   int64  \n",
      " 5   Street         1100 non-null   object \n",
      " 6   Alley          69 non-null     object \n",
      " 7   LotShape       1100 non-null   object \n",
      " 8   LandContour    1100 non-null   object \n",
      " 9   Utilities      1100 non-null   object \n",
      " 10  LotConfig      1100 non-null   object \n",
      " 11  LandSlope      1100 non-null   object \n",
      " 12  Neighborhood   1100 non-null   object \n",
      " 13  Condition1     1100 non-null   object \n",
      " 14  Condition2     1100 non-null   object \n",
      " 15  BldgType       1100 non-null   object \n",
      " 16  HouseStyle     1100 non-null   object \n",
      " 17  OverallQual    1100 non-null   int64  \n",
      " 18  OverallCond    1100 non-null   int64  \n",
      " 19  YearBuilt      1100 non-null   int64  \n",
      " 20  YearRemodAdd   1100 non-null   int64  \n",
      " 21  RoofStyle      1100 non-null   object \n",
      " 22  RoofMatl       1100 non-null   object \n",
      " 23  Exterior1st    1100 non-null   object \n",
      " 24  Exterior2nd    1100 non-null   object \n",
      " 25  MasVnrType     1094 non-null   object \n",
      " 26  MasVnrArea     1094 non-null   float64\n",
      " 27  ExterQual      1100 non-null   object \n",
      " 28  ExterCond      1100 non-null   object \n",
      " 29  Foundation     1100 non-null   object \n",
      " 30  BsmtQual       1069 non-null   object \n",
      " 31  BsmtCond       1069 non-null   object \n",
      " 32  BsmtExposure   1068 non-null   object \n",
      " 33  BsmtFinType1   1069 non-null   object \n",
      " 34  BsmtFinSF1     1100 non-null   int64  \n",
      " 35  BsmtFinType2   1068 non-null   object \n",
      " 36  BsmtFinSF2     1100 non-null   int64  \n",
      " 37  BsmtUnfSF      1100 non-null   int64  \n",
      " 38  TotalBsmtSF    1100 non-null   int64  \n",
      " 39  Heating        1100 non-null   object \n",
      " 40  HeatingQC      1100 non-null   object \n",
      " 41  CentralAir     1100 non-null   object \n",
      " 42  Electrical     1100 non-null   object \n",
      " 43  1stFlrSF       1100 non-null   int64  \n",
      " 44  2ndFlrSF       1100 non-null   int64  \n",
      " 45  LowQualFinSF   1100 non-null   int64  \n",
      " 46  GrLivArea      1100 non-null   int64  \n",
      " 47  BsmtFullBath   1100 non-null   int64  \n",
      " 48  BsmtHalfBath   1100 non-null   int64  \n",
      " 49  FullBath       1100 non-null   int64  \n",
      " 50  HalfBath       1100 non-null   int64  \n",
      " 51  BedroomAbvGr   1100 non-null   int64  \n",
      " 52  KitchenAbvGr   1100 non-null   int64  \n",
      " 53  KitchenQual    1100 non-null   object \n",
      " 54  TotRmsAbvGrd   1100 non-null   int64  \n",
      " 55  Functional     1100 non-null   object \n",
      " 56  Fireplaces     1100 non-null   int64  \n",
      " 57  FireplaceQu    576 non-null    object \n",
      " 58  GarageType     1039 non-null   object \n",
      " 59  GarageYrBlt    1039 non-null   float64\n",
      " 60  GarageFinish   1039 non-null   object \n",
      " 61  GarageCars     1100 non-null   int64  \n",
      " 62  GarageArea     1100 non-null   int64  \n",
      " 63  GarageQual     1039 non-null   object \n",
      " 64  GarageCond     1039 non-null   object \n",
      " 65  PavedDrive     1100 non-null   object \n",
      " 66  WoodDeckSF     1100 non-null   int64  \n",
      " 67  OpenPorchSF    1100 non-null   int64  \n",
      " 68  EnclosedPorch  1100 non-null   int64  \n",
      " 69  3SsnPorch      1100 non-null   int64  \n",
      " 70  ScreenPorch    1100 non-null   int64  \n",
      " 71  PoolArea       1100 non-null   int64  \n",
      " 72  PoolQC         2 non-null      object \n",
      " 73  Fence          208 non-null    object \n",
      " 74  MiscFeature    46 non-null     object \n",
      " 75  MiscVal        1100 non-null   int64  \n",
      " 76  MoSold         1100 non-null   int64  \n",
      " 77  YrSold         1100 non-null   int64  \n",
      " 78  SaleType       1100 non-null   object \n",
      " 79  SaleCondition  1100 non-null   object \n",
      " 80  SalePrice      1100 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 696.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e2bc4",
   "metadata": {},
   "source": [
    "- Let us remove some useless columns. **The detailed description of the features is provided in a text file in train folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c8f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9317</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>176432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>70</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6882</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3696</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11880</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1095          20       RL         78.0     9317   Pave      IR1         Lvl   \n",
       "1096          70       RM         60.0     6882   Pave      Reg         Lvl   \n",
       "1097         120       RL          NaN     3696   Pave      Reg         Lvl   \n",
       "1098          50       RM         50.0     6000   Pave      Reg         Lvl   \n",
       "1099          20       RL         82.0    11880   Pave      IR1         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1       AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2       AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3       AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4       AllPub       FR2       Gtl  ...             0         0           0   \n",
       "...        ...       ...       ...  ...           ...       ...         ...   \n",
       "1095    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1096    AllPub    Inside       Gtl  ...           115         0           0   \n",
       "1097    AllPub    Inside       Gtl  ...           137         0           0   \n",
       "1098    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1099    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0           0       0       2    2008        WD         Normal    208500  \n",
       "1           0       0       5    2007        WD         Normal    181500  \n",
       "2           0       0       9    2008        WD         Normal    223500  \n",
       "3           0       0       2    2006        WD        Abnorml    140000  \n",
       "4           0       0      12    2008        WD         Normal    250000  \n",
       "...       ...     ...     ...     ...       ...            ...       ...  \n",
       "1095        0       0       3    2007        WD         Normal    176432  \n",
       "1096        0       0       3    2007        WD         Normal    127000  \n",
       "1097        0       0      10    2007        WD         Normal    170000  \n",
       "1098        0       0       7    2009        WD         Normal    128000  \n",
       "1099        0       0       4    2009       COD        Abnorml    157000  \n",
       "\n",
       "[1100 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(labels=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd38292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8f47fe",
   "metadata": {},
   "source": [
    "#### Convert all string columns to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e762dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652c7e1",
   "metadata": {},
   "source": [
    "- We can iterate over columns and will apply le.fit_transform() if type is str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51126042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[:5]:\n",
    "    print(type(df[i].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f653c",
   "metadata": {},
   "source": [
    "- **Here some columns may have different types of values in them. So we need to convert every column to `astype('str')`. LabelEncoder gives error otherwise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249582f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for i in df.columns:\n",
    "    if type(df[i].values[0])==str:  # check if 1st value of this column is string\n",
    "        df[i] = le.fit_transform(df[i].astype('str'))\n",
    "        df[i] = df[i].fillna(df[i].mode())\n",
    "    else:\n",
    "        df[i] = df[i].fillna(df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde3ba66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
       "0          60         3         65.0     8450       1         3            3   \n",
       "1          20         3         80.0     9600       1         3            3   \n",
       "2          60         3         68.0    11250       1         0            3   \n",
       "3          70         3         60.0     9550       1         0            3   \n",
       "4          60         3         84.0    14260       1         0            3   \n",
       "\n",
       "   Utilities  LotConfig  LandSlope  ...  EnclosedPorch  3SsnPorch  \\\n",
       "0          0          4          0  ...              0          0   \n",
       "1          0          2          0  ...              0          0   \n",
       "2          0          4          0  ...              0          0   \n",
       "3          0          0          0  ...            272          0   \n",
       "4          0          2          0  ...              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \\\n",
       "0            0         0        0       2    2008         8              4   \n",
       "1            0         0        0       5    2007         8              4   \n",
       "2            0         0        0       9    2008         8              4   \n",
       "3            0         0        0       2    2006         8              0   \n",
       "4            0         0        0      12    2008         8              4   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8bb47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 75 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1100 non-null   int64  \n",
      " 1   MSZoning       1100 non-null   int64  \n",
      " 2   LotFrontage    1100 non-null   float64\n",
      " 3   LotArea        1100 non-null   int64  \n",
      " 4   Street         1100 non-null   int64  \n",
      " 5   LotShape       1100 non-null   int64  \n",
      " 6   LandContour    1100 non-null   int64  \n",
      " 7   Utilities      1100 non-null   int64  \n",
      " 8   LotConfig      1100 non-null   int64  \n",
      " 9   LandSlope      1100 non-null   int64  \n",
      " 10  Neighborhood   1100 non-null   int64  \n",
      " 11  Condition1     1100 non-null   int64  \n",
      " 12  Condition2     1100 non-null   int64  \n",
      " 13  BldgType       1100 non-null   int64  \n",
      " 14  HouseStyle     1100 non-null   int64  \n",
      " 15  OverallQual    1100 non-null   int64  \n",
      " 16  OverallCond    1100 non-null   int64  \n",
      " 17  YearBuilt      1100 non-null   int64  \n",
      " 18  YearRemodAdd   1100 non-null   int64  \n",
      " 19  RoofStyle      1100 non-null   int64  \n",
      " 20  RoofMatl       1100 non-null   int64  \n",
      " 21  Exterior1st    1100 non-null   int64  \n",
      " 22  Exterior2nd    1100 non-null   int64  \n",
      " 23  MasVnrType     1100 non-null   int64  \n",
      " 24  MasVnrArea     1100 non-null   float64\n",
      " 25  ExterQual      1100 non-null   int64  \n",
      " 26  ExterCond      1100 non-null   int64  \n",
      " 27  Foundation     1100 non-null   int64  \n",
      " 28  BsmtQual       1100 non-null   int64  \n",
      " 29  BsmtCond       1100 non-null   int64  \n",
      " 30  BsmtExposure   1100 non-null   int64  \n",
      " 31  BsmtFinType1   1100 non-null   int64  \n",
      " 32  BsmtFinSF1     1100 non-null   int64  \n",
      " 33  BsmtFinType2   1100 non-null   int64  \n",
      " 34  BsmtFinSF2     1100 non-null   int64  \n",
      " 35  BsmtUnfSF      1100 non-null   int64  \n",
      " 36  TotalBsmtSF    1100 non-null   int64  \n",
      " 37  Heating        1100 non-null   int64  \n",
      " 38  HeatingQC      1100 non-null   int64  \n",
      " 39  CentralAir     1100 non-null   int64  \n",
      " 40  Electrical     1100 non-null   int64  \n",
      " 41  1stFlrSF       1100 non-null   int64  \n",
      " 42  2ndFlrSF       1100 non-null   int64  \n",
      " 43  LowQualFinSF   1100 non-null   int64  \n",
      " 44  GrLivArea      1100 non-null   int64  \n",
      " 45  BsmtFullBath   1100 non-null   int64  \n",
      " 46  BsmtHalfBath   1100 non-null   int64  \n",
      " 47  FullBath       1100 non-null   int64  \n",
      " 48  HalfBath       1100 non-null   int64  \n",
      " 49  BedroomAbvGr   1100 non-null   int64  \n",
      " 50  KitchenAbvGr   1100 non-null   int64  \n",
      " 51  KitchenQual    1100 non-null   int64  \n",
      " 52  TotRmsAbvGrd   1100 non-null   int64  \n",
      " 53  Functional     1100 non-null   int64  \n",
      " 54  Fireplaces     1100 non-null   int64  \n",
      " 55  GarageType     1100 non-null   int64  \n",
      " 56  GarageYrBlt    1100 non-null   float64\n",
      " 57  GarageFinish   1100 non-null   int64  \n",
      " 58  GarageCars     1100 non-null   int64  \n",
      " 59  GarageArea     1100 non-null   int64  \n",
      " 60  GarageQual     1100 non-null   int64  \n",
      " 61  GarageCond     1100 non-null   int64  \n",
      " 62  PavedDrive     1100 non-null   int64  \n",
      " 63  WoodDeckSF     1100 non-null   int64  \n",
      " 64  OpenPorchSF    1100 non-null   int64  \n",
      " 65  EnclosedPorch  1100 non-null   int64  \n",
      " 66  3SsnPorch      1100 non-null   int64  \n",
      " 67  ScreenPorch    1100 non-null   int64  \n",
      " 68  PoolArea       1100 non-null   int64  \n",
      " 69  MiscVal        1100 non-null   int64  \n",
      " 70  MoSold         1100 non-null   int64  \n",
      " 71  YrSold         1100 non-null   int64  \n",
      " 72  SaleType       1100 non-null   int64  \n",
      " 73  SaleCondition  1100 non-null   int64  \n",
      " 74  SalePrice      1100 non-null   int64  \n",
      "dtypes: float64(3), int64(72)\n",
      "memory usage: 644.7 KB\n"
     ]
    }
   ],
   "source": [
    "## now check data after some data preprocessing\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed4fdb",
   "metadata": {},
   "source": [
    "- There are some 'object'. This was giving error while training. So we need to convert these to common dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811ff8c",
   "metadata": {},
   "source": [
    "#### Divide df in X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "183ebf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100, 74), (1100,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df.values[:,:-1]\n",
    "Y_train = df.values[:,-1]\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b7e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype('float32')\n",
    "Y_train = np.asarray(Y_train).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1947ea",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53c8e378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 74)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189a69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7de1ad1",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4a07fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85289b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 12:50:41.510046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-20 12:50:41.510098: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-20 12:50:41.510124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (harsh): /proc/driver/nvidia/version does not exist\n",
      "2022-03-20 12:50:41.512586: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(150,activation='relu', input_shape=((74,))))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(70,activation='relu'))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1)) # by default linear_value z is activation of function if not passed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b64b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f035bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc987de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizer_v2.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f65b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile model\n",
    "# opt = Adam(learning_rate=0.1)\n",
    "# model.compile(optimizer=opt, loss='log-mse')\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "## we can't calculate accuracy in regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f50db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2/2 [==============================] - 1s 183ms/step - loss: 40108961792.0000 - val_loss: 35467046912.0000\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 40108683264.0000 - val_loss: 35466571776.0000\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 40108068864.0000 - val_loss: 35465654272.0000\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 40106893312.0000 - val_loss: 35463872512.0000\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 40104599552.0000 - val_loss: 35460907008.0000\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 40100847616.0000 - val_loss: 35456335872.0000\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 40095145984.0000 - val_loss: 35449643008.0000\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 40086802432.0000 - val_loss: 35440234496.0000\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 40075177984.0000 - val_loss: 35427500032.0000\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 40058990592.0000 - val_loss: 35409965056.0000\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 40036909056.0000 - val_loss: 35386945536.0000\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 40008282112.0000 - val_loss: 35357917184.0000\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 39971774464.0000 - val_loss: 35320991744.0000\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 39925542912.0000 - val_loss: 35275096064.0000\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 39867437056.0000 - val_loss: 35217805312.0000\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 39795871744.0000 - val_loss: 35149062144.0000\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 39709433856.0000 - val_loss: 35066224640.0000\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 39605186560.0000 - val_loss: 34967322624.0000\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 39481909248.0000 - val_loss: 34852392960.0000\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 39338147840.0000 - val_loss: 34718863360.0000\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 39169712128.0000 - val_loss: 34559893504.0000\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 38971076608.0000 - val_loss: 34377334784.0000\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 38743040000.0000 - val_loss: 34169184256.0000\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 38481334272.0000 - val_loss: 33929635840.0000\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 38180474880.0000 - val_loss: 33655693312.0000\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 37838516224.0000 - val_loss: 33348007936.0000\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 37449080832.0000 - val_loss: 32996136960.0000\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 37009805312.0000 - val_loss: 32604991488.0000\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 36520714240.0000 - val_loss: 32169869312.0000\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 35981881344.0000 - val_loss: 31695339520.0000\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 35385184256.0000 - val_loss: 31163838464.0000\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 34720387072.0000 - val_loss: 30576646144.0000\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 33996820480.0000 - val_loss: 29948276736.0000\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 33216063488.0000 - val_loss: 29265303552.0000\n",
      "Epoch 35/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 32368685056.0000 - val_loss: 28525117440.0000\n",
      "Epoch 36/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 31452819456.0000 - val_loss: 27729131520.0000\n",
      "Epoch 37/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 30465052672.0000 - val_loss: 26868897792.0000\n",
      "Epoch 38/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 29404782592.0000 - val_loss: 25951635456.0000\n",
      "Epoch 39/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 28290551808.0000 - val_loss: 25001111552.0000\n",
      "Epoch 40/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 27120394240.0000 - val_loss: 23991349248.0000\n",
      "Epoch 41/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 25886328832.0000 - val_loss: 22931197952.0000\n",
      "Epoch 42/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 24603971584.0000 - val_loss: 21837948928.0000\n",
      "Epoch 43/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 23285256192.0000 - val_loss: 20714446848.0000\n",
      "Epoch 44/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 21936879616.0000 - val_loss: 19570882560.0000\n",
      "Epoch 45/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 20565886976.0000 - val_loss: 18401019904.0000\n",
      "Epoch 46/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 19180783616.0000 - val_loss: 17230051328.0000\n",
      "Epoch 47/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 17811773440.0000 - val_loss: 16078726144.0000\n",
      "Epoch 48/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 16461449216.0000 - val_loss: 14932692992.0000\n",
      "Epoch 49/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 15156312064.0000 - val_loss: 13848274944.0000\n",
      "Epoch 50/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 13911436288.0000 - val_loss: 12792015872.0000\n",
      "Epoch 51/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 12722566144.0000 - val_loss: 11780415488.0000\n",
      "Epoch 52/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 11620779008.0000 - val_loss: 10873748480.0000\n",
      "Epoch 53/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10646156288.0000 - val_loss: 10046764032.0000\n",
      "Epoch 54/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9787823104.0000 - val_loss: 9323194368.0000\n",
      "Epoch 55/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 9048163328.0000 - val_loss: 8679782400.0000\n",
      "Epoch 56/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 8416090624.0000 - val_loss: 8122924032.0000\n",
      "Epoch 57/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 7895915008.0000 - val_loss: 7658351616.0000\n",
      "Epoch 58/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7498808320.0000 - val_loss: 7310897152.0000\n",
      "Epoch 59/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 7181461504.0000 - val_loss: 7001836544.0000\n",
      "Epoch 60/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6912734208.0000 - val_loss: 6721077248.0000\n",
      "Epoch 61/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6679910400.0000 - val_loss: 6482137600.0000\n",
      "Epoch 62/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6477008896.0000 - val_loss: 6275039744.0000\n",
      "Epoch 63/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6300974080.0000 - val_loss: 6103630848.0000\n",
      "Epoch 64/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6130593792.0000 - val_loss: 5938363392.0000\n",
      "Epoch 65/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5956763648.0000 - val_loss: 5747124224.0000\n",
      "Epoch 66/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5791264768.0000 - val_loss: 5594456576.0000\n",
      "Epoch 67/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5624661504.0000 - val_loss: 5428273664.0000\n",
      "Epoch 68/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 5466793472.0000 - val_loss: 5277785600.0000\n",
      "Epoch 69/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 37ms/step - loss: 5303304192.0000 - val_loss: 5110006272.0000\n",
      "Epoch 70/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 5150514688.0000 - val_loss: 4971011584.0000\n",
      "Epoch 71/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4995864576.0000 - val_loss: 4806612992.0000\n",
      "Epoch 72/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4853895168.0000 - val_loss: 4642759680.0000\n",
      "Epoch 73/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4711064064.0000 - val_loss: 4560872448.0000\n",
      "Epoch 74/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4571328000.0000 - val_loss: 4364640768.0000\n",
      "Epoch 75/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4444574720.0000 - val_loss: 4323844096.0000\n",
      "Epoch 76/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4309285888.0000 - val_loss: 4170969600.0000\n",
      "Epoch 77/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4189490176.0000 - val_loss: 3997358592.0000\n",
      "Epoch 78/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 4079812352.0000 - val_loss: 3887131904.0000\n",
      "Epoch 79/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3952350464.0000 - val_loss: 3817013760.0000\n",
      "Epoch 80/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3843946752.0000 - val_loss: 3744333312.0000\n",
      "Epoch 81/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3737159424.0000 - val_loss: 3621222912.0000\n",
      "Epoch 82/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3631722752.0000 - val_loss: 3492300544.0000\n",
      "Epoch 83/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3533550336.0000 - val_loss: 3449449472.0000\n",
      "Epoch 84/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3439438336.0000 - val_loss: 3275773440.0000\n",
      "Epoch 85/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3345492736.0000 - val_loss: 3293323520.0000\n",
      "Epoch 86/2000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3267297792.0000 - val_loss: 3191756800.0000\n",
      "Epoch 87/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3167478784.0000 - val_loss: 3018446080.0000\n",
      "Epoch 88/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3089612032.0000 - val_loss: 2971788800.0000\n",
      "Epoch 89/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3042001664.0000 - val_loss: 2857185792.0000\n",
      "Epoch 90/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2931655936.0000 - val_loss: 2859610880.0000\n",
      "Epoch 91/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2853091072.0000 - val_loss: 2720816896.0000\n",
      "Epoch 92/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2803012608.0000 - val_loss: 2653747968.0000\n",
      "Epoch 93/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2704001280.0000 - val_loss: 2655420416.0000\n",
      "Epoch 94/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2629189376.0000 - val_loss: 2522582784.0000\n",
      "Epoch 95/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2571741952.0000 - val_loss: 2459916288.0000\n",
      "Epoch 96/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2504932608.0000 - val_loss: 2396371968.0000\n",
      "Epoch 97/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2429367296.0000 - val_loss: 2428293888.0000\n",
      "Epoch 98/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2368460288.0000 - val_loss: 2285701632.0000\n",
      "Epoch 99/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2324751104.0000 - val_loss: 2208726272.0000\n",
      "Epoch 100/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2249942016.0000 - val_loss: 2203697920.0000\n",
      "Epoch 101/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2179728384.0000 - val_loss: 2110830464.0000\n",
      "Epoch 102/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2122777728.0000 - val_loss: 2108236800.0000\n",
      "Epoch 103/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2066856192.0000 - val_loss: 1998912256.0000\n",
      "Epoch 104/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2025827712.0000 - val_loss: 1959865216.0000\n",
      "Epoch 105/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1958753920.0000 - val_loss: 1922467584.0000\n",
      "Epoch 106/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1911275776.0000 - val_loss: 1860312704.0000\n",
      "Epoch 107/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1857831552.0000 - val_loss: 1855156864.0000\n",
      "Epoch 108/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1815140480.0000 - val_loss: 1827092096.0000\n",
      "Epoch 109/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1757672704.0000 - val_loss: 1738092288.0000\n",
      "Epoch 110/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1712142720.0000 - val_loss: 1709019392.0000\n",
      "Epoch 111/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1669254656.0000 - val_loss: 1655627136.0000\n",
      "Epoch 112/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1626887168.0000 - val_loss: 1640375936.0000\n",
      "Epoch 113/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1601053952.0000 - val_loss: 1664730880.0000\n",
      "Epoch 114/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1559834368.0000 - val_loss: 1558698496.0000\n",
      "Epoch 115/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1536830848.0000 - val_loss: 1616766592.0000\n",
      "Epoch 116/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1524290816.0000 - val_loss: 1524054016.0000\n",
      "Epoch 117/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1443555456.0000 - val_loss: 1478813568.0000\n",
      "Epoch 118/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1413033728.0000 - val_loss: 1448463104.0000\n",
      "Epoch 119/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1385408640.0000 - val_loss: 1423785856.0000\n",
      "Epoch 120/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1374260096.0000 - val_loss: 1408225408.0000\n",
      "Epoch 121/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1351537408.0000 - val_loss: 1377451648.0000\n",
      "Epoch 122/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1298458752.0000 - val_loss: 1354302208.0000\n",
      "Epoch 123/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1276430720.0000 - val_loss: 1371152512.0000\n",
      "Epoch 124/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1253596032.0000 - val_loss: 1313283712.0000\n",
      "Epoch 125/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1216867328.0000 - val_loss: 1306895616.0000\n",
      "Epoch 126/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1216666752.0000 - val_loss: 1305944192.0000\n",
      "Epoch 127/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1194158848.0000 - val_loss: 1271684352.0000\n",
      "Epoch 128/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1150635008.0000 - val_loss: 1253164032.0000\n",
      "Epoch 129/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1139796608.0000 - val_loss: 1238046848.0000\n",
      "Epoch 130/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1108785664.0000 - val_loss: 1233787904.0000\n",
      "Epoch 131/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1091352960.0000 - val_loss: 1206703232.0000\n",
      "Epoch 132/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1071909184.0000 - val_loss: 1193857152.0000\n",
      "Epoch 133/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1057908800.0000 - val_loss: 1188756736.0000\n",
      "Epoch 134/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1041442112.0000 - val_loss: 1170183680.0000\n",
      "Epoch 135/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1037314176.0000 - val_loss: 1184918400.0000\n",
      "Epoch 136/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1052627456.0000 - val_loss: 1155891456.0000\n",
      "Epoch 137/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1001908800.0000 - val_loss: 1143133312.0000\n",
      "Epoch 138/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 31ms/step - loss: 974587200.0000 - val_loss: 1129336192.0000\n",
      "Epoch 139/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 955177088.0000 - val_loss: 1118925568.0000\n",
      "Epoch 140/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 946484288.0000 - val_loss: 1125004672.0000\n",
      "Epoch 141/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 938888576.0000 - val_loss: 1105221760.0000\n",
      "Epoch 142/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 912975616.0000 - val_loss: 1093079296.0000\n",
      "Epoch 143/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 908749504.0000 - val_loss: 1110546048.0000\n",
      "Epoch 144/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 929093120.0000 - val_loss: 1089010560.0000\n",
      "Epoch 145/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 894602944.0000 - val_loss: 1077952768.0000\n",
      "Epoch 146/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 865226624.0000 - val_loss: 1067271104.0000\n",
      "Epoch 147/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 850750464.0000 - val_loss: 1061349888.0000\n",
      "Epoch 148/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 838571392.0000 - val_loss: 1052326592.0000\n",
      "Epoch 149/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 845934208.0000 - val_loss: 1100741120.0000\n",
      "Epoch 150/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 856792640.0000 - val_loss: 1042714624.0000\n",
      "Epoch 151/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 806489152.0000 - val_loss: 1036801408.0000\n",
      "Epoch 152/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 796543680.0000 - val_loss: 1031992512.0000\n",
      "Epoch 153/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 796567168.0000 - val_loss: 1036154688.0000\n",
      "Epoch 154/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 790238400.0000 - val_loss: 1028068416.0000\n",
      "Epoch 155/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 772718784.0000 - val_loss: 1018658048.0000\n",
      "Epoch 156/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 757815552.0000 - val_loss: 1012260032.0000\n",
      "Epoch 157/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 749846912.0000 - val_loss: 1006253760.0000\n",
      "Epoch 158/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 741788928.0000 - val_loss: 1019311424.0000\n",
      "Epoch 159/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 747373312.0000 - val_loss: 1016285952.0000\n",
      "Epoch 160/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 722795904.0000 - val_loss: 1009546432.0000\n",
      "Epoch 161/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 723246656.0000 - val_loss: 994303936.0000\n",
      "Epoch 162/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 725285056.0000 - val_loss: 1029209152.0000\n",
      "Epoch 163/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 733965888.0000 - val_loss: 994195136.0000\n",
      "Epoch 164/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 699435520.0000 - val_loss: 993569408.0000\n",
      "Epoch 165/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 692381440.0000 - val_loss: 984869632.0000\n",
      "Epoch 166/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 677226624.0000 - val_loss: 985332096.0000\n",
      "Epoch 167/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 691543616.0000 - val_loss: 1011943616.0000\n",
      "Epoch 168/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 668607104.0000 - val_loss: 1004361472.0000\n",
      "Epoch 169/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 716598336.0000 - val_loss: 991562112.0000\n",
      "Epoch 170/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 660441600.0000 - val_loss: 997345088.0000\n",
      "Epoch 171/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 650501568.0000 - val_loss: 971257600.0000\n",
      "Epoch 172/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 644753472.0000 - val_loss: 962827648.0000\n",
      "Epoch 173/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 633464704.0000 - val_loss: 964021696.0000\n",
      "Epoch 174/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 628535680.0000 - val_loss: 961827712.0000\n",
      "Epoch 175/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 622351360.0000 - val_loss: 964667584.0000\n",
      "Epoch 176/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 624725056.0000 - val_loss: 1000590528.0000\n",
      "Epoch 177/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 667174784.0000 - val_loss: 977935104.0000\n",
      "Epoch 178/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 633471424.0000 - val_loss: 968213056.0000\n",
      "Epoch 179/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 607392064.0000 - val_loss: 949986304.0000\n",
      "Epoch 180/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 595415424.0000 - val_loss: 948988544.0000\n",
      "Epoch 181/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 590493440.0000 - val_loss: 948673024.0000\n",
      "Epoch 182/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 589536704.0000 - val_loss: 943780864.0000\n",
      "Epoch 183/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 583410880.0000 - val_loss: 943678976.0000\n",
      "Epoch 184/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 589911424.0000 - val_loss: 947844288.0000\n",
      "Epoch 185/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 595439296.0000 - val_loss: 944592960.0000\n",
      "Epoch 186/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 572414528.0000 - val_loss: 932722816.0000\n",
      "Epoch 187/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 570139008.0000 - val_loss: 944465216.0000\n",
      "Epoch 188/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 578830016.0000 - val_loss: 934792832.0000\n",
      "Epoch 189/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 569834496.0000 - val_loss: 937744192.0000\n",
      "Epoch 190/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 560589824.0000 - val_loss: 928068800.0000\n",
      "Epoch 191/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 546690944.0000 - val_loss: 931938816.0000\n",
      "Epoch 192/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 545826048.0000 - val_loss: 938967936.0000\n",
      "Epoch 193/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 555297600.0000 - val_loss: 930444288.0000\n",
      "Epoch 194/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 550210112.0000 - val_loss: 933769280.0000\n",
      "Epoch 195/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 554040896.0000 - val_loss: 941447680.0000\n",
      "Epoch 196/2000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 534788416.0000 - val_loss: 922975936.0000\n",
      "Epoch 197/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 519773504.0000 - val_loss: 924339008.0000\n",
      "Epoch 198/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 517527840.0000 - val_loss: 924284672.0000\n",
      "Epoch 199/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 513292832.0000 - val_loss: 921053312.0000\n",
      "Epoch 200/2000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 521161568.0000 - val_loss: 939854464.0000\n",
      "Epoch 201/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 507853728.0000 - val_loss: 951875776.0000\n",
      "Epoch 202/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 515189888.0000 - val_loss: 924274688.0000\n",
      "Epoch 203/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 496053088.0000 - val_loss: 923164672.0000\n",
      "Epoch 204/2000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 497375264.0000 - val_loss: 916756224.0000\n",
      "Epoch 205/2000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 494766720.0000 - val_loss: 944859456.0000\n",
      "Epoch 206/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 534748576.0000 - val_loss: 947316992.0000\n",
      "Epoch 207/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 526892000.0000 - val_loss: 931962112.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 483358816.0000 - val_loss: 915321792.0000\n",
      "Epoch 209/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 484969344.0000 - val_loss: 953651264.0000\n",
      "Epoch 210/2000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 493130496.0000 - val_loss: 911924288.0000\n",
      "Epoch 211/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 470847936.0000 - val_loss: 911821888.0000\n",
      "Epoch 212/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 473900832.0000 - val_loss: 924256448.0000\n",
      "Epoch 213/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 468874560.0000 - val_loss: 935295104.0000\n",
      "Epoch 214/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 501502496.0000 - val_loss: 941955840.0000\n",
      "Epoch 215/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 479068896.0000 - val_loss: 911306368.0000\n",
      "Epoch 216/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 457134624.0000 - val_loss: 905967936.0000\n",
      "Epoch 217/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 469288640.0000 - val_loss: 917751872.0000\n",
      "Epoch 218/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 455535648.0000 - val_loss: 914976960.0000\n",
      "Epoch 219/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 454562240.0000 - val_loss: 905469312.0000\n",
      "Epoch 220/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 445310688.0000 - val_loss: 903205952.0000\n",
      "Epoch 221/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 444519136.0000 - val_loss: 906243008.0000\n",
      "Epoch 222/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 461518816.0000 - val_loss: 919336256.0000\n",
      "Epoch 223/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 451472320.0000 - val_loss: 902668864.0000\n",
      "Epoch 224/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 441251424.0000 - val_loss: 912450176.0000\n",
      "Epoch 225/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 448166304.0000 - val_loss: 910875264.0000\n",
      "Epoch 226/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 431889312.0000 - val_loss: 902035200.0000\n",
      "Epoch 227/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 433281760.0000 - val_loss: 912721536.0000\n",
      "Epoch 228/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 425779872.0000 - val_loss: 902860864.0000\n",
      "Epoch 229/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 422683776.0000 - val_loss: 899628224.0000\n",
      "Epoch 230/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 425048704.0000 - val_loss: 907828800.0000\n",
      "Epoch 231/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 439410912.0000 - val_loss: 940363200.0000\n",
      "Epoch 232/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 429234944.0000 - val_loss: 901353280.0000\n",
      "Epoch 233/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 413013120.0000 - val_loss: 901279808.0000\n",
      "Epoch 234/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 410737024.0000 - val_loss: 904917824.0000\n",
      "Epoch 235/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 407040960.0000 - val_loss: 900257216.0000\n",
      "Epoch 236/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 406330784.0000 - val_loss: 966214272.0000\n",
      "Epoch 237/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 451690752.0000 - val_loss: 902617152.0000\n",
      "Epoch 238/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 403454496.0000 - val_loss: 895097152.0000\n",
      "Epoch 239/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 411547392.0000 - val_loss: 922519680.0000\n",
      "Epoch 240/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 443390944.0000 - val_loss: 914310592.0000\n",
      "Epoch 241/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 420127872.0000 - val_loss: 906306304.0000\n",
      "Epoch 242/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 404355168.0000 - val_loss: 895130240.0000\n",
      "Epoch 243/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 407386624.0000 - val_loss: 913749440.0000\n",
      "Epoch 244/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 400132640.0000 - val_loss: 889238976.0000\n",
      "Epoch 245/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 387923104.0000 - val_loss: 884442176.0000\n",
      "Epoch 246/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 386540896.0000 - val_loss: 885258880.0000\n",
      "Epoch 247/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 386423424.0000 - val_loss: 913003008.0000\n",
      "Epoch 248/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 402940192.0000 - val_loss: 895115584.0000\n",
      "Epoch 249/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 388756672.0000 - val_loss: 900620928.0000\n",
      "Epoch 250/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 391765504.0000 - val_loss: 895778816.0000\n",
      "Epoch 251/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 377630720.0000 - val_loss: 885469696.0000\n",
      "Epoch 252/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 375207744.0000 - val_loss: 890670784.0000\n",
      "Epoch 253/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 394928864.0000 - val_loss: 912144000.0000\n",
      "Epoch 254/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 377228224.0000 - val_loss: 884313664.0000\n",
      "Epoch 255/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 376386976.0000 - val_loss: 883394944.0000\n",
      "Epoch 256/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 369467904.0000 - val_loss: 877335360.0000\n",
      "Epoch 257/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 377938848.0000 - val_loss: 930551552.0000\n",
      "Epoch 258/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 393173696.0000 - val_loss: 881754624.0000\n",
      "Epoch 259/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 376722720.0000 - val_loss: 904121728.0000\n",
      "Epoch 260/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 375435488.0000 - val_loss: 881496128.0000\n",
      "Epoch 261/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 357992416.0000 - val_loss: 877842816.0000\n",
      "Epoch 262/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 366919232.0000 - val_loss: 893849088.0000\n",
      "Epoch 263/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 365623264.0000 - val_loss: 882377536.0000\n",
      "Epoch 264/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 356553120.0000 - val_loss: 893747776.0000\n",
      "Epoch 265/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 383428704.0000 - val_loss: 905993216.0000\n",
      "Epoch 266/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 366889408.0000 - val_loss: 877603328.0000\n",
      "Epoch 267/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 350183040.0000 - val_loss: 877388352.0000\n",
      "Epoch 268/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 364055392.0000 - val_loss: 888302784.0000\n",
      "Epoch 269/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 353569056.0000 - val_loss: 882391808.0000\n",
      "Epoch 270/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 345612288.0000 - val_loss: 891367872.0000\n",
      "Epoch 271/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 354337600.0000 - val_loss: 871666432.0000\n",
      "Epoch 272/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 343913280.0000 - val_loss: 875780288.0000\n",
      "Epoch 273/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 353010592.0000 - val_loss: 907947072.0000\n",
      "Epoch 274/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 358528704.0000 - val_loss: 880570432.0000\n",
      "Epoch 275/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 338619456.0000 - val_loss: 874507968.0000\n",
      "Epoch 276/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 342800288.0000 - val_loss: 895634560.0000\n",
      "Epoch 277/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 364730912.0000 - val_loss: 889775808.0000\n",
      "Epoch 278/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 34ms/step - loss: 344457984.0000 - val_loss: 878502912.0000\n",
      "Epoch 279/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 333210144.0000 - val_loss: 869522944.0000\n",
      "Epoch 280/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 336953760.0000 - val_loss: 895468736.0000\n",
      "Epoch 281/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 331478816.0000 - val_loss: 872989632.0000\n",
      "Epoch 282/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 350243488.0000 - val_loss: 902120960.0000\n",
      "Epoch 283/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 342198208.0000 - val_loss: 872152960.0000\n",
      "Epoch 284/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 326434816.0000 - val_loss: 873330048.0000\n",
      "Epoch 285/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 325642784.0000 - val_loss: 868494080.0000\n",
      "Epoch 286/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 329084704.0000 - val_loss: 900131328.0000\n",
      "Epoch 287/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 340925760.0000 - val_loss: 886058048.0000\n",
      "Epoch 288/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 349606176.0000 - val_loss: 913878912.0000\n",
      "Epoch 289/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 336721440.0000 - val_loss: 871656192.0000\n",
      "Epoch 290/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 317952608.0000 - val_loss: 875951296.0000\n",
      "Epoch 291/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 320613056.0000 - val_loss: 881302784.0000\n",
      "Epoch 292/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 320909376.0000 - val_loss: 873943616.0000\n",
      "Epoch 293/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 317430272.0000 - val_loss: 878962816.0000\n",
      "Epoch 294/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 313137472.0000 - val_loss: 879231104.0000\n",
      "Epoch 295/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 337001280.0000 - val_loss: 886948416.0000\n",
      "Epoch 296/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 325594624.0000 - val_loss: 869607936.0000\n",
      "Epoch 297/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 309994400.0000 - val_loss: 874445504.0000\n",
      "Epoch 298/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 308459616.0000 - val_loss: 872630464.0000\n",
      "Epoch 299/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 310280832.0000 - val_loss: 887724096.0000\n",
      "Epoch 300/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 322562080.0000 - val_loss: 888243712.0000\n",
      "Epoch 301/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 312289024.0000 - val_loss: 877823168.0000\n",
      "Epoch 302/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 310577344.0000 - val_loss: 889610688.0000\n",
      "Epoch 303/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 318473184.0000 - val_loss: 883406912.0000\n",
      "Epoch 304/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 306504992.0000 - val_loss: 881000512.0000\n",
      "Epoch 305/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 301963904.0000 - val_loss: 880757120.0000\n",
      "Epoch 306/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 299023520.0000 - val_loss: 870493568.0000\n",
      "Epoch 307/2000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 309137696.0000 - val_loss: 915749504.0000\n",
      "Epoch 308/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 343694400.0000 - val_loss: 873656256.0000\n",
      "Epoch 309/2000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 306444576.0000 - val_loss: 876592512.0000\n",
      "Epoch 310/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 316013312.0000 - val_loss: 878715328.0000\n",
      "Epoch 311/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 305212832.0000 - val_loss: 873757248.0000\n",
      "Epoch 312/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 293627712.0000 - val_loss: 888474112.0000\n",
      "Epoch 313/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 297567008.0000 - val_loss: 873397184.0000\n",
      "Epoch 314/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 300297504.0000 - val_loss: 889430528.0000\n",
      "Epoch 315/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 293951552.0000 - val_loss: 877601088.0000\n",
      "Epoch 316/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 288230048.0000 - val_loss: 876856256.0000\n",
      "Epoch 317/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 291692608.0000 - val_loss: 919664704.0000\n",
      "Epoch 318/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 333021632.0000 - val_loss: 882465344.0000\n",
      "Epoch 319/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 293097760.0000 - val_loss: 873152000.0000\n",
      "Epoch 320/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 287287712.0000 - val_loss: 888666624.0000\n",
      "Epoch 321/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 288715008.0000 - val_loss: 876926720.0000\n",
      "Epoch 322/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 294566112.0000 - val_loss: 881016192.0000\n",
      "Epoch 323/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 296776768.0000 - val_loss: 888241728.0000\n",
      "Epoch 324/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 282207296.0000 - val_loss: 872224576.0000\n",
      "Epoch 325/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 279317760.0000 - val_loss: 877904832.0000\n",
      "Epoch 326/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 298225024.0000 - val_loss: 893780416.0000\n",
      "Epoch 327/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 288444352.0000 - val_loss: 865412352.0000\n",
      "Epoch 328/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 275897088.0000 - val_loss: 868032832.0000\n",
      "Epoch 329/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 275056864.0000 - val_loss: 868602880.0000\n",
      "Epoch 330/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 280951840.0000 - val_loss: 882762304.0000\n",
      "Epoch 331/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 310481184.0000 - val_loss: 887560320.0000\n",
      "Epoch 332/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 317299168.0000 - val_loss: 891498112.0000\n",
      "Epoch 333/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 283942272.0000 - val_loss: 869965056.0000\n",
      "Epoch 334/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 284223552.0000 - val_loss: 885835904.0000\n",
      "Epoch 335/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 276754688.0000 - val_loss: 867790976.0000\n",
      "Epoch 336/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 270903200.0000 - val_loss: 868149376.0000\n",
      "Epoch 337/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 269376896.0000 - val_loss: 862601856.0000\n",
      "Epoch 338/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 270051872.0000 - val_loss: 874550080.0000\n",
      "Epoch 339/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 289940896.0000 - val_loss: 899568704.0000\n",
      "Epoch 340/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 301279872.0000 - val_loss: 869572992.0000\n",
      "Epoch 341/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 273653472.0000 - val_loss: 867793856.0000\n",
      "Epoch 342/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 267211616.0000 - val_loss: 866396864.0000\n",
      "Epoch 343/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 263609424.0000 - val_loss: 863039424.0000\n",
      "Epoch 344/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 273806016.0000 - val_loss: 900448640.0000\n",
      "Epoch 345/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 301870048.0000 - val_loss: 870768640.0000\n",
      "Epoch 346/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 261997936.0000 - val_loss: 873546176.0000\n",
      "Epoch 347/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 263636352.0000 - val_loss: 877177472.0000\n",
      "Epoch 348/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 43ms/step - loss: 262600560.0000 - val_loss: 872920384.0000\n",
      "Epoch 349/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 267405632.0000 - val_loss: 884650368.0000\n",
      "Epoch 350/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 264974928.0000 - val_loss: 863840448.0000\n",
      "Epoch 351/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 257351488.0000 - val_loss: 874780032.0000\n",
      "Epoch 352/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 257719312.0000 - val_loss: 867424640.0000\n",
      "Epoch 353/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 255839104.0000 - val_loss: 870836800.0000\n",
      "Epoch 354/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 271861120.0000 - val_loss: 941997888.0000\n",
      "Epoch 355/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 293204448.0000 - val_loss: 872364288.0000\n",
      "Epoch 356/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 254050752.0000 - val_loss: 870318272.0000\n",
      "Epoch 357/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 257617248.0000 - val_loss: 890997760.0000\n",
      "Epoch 358/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 260327376.0000 - val_loss: 868275712.0000\n",
      "Epoch 359/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 250728480.0000 - val_loss: 874547968.0000\n",
      "Epoch 360/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 279248512.0000 - val_loss: 892404736.0000\n",
      "Epoch 361/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 263615504.0000 - val_loss: 872723328.0000\n",
      "Epoch 362/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 248789216.0000 - val_loss: 867872640.0000\n",
      "Epoch 363/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 258212400.0000 - val_loss: 892462848.0000\n",
      "Epoch 364/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 273901312.0000 - val_loss: 880120576.0000\n",
      "Epoch 365/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 275395488.0000 - val_loss: 889168256.0000\n",
      "Epoch 366/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 261827808.0000 - val_loss: 872128512.0000\n",
      "Epoch 367/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 244907056.0000 - val_loss: 867665088.0000\n",
      "Epoch 368/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 244631600.0000 - val_loss: 869542400.0000\n",
      "Epoch 369/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 243644496.0000 - val_loss: 867355392.0000\n",
      "Epoch 370/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 243551584.0000 - val_loss: 870193792.0000\n",
      "Epoch 371/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 272977760.0000 - val_loss: 913136000.0000\n",
      "Epoch 372/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 280076352.0000 - val_loss: 867066304.0000\n",
      "Epoch 373/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 240942576.0000 - val_loss: 876762176.0000\n",
      "Epoch 374/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 253426672.0000 - val_loss: 874509120.0000\n",
      "Epoch 375/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 240304464.0000 - val_loss: 876250944.0000\n",
      "Epoch 376/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 254856848.0000 - val_loss: 872964032.0000\n",
      "Epoch 377/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 239242016.0000 - val_loss: 871628224.0000\n",
      "Epoch 378/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 237607712.0000 - val_loss: 870597632.0000\n",
      "Epoch 379/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 237075872.0000 - val_loss: 876257088.0000\n",
      "Epoch 380/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 239148352.0000 - val_loss: 870925952.0000\n",
      "Epoch 381/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 233820720.0000 - val_loss: 875296704.0000\n",
      "Epoch 382/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 264690608.0000 - val_loss: 927197376.0000\n",
      "Epoch 383/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 297230272.0000 - val_loss: 871303680.0000\n",
      "Epoch 384/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 234480896.0000 - val_loss: 863828160.0000\n",
      "Epoch 385/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 236423296.0000 - val_loss: 881315072.0000\n",
      "Epoch 386/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 247522864.0000 - val_loss: 876666560.0000\n",
      "Epoch 387/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 234027536.0000 - val_loss: 870230656.0000\n",
      "Epoch 388/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 230214432.0000 - val_loss: 872976832.0000\n",
      "Epoch 389/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 233348144.0000 - val_loss: 865705152.0000\n",
      "Epoch 390/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 233385760.0000 - val_loss: 902594944.0000\n",
      "Epoch 391/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 238487584.0000 - val_loss: 876321920.0000\n",
      "Epoch 392/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 227491680.0000 - val_loss: 872610560.0000\n",
      "Epoch 393/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 227463920.0000 - val_loss: 883450240.0000\n",
      "Epoch 394/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 245830688.0000 - val_loss: 876293184.0000\n",
      "Epoch 395/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 228083568.0000 - val_loss: 874553728.0000\n",
      "Epoch 396/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 229137760.0000 - val_loss: 872125696.0000\n",
      "Epoch 397/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 225987616.0000 - val_loss: 886719360.0000\n",
      "Epoch 398/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 248657488.0000 - val_loss: 925067968.0000\n",
      "Epoch 399/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 267554256.0000 - val_loss: 876468288.0000\n",
      "Epoch 400/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 221532816.0000 - val_loss: 871861440.0000\n",
      "Epoch 401/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 220547264.0000 - val_loss: 875937152.0000\n",
      "Epoch 402/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 235558096.0000 - val_loss: 891137216.0000\n",
      "Epoch 403/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 226838272.0000 - val_loss: 875890880.0000\n",
      "Epoch 404/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 227965744.0000 - val_loss: 889037376.0000\n",
      "Epoch 405/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 221422736.0000 - val_loss: 891772928.0000\n",
      "Epoch 406/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 244406272.0000 - val_loss: 893695232.0000\n",
      "Epoch 407/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 241447248.0000 - val_loss: 887513664.0000\n",
      "Epoch 408/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 224865664.0000 - val_loss: 867125504.0000\n",
      "Epoch 409/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 217282336.0000 - val_loss: 870843456.0000\n",
      "Epoch 410/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 223390336.0000 - val_loss: 883873728.0000\n",
      "Epoch 411/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 236727312.0000 - val_loss: 882594880.0000\n",
      "Epoch 412/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 228653600.0000 - val_loss: 874784192.0000\n",
      "Epoch 413/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 238368512.0000 - val_loss: 894434432.0000\n",
      "Epoch 414/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 250671584.0000 - val_loss: 889861952.0000\n",
      "Epoch 415/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 222720816.0000 - val_loss: 869589312.0000\n",
      "Epoch 416/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 212425504.0000 - val_loss: 868520832.0000\n",
      "Epoch 417/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 212726176.0000 - val_loss: 864360576.0000\n",
      "Epoch 418/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 212765904.0000 - val_loss: 871695360.0000\n",
      "Epoch 419/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 210805072.0000 - val_loss: 870069504.0000\n",
      "Epoch 420/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 217355104.0000 - val_loss: 891390592.0000\n",
      "Epoch 421/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 233438640.0000 - val_loss: 880571904.0000\n",
      "Epoch 422/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 240769952.0000 - val_loss: 899345024.0000\n",
      "Epoch 423/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 252929456.0000 - val_loss: 894619840.0000\n",
      "Epoch 424/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 226057632.0000 - val_loss: 872811520.0000\n",
      "Epoch 425/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 207518448.0000 - val_loss: 866882944.0000\n",
      "Epoch 426/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 214648128.0000 - val_loss: 890847040.0000\n",
      "Epoch 427/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 214515616.0000 - val_loss: 874941248.0000\n",
      "Epoch 428/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 210023408.0000 - val_loss: 874632128.0000\n",
      "Epoch 429/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 207175040.0000 - val_loss: 869303168.0000\n",
      "Epoch 430/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 204802528.0000 - val_loss: 866678144.0000\n",
      "Epoch 431/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 203471904.0000 - val_loss: 872255680.0000\n",
      "Epoch 432/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 212793584.0000 - val_loss: 907972096.0000\n",
      "Epoch 433/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 249631504.0000 - val_loss: 896795968.0000\n",
      "Epoch 434/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 226089776.0000 - val_loss: 875442560.0000\n",
      "Epoch 435/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 203216976.0000 - val_loss: 868924032.0000\n",
      "Epoch 436/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 203374368.0000 - val_loss: 887384000.0000\n",
      "Epoch 437/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 211687840.0000 - val_loss: 871472704.0000\n",
      "Epoch 438/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 199698464.0000 - val_loss: 869580288.0000\n",
      "Epoch 439/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 200740272.0000 - val_loss: 866705920.0000\n",
      "Epoch 440/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205434848.0000 - val_loss: 884140544.0000\n",
      "Epoch 441/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 230603056.0000 - val_loss: 895998528.0000\n",
      "Epoch 442/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 217449456.0000 - val_loss: 871817344.0000\n",
      "Epoch 443/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 201680592.0000 - val_loss: 874621952.0000\n",
      "Epoch 444/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 196843104.0000 - val_loss: 869382976.0000\n",
      "Epoch 445/2000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 195774800.0000 - val_loss: 872451712.0000\n",
      "Epoch 446/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 197982160.0000 - val_loss: 880364736.0000\n",
      "Epoch 447/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 218793344.0000 - val_loss: 917077504.0000\n",
      "Epoch 448/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 251885360.0000 - val_loss: 884288896.0000\n",
      "Epoch 449/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 213534720.0000 - val_loss: 876592576.0000\n",
      "Epoch 450/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 197640400.0000 - val_loss: 867467712.0000\n",
      "Epoch 451/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 194981616.0000 - val_loss: 878289344.0000\n",
      "Epoch 452/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 199691216.0000 - val_loss: 874255104.0000\n",
      "Epoch 453/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 207465040.0000 - val_loss: 898293696.0000\n",
      "Epoch 454/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 213917888.0000 - val_loss: 879340352.0000\n",
      "Epoch 455/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 192169648.0000 - val_loss: 876342272.0000\n",
      "Epoch 456/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 192110816.0000 - val_loss: 866924480.0000\n",
      "Epoch 457/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 192896128.0000 - val_loss: 877055360.0000\n",
      "Epoch 458/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 197660672.0000 - val_loss: 881291072.0000\n",
      "Epoch 459/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 189748192.0000 - val_loss: 899121024.0000\n",
      "Epoch 460/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 242085072.0000 - val_loss: 895285504.0000\n",
      "Epoch 461/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 226809856.0000 - val_loss: 877391808.0000\n",
      "Epoch 462/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 192701744.0000 - val_loss: 867811136.0000\n",
      "Epoch 463/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 187676480.0000 - val_loss: 874874816.0000\n",
      "Epoch 464/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 189098208.0000 - val_loss: 871652928.0000\n",
      "Epoch 465/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 198939264.0000 - val_loss: 895400448.0000\n",
      "Epoch 466/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 233115808.0000 - val_loss: 893391040.0000\n",
      "Epoch 467/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 203315952.0000 - val_loss: 874931648.0000\n",
      "Epoch 468/2000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 186887440.0000 - val_loss: 876969856.0000\n",
      "Epoch 469/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 184276944.0000 - val_loss: 875380800.0000\n",
      "Epoch 470/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 184944496.0000 - val_loss: 881799808.0000\n",
      "Epoch 471/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 196840880.0000 - val_loss: 876767104.0000\n",
      "Epoch 472/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 185487056.0000 - val_loss: 873920704.0000\n",
      "Epoch 473/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 186693984.0000 - val_loss: 888919680.0000\n",
      "Epoch 474/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 202335136.0000 - val_loss: 891355712.0000\n",
      "Epoch 475/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 189153168.0000 - val_loss: 879048576.0000\n",
      "Epoch 476/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 186979056.0000 - val_loss: 896444736.0000\n",
      "Epoch 477/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 200520320.0000 - val_loss: 885318912.0000\n",
      "Epoch 478/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 184516464.0000 - val_loss: 877633216.0000\n",
      "Epoch 479/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 186053200.0000 - val_loss: 883088576.0000\n",
      "Epoch 480/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 182016272.0000 - val_loss: 877875584.0000\n",
      "Epoch 481/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 179653824.0000 - val_loss: 878203456.0000\n",
      "Epoch 482/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 177699280.0000 - val_loss: 889147968.0000\n",
      "Epoch 483/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 189876928.0000 - val_loss: 876030528.0000\n",
      "Epoch 484/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 181042256.0000 - val_loss: 870881472.0000\n",
      "Epoch 485/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 180891920.0000 - val_loss: 892814272.0000\n",
      "Epoch 486/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 225382592.0000 - val_loss: 909369152.0000\n",
      "Epoch 487/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 217568640.0000 - val_loss: 882164608.0000\n",
      "Epoch 488/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 46ms/step - loss: 191439312.0000 - val_loss: 887198144.0000\n",
      "Epoch 489/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 189721936.0000 - val_loss: 879557632.0000\n",
      "Epoch 490/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 175683504.0000 - val_loss: 870953536.0000\n",
      "Epoch 491/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 174128896.0000 - val_loss: 879745856.0000\n",
      "Epoch 492/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 187459920.0000 - val_loss: 898295168.0000\n",
      "Epoch 493/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 184140368.0000 - val_loss: 879424960.0000\n",
      "Epoch 494/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 171825376.0000 - val_loss: 875717376.0000\n",
      "Epoch 495/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 175326928.0000 - val_loss: 882799616.0000\n",
      "Epoch 496/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 176357040.0000 - val_loss: 871754816.0000\n",
      "Epoch 497/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 172267840.0000 - val_loss: 890955200.0000\n",
      "Epoch 498/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 193634160.0000 - val_loss: 898127552.0000\n",
      "Epoch 499/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 191767168.0000 - val_loss: 888562112.0000\n",
      "Epoch 500/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 188045552.0000 - val_loss: 891615360.0000\n",
      "Epoch 501/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 178642576.0000 - val_loss: 878406400.0000\n",
      "Epoch 502/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 169069808.0000 - val_loss: 876274560.0000\n",
      "Epoch 503/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 167235840.0000 - val_loss: 875468480.0000\n",
      "Epoch 504/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 170598032.0000 - val_loss: 877275712.0000\n",
      "Epoch 505/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 177023280.0000 - val_loss: 891025792.0000\n",
      "Epoch 506/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 196463520.0000 - val_loss: 894020800.0000\n",
      "Epoch 507/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 184468048.0000 - val_loss: 875085952.0000\n",
      "Epoch 508/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 165408560.0000 - val_loss: 887744448.0000\n",
      "Epoch 509/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 167631264.0000 - val_loss: 878022976.0000\n",
      "Epoch 510/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 170665840.0000 - val_loss: 877142144.0000\n",
      "Epoch 511/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 180245488.0000 - val_loss: 887555008.0000\n",
      "Epoch 512/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 179978544.0000 - val_loss: 876225600.0000\n",
      "Epoch 513/2000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 168226896.0000 - val_loss: 866710464.0000\n",
      "Epoch 514/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 162949472.0000 - val_loss: 879337024.0000\n",
      "Epoch 515/2000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 167714224.0000 - val_loss: 886705984.0000\n",
      "Epoch 516/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 181209840.0000 - val_loss: 904817408.0000\n",
      "Epoch 517/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 182236432.0000 - val_loss: 886584320.0000\n",
      "Epoch 518/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 177046192.0000 - val_loss: 893982848.0000\n",
      "Epoch 519/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 173470880.0000 - val_loss: 889790400.0000\n",
      "Epoch 520/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 167163376.0000 - val_loss: 884130688.0000\n",
      "Epoch 521/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 163194960.0000 - val_loss: 876665408.0000\n",
      "Epoch 522/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 159845712.0000 - val_loss: 876636288.0000\n",
      "Epoch 523/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 172988272.0000 - val_loss: 913818816.0000\n",
      "Epoch 524/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 194703696.0000 - val_loss: 876916672.0000\n",
      "Epoch 525/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 166331664.0000 - val_loss: 876659520.0000\n",
      "Epoch 526/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 171193616.0000 - val_loss: 881831616.0000\n",
      "Epoch 527/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 168197472.0000 - val_loss: 881643968.0000\n",
      "Epoch 528/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 163377712.0000 - val_loss: 883269632.0000\n",
      "Epoch 529/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 162912560.0000 - val_loss: 889824640.0000\n",
      "Epoch 530/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 160446656.0000 - val_loss: 875387584.0000\n",
      "Epoch 531/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 159249024.0000 - val_loss: 887105408.0000\n",
      "Epoch 532/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 172580512.0000 - val_loss: 892287488.0000\n",
      "Epoch 533/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 176161328.0000 - val_loss: 889320192.0000\n",
      "Epoch 534/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 169035696.0000 - val_loss: 880409408.0000\n",
      "Epoch 535/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 154849632.0000 - val_loss: 878335360.0000\n",
      "Epoch 536/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 154834128.0000 - val_loss: 886522176.0000\n",
      "Epoch 537/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 153304928.0000 - val_loss: 882758272.0000\n",
      "Epoch 538/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 153727536.0000 - val_loss: 884455680.0000\n",
      "Epoch 539/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 168942464.0000 - val_loss: 908427584.0000\n",
      "Epoch 540/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 179711984.0000 - val_loss: 880433792.0000\n",
      "Epoch 541/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 161409584.0000 - val_loss: 880080256.0000\n",
      "Epoch 542/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 160264080.0000 - val_loss: 890760640.0000\n",
      "Epoch 543/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 155063696.0000 - val_loss: 880081216.0000\n",
      "Epoch 544/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 150604224.0000 - val_loss: 887494144.0000\n",
      "Epoch 545/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 149454320.0000 - val_loss: 879508544.0000\n",
      "Epoch 546/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 160223248.0000 - val_loss: 929355072.0000\n",
      "Epoch 547/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 194631648.0000 - val_loss: 904262528.0000\n",
      "Epoch 548/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 163913872.0000 - val_loss: 893545600.0000\n",
      "Epoch 549/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 154626704.0000 - val_loss: 886765824.0000\n",
      "Epoch 550/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 160418032.0000 - val_loss: 911014656.0000\n",
      "Epoch 551/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 165719424.0000 - val_loss: 884667264.0000\n",
      "Epoch 552/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 154405392.0000 - val_loss: 889951424.0000\n",
      "Epoch 553/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 168387792.0000 - val_loss: 896184640.0000\n",
      "Epoch 554/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 154718240.0000 - val_loss: 881011520.0000\n",
      "Epoch 555/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 146221216.0000 - val_loss: 879365376.0000\n",
      "Epoch 556/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 156280368.0000 - val_loss: 900543488.0000\n",
      "Epoch 557/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 178901472.0000 - val_loss: 896632000.0000\n",
      "Epoch 558/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 168433104.0000 - val_loss: 882926656.0000\n",
      "Epoch 559/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 161137680.0000 - val_loss: 892044608.0000\n",
      "Epoch 560/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 152199536.0000 - val_loss: 876861632.0000\n",
      "Epoch 561/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 143719456.0000 - val_loss: 878193600.0000\n",
      "Epoch 562/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 144298288.0000 - val_loss: 875850368.0000\n",
      "Epoch 563/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 145497856.0000 - val_loss: 880542464.0000\n",
      "Epoch 564/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 145999552.0000 - val_loss: 878484992.0000\n",
      "Epoch 565/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 158638384.0000 - val_loss: 901570368.0000\n",
      "Epoch 566/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 182130336.0000 - val_loss: 904208256.0000\n",
      "Epoch 567/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 174158464.0000 - val_loss: 882334976.0000\n",
      "Epoch 568/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 146198320.0000 - val_loss: 875560064.0000\n",
      "Epoch 569/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 141299056.0000 - val_loss: 884305088.0000\n",
      "Epoch 570/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 142631840.0000 - val_loss: 882107008.0000\n",
      "Epoch 571/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 140649264.0000 - val_loss: 882279872.0000\n",
      "Epoch 572/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 141315328.0000 - val_loss: 880154240.0000\n",
      "Epoch 573/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 148642896.0000 - val_loss: 878405376.0000\n",
      "Epoch 574/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 165111360.0000 - val_loss: 911292544.0000\n",
      "Epoch 575/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 167315360.0000 - val_loss: 878223808.0000\n",
      "Epoch 576/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 140226880.0000 - val_loss: 880050560.0000\n",
      "Epoch 577/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 139492800.0000 - val_loss: 886178432.0000\n",
      "Epoch 578/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 163378832.0000 - val_loss: 920109056.0000\n",
      "Epoch 579/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 172334416.0000 - val_loss: 880513984.0000\n",
      "Epoch 580/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 142490480.0000 - val_loss: 879449280.0000\n",
      "Epoch 581/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 145312688.0000 - val_loss: 885217600.0000\n",
      "Epoch 582/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 142632032.0000 - val_loss: 878802752.0000\n",
      "Epoch 583/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 136384256.0000 - val_loss: 884748224.0000\n",
      "Epoch 584/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 144779360.0000 - val_loss: 887847168.0000\n",
      "Epoch 585/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 137202576.0000 - val_loss: 880649408.0000\n",
      "Epoch 586/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 135283184.0000 - val_loss: 902115904.0000\n",
      "Epoch 587/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 172316672.0000 - val_loss: 925834816.0000\n",
      "Epoch 588/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 167211104.0000 - val_loss: 885697024.0000\n",
      "Epoch 589/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 137239712.0000 - val_loss: 890997376.0000\n",
      "Epoch 590/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 133056248.0000 - val_loss: 885221760.0000\n",
      "Epoch 591/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 142660304.0000 - val_loss: 901911936.0000\n",
      "Epoch 592/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 163695600.0000 - val_loss: 903808384.0000\n",
      "Epoch 593/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 154316048.0000 - val_loss: 891322560.0000\n",
      "Epoch 594/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 137657952.0000 - val_loss: 883078912.0000\n",
      "Epoch 595/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 132647120.0000 - val_loss: 881772416.0000\n",
      "Epoch 596/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 133209096.0000 - val_loss: 883645184.0000\n",
      "Epoch 597/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 137102176.0000 - val_loss: 897238912.0000\n",
      "Epoch 598/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 145761152.0000 - val_loss: 901366720.0000\n",
      "Epoch 599/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 152574000.0000 - val_loss: 898768448.0000\n",
      "Epoch 600/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 147919760.0000 - val_loss: 899875776.0000\n",
      "Epoch 601/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 150042464.0000 - val_loss: 890942400.0000\n",
      "Epoch 602/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 132015288.0000 - val_loss: 877069568.0000\n",
      "Epoch 603/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 132256488.0000 - val_loss: 888597504.0000\n",
      "Epoch 604/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 131404448.0000 - val_loss: 874106240.0000\n",
      "Epoch 605/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 129276000.0000 - val_loss: 891368320.0000\n",
      "Epoch 606/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 139793712.0000 - val_loss: 878437760.0000\n",
      "Epoch 607/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 168777584.0000 - val_loss: 922747200.0000\n",
      "Epoch 608/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 157905952.0000 - val_loss: 885169536.0000\n",
      "Epoch 609/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 127728208.0000 - val_loss: 886355264.0000\n",
      "Epoch 610/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 127121456.0000 - val_loss: 888878848.0000\n",
      "Epoch 611/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 126870368.0000 - val_loss: 888295488.0000\n",
      "Epoch 612/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 145455056.0000 - val_loss: 912557504.0000\n",
      "Epoch 613/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 145901296.0000 - val_loss: 876900544.0000\n",
      "Epoch 614/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 131940856.0000 - val_loss: 892256320.0000\n",
      "Epoch 615/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 140036624.0000 - val_loss: 889080000.0000\n",
      "Epoch 616/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 127267496.0000 - val_loss: 879831616.0000\n",
      "Epoch 617/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 125093296.0000 - val_loss: 882113216.0000\n",
      "Epoch 618/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 128430696.0000 - val_loss: 898596096.0000\n",
      "Epoch 619/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 154581760.0000 - val_loss: 900032896.0000\n",
      "Epoch 620/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 148235424.0000 - val_loss: 901802752.0000\n",
      "Epoch 621/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 131674320.0000 - val_loss: 886390208.0000\n",
      "Epoch 622/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 124250464.0000 - val_loss: 879601280.0000\n",
      "Epoch 623/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 126865480.0000 - val_loss: 888653696.0000\n",
      "Epoch 624/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 128607160.0000 - val_loss: 883223488.0000\n",
      "Epoch 625/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 125898064.0000 - val_loss: 879285696.0000\n",
      "Epoch 626/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 125289240.0000 - val_loss: 880584576.0000\n",
      "Epoch 627/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 120753056.0000 - val_loss: 879415424.0000\n",
      "Epoch 628/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 67ms/step - loss: 122273456.0000 - val_loss: 882924928.0000\n",
      "Epoch 629/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 120963688.0000 - val_loss: 885444992.0000\n",
      "Epoch 630/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 121653192.0000 - val_loss: 894625664.0000\n",
      "Epoch 631/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 133057912.0000 - val_loss: 937930880.0000\n",
      "Epoch 632/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 197040656.0000 - val_loss: 894549248.0000\n",
      "Epoch 633/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 139009552.0000 - val_loss: 883328384.0000\n",
      "Epoch 634/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 120447464.0000 - val_loss: 882484608.0000\n",
      "Epoch 635/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 118299256.0000 - val_loss: 881512832.0000\n",
      "Epoch 636/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 122368352.0000 - val_loss: 889315904.0000\n",
      "Epoch 637/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 128586080.0000 - val_loss: 887656960.0000\n",
      "Epoch 638/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 130398056.0000 - val_loss: 897040384.0000\n",
      "Epoch 639/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 127701608.0000 - val_loss: 887206976.0000\n",
      "Epoch 640/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 117509472.0000 - val_loss: 883480640.0000\n",
      "Epoch 641/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 116427032.0000 - val_loss: 888040384.0000\n",
      "Epoch 642/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 122277072.0000 - val_loss: 900630144.0000\n",
      "Epoch 643/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 149036576.0000 - val_loss: 902521024.0000\n",
      "Epoch 644/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 155681296.0000 - val_loss: 902834944.0000\n",
      "Epoch 645/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 126051664.0000 - val_loss: 884090048.0000\n",
      "Epoch 646/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 116772328.0000 - val_loss: 883608512.0000\n",
      "Epoch 647/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 115829440.0000 - val_loss: 878797248.0000\n",
      "Epoch 648/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 114151984.0000 - val_loss: 882650560.0000\n",
      "Epoch 649/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 114065184.0000 - val_loss: 875594944.0000\n",
      "Epoch 650/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 113908176.0000 - val_loss: 885860288.0000\n",
      "Epoch 651/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 114563072.0000 - val_loss: 885458624.0000\n",
      "Epoch 652/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 125730144.0000 - val_loss: 921080384.0000\n",
      "Epoch 653/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 158038512.0000 - val_loss: 888765696.0000\n",
      "Epoch 654/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 138118976.0000 - val_loss: 900544128.0000\n",
      "Epoch 655/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 118712416.0000 - val_loss: 887515072.0000\n",
      "Epoch 656/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 112803728.0000 - val_loss: 893166912.0000\n",
      "Epoch 657/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 111449888.0000 - val_loss: 884100736.0000\n",
      "Epoch 658/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 111212304.0000 - val_loss: 880487168.0000\n",
      "Epoch 659/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 113439896.0000 - val_loss: 882631680.0000\n",
      "Epoch 660/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 119598696.0000 - val_loss: 896385536.0000\n",
      "Epoch 661/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 142152480.0000 - val_loss: 900193856.0000\n",
      "Epoch 662/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 145138544.0000 - val_loss: 895487232.0000\n",
      "Epoch 663/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 146696848.0000 - val_loss: 900968384.0000\n",
      "Epoch 664/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 130376496.0000 - val_loss: 888016320.0000\n",
      "Epoch 665/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 115741512.0000 - val_loss: 883826816.0000\n",
      "Epoch 666/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 108800888.0000 - val_loss: 889036992.0000\n",
      "Epoch 667/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 108893776.0000 - val_loss: 885311680.0000\n",
      "Epoch 668/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 108041456.0000 - val_loss: 884244672.0000\n",
      "Epoch 669/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 112570976.0000 - val_loss: 888901568.0000\n",
      "Epoch 670/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 117316312.0000 - val_loss: 905822784.0000\n",
      "Epoch 671/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 120859096.0000 - val_loss: 892689216.0000\n",
      "Epoch 672/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 122788216.0000 - val_loss: 922459136.0000\n",
      "Epoch 673/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 127957240.0000 - val_loss: 892690048.0000\n",
      "Epoch 674/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 110969424.0000 - val_loss: 893708416.0000\n",
      "Epoch 675/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 108790320.0000 - val_loss: 884167936.0000\n",
      "Epoch 676/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 106188856.0000 - val_loss: 881662464.0000\n",
      "Epoch 677/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 112925584.0000 - val_loss: 919967360.0000\n",
      "Epoch 678/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 151383808.0000 - val_loss: 896222976.0000\n",
      "Epoch 679/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 116609008.0000 - val_loss: 898053440.0000\n",
      "Epoch 680/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 118043272.0000 - val_loss: 894040448.0000\n",
      "Epoch 681/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 109432296.0000 - val_loss: 884649216.0000\n",
      "Epoch 682/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 105988616.0000 - val_loss: 893517376.0000\n",
      "Epoch 683/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 112087256.0000 - val_loss: 891647040.0000\n",
      "Epoch 684/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 106716088.0000 - val_loss: 882405760.0000\n",
      "Epoch 685/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 103687760.0000 - val_loss: 887715776.0000\n",
      "Epoch 686/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 103814272.0000 - val_loss: 884364032.0000\n",
      "Epoch 687/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 103452160.0000 - val_loss: 887981376.0000\n",
      "Epoch 688/2000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 105189304.0000 - val_loss: 877273024.0000\n",
      "Epoch 689/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 127416672.0000 - val_loss: 932309312.0000\n",
      "Epoch 690/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 150172400.0000 - val_loss: 879634240.0000\n",
      "Epoch 691/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 102864560.0000 - val_loss: 882724928.0000\n",
      "Epoch 692/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 102700944.0000 - val_loss: 886532928.0000\n",
      "Epoch 693/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 103517424.0000 - val_loss: 887727040.0000\n",
      "Epoch 694/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 100538256.0000 - val_loss: 884430528.0000\n",
      "Epoch 695/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 102087456.0000 - val_loss: 901831360.0000\n",
      "Epoch 696/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 127418144.0000 - val_loss: 908590592.0000\n",
      "Epoch 697/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 131584632.0000 - val_loss: 904548032.0000\n",
      "Epoch 698/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 68ms/step - loss: 113597144.0000 - val_loss: 886435648.0000\n",
      "Epoch 699/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 99333216.0000 - val_loss: 887019840.0000\n",
      "Epoch 700/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 99019480.0000 - val_loss: 884956736.0000\n",
      "Epoch 701/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 101052120.0000 - val_loss: 883913088.0000\n",
      "Epoch 702/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 101972024.0000 - val_loss: 905569920.0000\n",
      "Epoch 703/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 123989400.0000 - val_loss: 889113856.0000\n",
      "Epoch 704/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 115667096.0000 - val_loss: 900187776.0000\n",
      "Epoch 705/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 127124600.0000 - val_loss: 891170368.0000\n",
      "Epoch 706/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 104859984.0000 - val_loss: 878128192.0000\n",
      "Epoch 707/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 96988696.0000 - val_loss: 881254592.0000\n",
      "Epoch 708/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 97342880.0000 - val_loss: 885839232.0000\n",
      "Epoch 709/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 97771872.0000 - val_loss: 902862528.0000\n",
      "Epoch 710/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 109576632.0000 - val_loss: 891948416.0000\n",
      "Epoch 711/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 98227224.0000 - val_loss: 884700992.0000\n",
      "Epoch 712/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 97805160.0000 - val_loss: 891825600.0000\n",
      "Epoch 713/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 101826432.0000 - val_loss: 894159168.0000\n",
      "Epoch 714/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 109582568.0000 - val_loss: 906747904.0000\n",
      "Epoch 715/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 137931984.0000 - val_loss: 901781248.0000\n",
      "Epoch 716/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 111927936.0000 - val_loss: 880085120.0000\n",
      "Epoch 717/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 99628216.0000 - val_loss: 886032192.0000\n",
      "Epoch 718/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 121988616.0000 - val_loss: 906005056.0000\n",
      "Epoch 719/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 112408240.0000 - val_loss: 876945408.0000\n",
      "Epoch 720/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 93996664.0000 - val_loss: 877130240.0000\n",
      "Epoch 721/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 96101392.0000 - val_loss: 886539904.0000\n",
      "Epoch 722/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 113180672.0000 - val_loss: 907023808.0000\n",
      "Epoch 723/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 127888080.0000 - val_loss: 896017280.0000\n",
      "Epoch 724/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 103707032.0000 - val_loss: 882386752.0000\n",
      "Epoch 725/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 93660696.0000 - val_loss: 876525376.0000\n",
      "Epoch 726/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 92273728.0000 - val_loss: 882900352.0000\n",
      "Epoch 727/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 92090960.0000 - val_loss: 883090176.0000\n",
      "Epoch 728/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 93381704.0000 - val_loss: 878266176.0000\n",
      "Epoch 729/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 93394656.0000 - val_loss: 881201664.0000\n",
      "Epoch 730/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 92594728.0000 - val_loss: 885888704.0000\n",
      "Epoch 731/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 91873224.0000 - val_loss: 879353920.0000\n",
      "Epoch 732/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 91932488.0000 - val_loss: 881948992.0000\n",
      "Epoch 733/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 122609512.0000 - val_loss: 928429056.0000\n",
      "Epoch 734/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 126198848.0000 - val_loss: 871167168.0000\n",
      "Epoch 735/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 90540704.0000 - val_loss: 880461504.0000\n",
      "Epoch 736/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 113238336.0000 - val_loss: 927640192.0000\n",
      "Epoch 737/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 125728528.0000 - val_loss: 886910848.0000\n",
      "Epoch 738/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 94035456.0000 - val_loss: 888518912.0000\n",
      "Epoch 739/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 97418448.0000 - val_loss: 879002432.0000\n",
      "Epoch 740/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 88398584.0000 - val_loss: 875806720.0000\n",
      "Epoch 741/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 92952416.0000 - val_loss: 877814272.0000\n",
      "Epoch 742/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 91954856.0000 - val_loss: 877642560.0000\n",
      "Epoch 743/2000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 95928096.0000 - val_loss: 902937088.0000\n",
      "Epoch 744/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 111338312.0000 - val_loss: 885096576.0000\n",
      "Epoch 745/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 97999432.0000 - val_loss: 881669568.0000\n",
      "Epoch 746/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 94242696.0000 - val_loss: 878643904.0000\n",
      "Epoch 747/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 88930368.0000 - val_loss: 874708032.0000\n",
      "Epoch 748/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 102295320.0000 - val_loss: 914534080.0000\n",
      "Epoch 749/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 104563648.0000 - val_loss: 888296832.0000\n",
      "Epoch 750/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 99029680.0000 - val_loss: 905763456.0000\n",
      "Epoch 751/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 111135112.0000 - val_loss: 897186560.0000\n",
      "Epoch 752/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 91645000.0000 - val_loss: 890234048.0000\n",
      "Epoch 753/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 93044888.0000 - val_loss: 902857728.0000\n",
      "Epoch 754/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 97940160.0000 - val_loss: 890936128.0000\n",
      "Epoch 755/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 90285760.0000 - val_loss: 887317824.0000\n",
      "Epoch 756/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 90409240.0000 - val_loss: 889738432.0000\n",
      "Epoch 757/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 103694016.0000 - val_loss: 908617472.0000\n",
      "Epoch 758/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 108410952.0000 - val_loss: 894370816.0000\n",
      "Epoch 759/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 90370792.0000 - val_loss: 876931648.0000\n",
      "Epoch 760/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 83632984.0000 - val_loss: 879337024.0000\n",
      "Epoch 761/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 83773592.0000 - val_loss: 875655680.0000\n",
      "Epoch 762/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 83625520.0000 - val_loss: 886306240.0000\n",
      "Epoch 763/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 97426816.0000 - val_loss: 906422976.0000\n",
      "Epoch 764/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 118843576.0000 - val_loss: 892787008.0000\n",
      "Epoch 765/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 100559152.0000 - val_loss: 875076224.0000\n",
      "Epoch 766/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 82895224.0000 - val_loss: 877658496.0000\n",
      "Epoch 767/2000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 82062488.0000 - val_loss: 877412544.0000\n",
      "Epoch 768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 86408416.0000 - val_loss: 882817536.0000\n",
      "Epoch 769/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 84802088.0000 - val_loss: 870268096.0000\n",
      "Epoch 770/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 85422264.0000 - val_loss: 885253312.0000\n",
      "Epoch 771/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 124565904.0000 - val_loss: 912010432.0000\n",
      "Epoch 772/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 127375688.0000 - val_loss: 890509696.0000\n",
      "Epoch 773/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 98979104.0000 - val_loss: 878977600.0000\n",
      "Epoch 774/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 90540072.0000 - val_loss: 882563584.0000\n",
      "Epoch 775/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 89265072.0000 - val_loss: 871377152.0000\n",
      "Epoch 776/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 82751208.0000 - val_loss: 872710016.0000\n",
      "Epoch 777/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 81971016.0000 - val_loss: 874348864.0000\n",
      "Epoch 778/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 85361232.0000 - val_loss: 877363136.0000\n",
      "Epoch 779/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 87460600.0000 - val_loss: 875394368.0000\n",
      "Epoch 780/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 93275320.0000 - val_loss: 883281920.0000\n",
      "Epoch 781/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 116351200.0000 - val_loss: 890192384.0000\n",
      "Epoch 782/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 97406624.0000 - val_loss: 868120192.0000\n",
      "Epoch 783/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 83583480.0000 - val_loss: 876262144.0000\n",
      "Epoch 784/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 83859440.0000 - val_loss: 869147136.0000\n",
      "Epoch 785/2000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 78730856.0000 - val_loss: 891195456.0000\n",
      "Epoch 786/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 104816488.0000 - val_loss: 894072640.0000\n",
      "Epoch 787/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 101525768.0000 - val_loss: 889891136.0000\n",
      "Epoch 788/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 100421656.0000 - val_loss: 887978688.0000\n",
      "Epoch 789/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 84578760.0000 - val_loss: 879782400.0000\n",
      "Epoch 790/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 77865776.0000 - val_loss: 875127168.0000\n",
      "Epoch 791/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 77244600.0000 - val_loss: 876074496.0000\n",
      "Epoch 792/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 82978032.0000 - val_loss: 888067840.0000\n",
      "Epoch 793/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 104949552.0000 - val_loss: 900270464.0000\n",
      "Epoch 794/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 111468664.0000 - val_loss: 880256448.0000\n",
      "Epoch 795/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 79951888.0000 - val_loss: 870516352.0000\n",
      "Epoch 796/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 77324048.0000 - val_loss: 873445184.0000\n",
      "Epoch 797/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 76292232.0000 - val_loss: 873910720.0000\n",
      "Epoch 798/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 78045536.0000 - val_loss: 874822912.0000\n",
      "Epoch 799/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 93442448.0000 - val_loss: 893048960.0000\n",
      "Epoch 800/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 104636096.0000 - val_loss: 892779584.0000\n",
      "Epoch 801/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 94261936.0000 - val_loss: 869991936.0000\n",
      "Epoch 802/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 76597680.0000 - val_loss: 871868928.0000\n",
      "Epoch 803/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 79452920.0000 - val_loss: 886539136.0000\n",
      "Epoch 804/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 84269104.0000 - val_loss: 892447936.0000\n",
      "Epoch 805/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 94971600.0000 - val_loss: 888764224.0000\n",
      "Epoch 806/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 79410272.0000 - val_loss: 870868352.0000\n",
      "Epoch 807/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 74707424.0000 - val_loss: 875475584.0000\n",
      "Epoch 808/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 74425720.0000 - val_loss: 874860416.0000\n",
      "Epoch 809/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 86260720.0000 - val_loss: 934888000.0000\n",
      "Epoch 810/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 140693024.0000 - val_loss: 887531328.0000\n",
      "Epoch 811/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 83850488.0000 - val_loss: 868241728.0000\n",
      "Epoch 812/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 75123256.0000 - val_loss: 869760384.0000\n",
      "Epoch 813/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 77359960.0000 - val_loss: 873674112.0000\n",
      "Epoch 814/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 81919736.0000 - val_loss: 877169472.0000\n",
      "Epoch 815/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 82580312.0000 - val_loss: 882628992.0000\n",
      "Epoch 816/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 74917000.0000 - val_loss: 875586560.0000\n",
      "Epoch 817/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 80341432.0000 - val_loss: 890790720.0000\n",
      "Epoch 818/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 103850504.0000 - val_loss: 876411008.0000\n",
      "Epoch 819/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 78384792.0000 - val_loss: 865939584.0000\n",
      "Epoch 820/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 74186000.0000 - val_loss: 874835072.0000\n",
      "Epoch 821/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 71875704.0000 - val_loss: 878834112.0000\n",
      "Epoch 822/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 71372128.0000 - val_loss: 873608704.0000\n",
      "Epoch 823/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 70940592.0000 - val_loss: 870035456.0000\n",
      "Epoch 824/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 74319544.0000 - val_loss: 901779584.0000\n",
      "Epoch 825/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 105712680.0000 - val_loss: 911729984.0000\n",
      "Epoch 826/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 119017472.0000 - val_loss: 902699968.0000\n",
      "Epoch 827/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 83552360.0000 - val_loss: 878764416.0000\n",
      "Epoch 828/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 73498760.0000 - val_loss: 880231168.0000\n",
      "Epoch 829/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 72509800.0000 - val_loss: 872775680.0000\n",
      "Epoch 830/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 71512968.0000 - val_loss: 879062464.0000\n",
      "Epoch 831/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 84941488.0000 - val_loss: 883624128.0000\n",
      "Epoch 832/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 86165040.0000 - val_loss: 873027392.0000\n",
      "Epoch 833/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 81248584.0000 - val_loss: 883925056.0000\n",
      "Epoch 834/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 79350248.0000 - val_loss: 867605632.0000\n",
      "Epoch 835/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 74363272.0000 - val_loss: 875846336.0000\n",
      "Epoch 836/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 88461352.0000 - val_loss: 893968064.0000\n",
      "Epoch 837/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 79066776.0000 - val_loss: 872154944.0000\n",
      "Epoch 838/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 68015160.0000 - val_loss: 870297728.0000\n",
      "Epoch 839/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 68346560.0000 - val_loss: 871325760.0000\n",
      "Epoch 840/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 68597168.0000 - val_loss: 878808448.0000\n",
      "Epoch 841/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 79733952.0000 - val_loss: 896740480.0000\n",
      "Epoch 842/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 95132112.0000 - val_loss: 873017280.0000\n",
      "Epoch 843/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 79398160.0000 - val_loss: 870534528.0000\n",
      "Epoch 844/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 68376568.0000 - val_loss: 867478784.0000\n",
      "Epoch 845/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 71609048.0000 - val_loss: 893807360.0000\n",
      "Epoch 846/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 106073520.0000 - val_loss: 891574592.0000\n",
      "Epoch 847/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 89423384.0000 - val_loss: 866735360.0000\n",
      "Epoch 848/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 68926232.0000 - val_loss: 872162752.0000\n",
      "Epoch 849/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 66521636.0000 - val_loss: 871180160.0000\n",
      "Epoch 850/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 66227820.0000 - val_loss: 869809728.0000\n",
      "Epoch 851/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 65998256.0000 - val_loss: 870123264.0000\n",
      "Epoch 852/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 71728488.0000 - val_loss: 905729536.0000\n",
      "Epoch 853/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 102469184.0000 - val_loss: 904277376.0000\n",
      "Epoch 854/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 93400824.0000 - val_loss: 889764416.0000\n",
      "Epoch 855/2000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 71135304.0000 - val_loss: 873838976.0000\n",
      "Epoch 856/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 65068952.0000 - val_loss: 875057536.0000\n",
      "Epoch 857/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 65151500.0000 - val_loss: 873291264.0000\n",
      "Epoch 858/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 65858792.0000 - val_loss: 880709696.0000\n",
      "Epoch 859/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 67379704.0000 - val_loss: 880642304.0000\n",
      "Epoch 860/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 71925952.0000 - val_loss: 899333120.0000\n",
      "Epoch 861/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 98651408.0000 - val_loss: 901442048.0000\n",
      "Epoch 862/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 86819192.0000 - val_loss: 891904960.0000\n",
      "Epoch 863/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 75465488.0000 - val_loss: 878098944.0000\n",
      "Epoch 864/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 65648184.0000 - val_loss: 872299712.0000\n",
      "Epoch 865/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 66286272.0000 - val_loss: 879014976.0000\n",
      "Epoch 866/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 77128584.0000 - val_loss: 891707200.0000\n",
      "Epoch 867/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 90107184.0000 - val_loss: 886965568.0000\n",
      "Epoch 868/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 88229224.0000 - val_loss: 892281856.0000\n",
      "Epoch 869/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 77941800.0000 - val_loss: 875147904.0000\n",
      "Epoch 870/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 67385928.0000 - val_loss: 871630656.0000\n",
      "Epoch 871/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 63418292.0000 - val_loss: 873386560.0000\n",
      "Epoch 872/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 61781252.0000 - val_loss: 873057280.0000\n",
      "Epoch 873/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 65046872.0000 - val_loss: 892369024.0000\n",
      "Epoch 874/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 88004944.0000 - val_loss: 880956928.0000\n",
      "Epoch 875/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 74823008.0000 - val_loss: 873211968.0000\n",
      "Epoch 876/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 65365060.0000 - val_loss: 873123648.0000\n",
      "Epoch 877/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 61827760.0000 - val_loss: 883438080.0000\n",
      "Epoch 878/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 72464568.0000 - val_loss: 890705280.0000\n",
      "Epoch 879/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 72349360.0000 - val_loss: 896260032.0000\n",
      "Epoch 880/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 77448920.0000 - val_loss: 888783040.0000\n",
      "Epoch 881/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 70417008.0000 - val_loss: 884252608.0000\n",
      "Epoch 882/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 67158136.0000 - val_loss: 888693184.0000\n",
      "Epoch 883/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 83732256.0000 - val_loss: 914975936.0000\n",
      "Epoch 884/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 84880168.0000 - val_loss: 885108352.0000\n",
      "Epoch 885/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 64360816.0000 - val_loss: 876787392.0000\n",
      "Epoch 886/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 60378448.0000 - val_loss: 879047872.0000\n",
      "Epoch 887/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 63574488.0000 - val_loss: 891657216.0000\n",
      "Epoch 888/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 75777488.0000 - val_loss: 890012480.0000\n",
      "Epoch 889/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 71214696.0000 - val_loss: 891773888.0000\n",
      "Epoch 890/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 78630744.0000 - val_loss: 906121024.0000\n",
      "Epoch 891/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 81157736.0000 - val_loss: 884272128.0000\n",
      "Epoch 892/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 64691684.0000 - val_loss: 880849344.0000\n",
      "Epoch 893/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 65892976.0000 - val_loss: 886545600.0000\n",
      "Epoch 894/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 62541704.0000 - val_loss: 877199488.0000\n",
      "Epoch 895/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 63088380.0000 - val_loss: 908731840.0000\n",
      "Epoch 896/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 99480144.0000 - val_loss: 881275648.0000\n",
      "Epoch 897/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 65714708.0000 - val_loss: 871136448.0000\n",
      "Epoch 898/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 62667200.0000 - val_loss: 887558272.0000\n",
      "Epoch 899/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 77608840.0000 - val_loss: 891880704.0000\n",
      "Epoch 900/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 68695376.0000 - val_loss: 875220992.0000\n",
      "Epoch 901/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 67098048.0000 - val_loss: 888766656.0000\n",
      "Epoch 902/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 66245084.0000 - val_loss: 870709632.0000\n",
      "Epoch 903/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 62514284.0000 - val_loss: 887690880.0000\n",
      "Epoch 904/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 80973728.0000 - val_loss: 888867392.0000\n",
      "Epoch 905/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 86153232.0000 - val_loss: 890192832.0000\n",
      "Epoch 906/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 78164320.0000 - val_loss: 883968384.0000\n",
      "Epoch 907/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 63593720.0000 - val_loss: 874254912.0000\n",
      "Epoch 908/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 58241004.0000 - val_loss: 874176384.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 56224316.0000 - val_loss: 873446912.0000\n",
      "Epoch 910/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 58035088.0000 - val_loss: 881595264.0000\n",
      "Epoch 911/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 71807272.0000 - val_loss: 913820032.0000\n",
      "Epoch 912/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 86486648.0000 - val_loss: 891954688.0000\n",
      "Epoch 913/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 58026608.0000 - val_loss: 878940608.0000\n",
      "Epoch 914/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 55865368.0000 - val_loss: 877837568.0000\n",
      "Epoch 915/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 55521680.0000 - val_loss: 884736128.0000\n",
      "Epoch 916/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 55389948.0000 - val_loss: 878760576.0000\n",
      "Epoch 917/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 56838116.0000 - val_loss: 886034240.0000\n",
      "Epoch 918/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 83065560.0000 - val_loss: 908857664.0000\n",
      "Epoch 919/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 96368936.0000 - val_loss: 884898176.0000\n",
      "Epoch 920/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 60741632.0000 - val_loss: 881056768.0000\n",
      "Epoch 921/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 54760648.0000 - val_loss: 882597248.0000\n",
      "Epoch 922/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 58196128.0000 - val_loss: 890287936.0000\n",
      "Epoch 923/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 73123760.0000 - val_loss: 891469504.0000\n",
      "Epoch 924/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 91440128.0000 - val_loss: 898062592.0000\n",
      "Epoch 925/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 83463096.0000 - val_loss: 884506048.0000\n",
      "Epoch 926/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 60585236.0000 - val_loss: 875112640.0000\n",
      "Epoch 927/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 53710068.0000 - val_loss: 875683712.0000\n",
      "Epoch 928/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 56286012.0000 - val_loss: 888589952.0000\n",
      "Epoch 929/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 68094744.0000 - val_loss: 884282304.0000\n",
      "Epoch 930/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 65877884.0000 - val_loss: 879460800.0000\n",
      "Epoch 931/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 62370328.0000 - val_loss: 885327104.0000\n",
      "Epoch 932/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 65572068.0000 - val_loss: 873858560.0000\n",
      "Epoch 933/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 68026552.0000 - val_loss: 898581568.0000\n",
      "Epoch 934/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 91358768.0000 - val_loss: 885691648.0000\n",
      "Epoch 935/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 69126560.0000 - val_loss: 877806400.0000\n",
      "Epoch 936/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 54950396.0000 - val_loss: 875279808.0000\n",
      "Epoch 937/2000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 52187304.0000 - val_loss: 880793664.0000\n",
      "Epoch 938/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 53591048.0000 - val_loss: 876613824.0000\n",
      "Epoch 939/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 51860304.0000 - val_loss: 875362112.0000\n",
      "Epoch 940/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 52143524.0000 - val_loss: 882767744.0000\n",
      "Epoch 941/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 59325840.0000 - val_loss: 887680000.0000\n",
      "Epoch 942/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 99361864.0000 - val_loss: 910523072.0000\n",
      "Epoch 943/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 90842280.0000 - val_loss: 882237888.0000\n",
      "Epoch 944/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 60190644.0000 - val_loss: 880085568.0000\n",
      "Epoch 945/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 58407776.0000 - val_loss: 882777600.0000\n",
      "Epoch 946/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 55877372.0000 - val_loss: 877689024.0000\n",
      "Epoch 947/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 53094024.0000 - val_loss: 881338048.0000\n",
      "Epoch 948/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 59424828.0000 - val_loss: 890277568.0000\n",
      "Epoch 949/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 72509224.0000 - val_loss: 886171840.0000\n",
      "Epoch 950/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 67654096.0000 - val_loss: 869652992.0000\n",
      "Epoch 951/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 56632824.0000 - val_loss: 874891968.0000\n",
      "Epoch 952/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 51213956.0000 - val_loss: 872470208.0000\n",
      "Epoch 953/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 49898528.0000 - val_loss: 877955328.0000\n",
      "Epoch 954/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 58615768.0000 - val_loss: 924742272.0000\n",
      "Epoch 955/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 87480672.0000 - val_loss: 896241472.0000\n",
      "Epoch 956/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 68036840.0000 - val_loss: 884759104.0000\n",
      "Epoch 957/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 51826400.0000 - val_loss: 877561536.0000\n",
      "Epoch 958/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 53537696.0000 - val_loss: 891587648.0000\n",
      "Epoch 959/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 59215228.0000 - val_loss: 877825088.0000\n",
      "Epoch 960/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 51238508.0000 - val_loss: 881299968.0000\n",
      "Epoch 961/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 54402628.0000 - val_loss: 886147456.0000\n",
      "Epoch 962/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 81241384.0000 - val_loss: 905573120.0000\n",
      "Epoch 963/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 79589224.0000 - val_loss: 875908352.0000\n",
      "Epoch 964/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 52688984.0000 - val_loss: 877189632.0000\n",
      "Epoch 965/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 49202356.0000 - val_loss: 874682752.0000\n",
      "Epoch 966/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 48192048.0000 - val_loss: 881022336.0000\n",
      "Epoch 967/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 48707092.0000 - val_loss: 887386240.0000\n",
      "Epoch 968/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 49077896.0000 - val_loss: 886473664.0000\n",
      "Epoch 969/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 47444116.0000 - val_loss: 885484544.0000\n",
      "Epoch 970/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 47808196.0000 - val_loss: 885665984.0000\n",
      "Epoch 971/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 69630224.0000 - val_loss: 951189376.0000\n",
      "Epoch 972/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 102671832.0000 - val_loss: 906609920.0000\n",
      "Epoch 973/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 63344320.0000 - val_loss: 891462912.0000\n",
      "Epoch 974/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 58504308.0000 - val_loss: 894777408.0000\n",
      "Epoch 975/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 53809420.0000 - val_loss: 884109696.0000\n",
      "Epoch 976/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 46455604.0000 - val_loss: 877426880.0000\n",
      "Epoch 977/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 46518012.0000 - val_loss: 882787520.0000\n",
      "Epoch 978/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 47392576.0000 - val_loss: 882625920.0000\n",
      "Epoch 979/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 47490588.0000 - val_loss: 876038784.0000\n",
      "Epoch 980/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 55835824.0000 - val_loss: 917338880.0000\n",
      "Epoch 981/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 96207168.0000 - val_loss: 886973824.0000\n",
      "Epoch 982/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 58481088.0000 - val_loss: 880922112.0000\n",
      "Epoch 983/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 47497888.0000 - val_loss: 877575104.0000\n",
      "Epoch 984/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 46000468.0000 - val_loss: 881731776.0000\n",
      "Epoch 985/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 47140004.0000 - val_loss: 882560704.0000\n",
      "Epoch 986/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 47360552.0000 - val_loss: 900259392.0000\n",
      "Epoch 987/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 57384624.0000 - val_loss: 919694976.0000\n",
      "Epoch 988/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 68073336.0000 - val_loss: 893339392.0000\n",
      "Epoch 989/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 59543868.0000 - val_loss: 905970048.0000\n",
      "Epoch 990/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 65616756.0000 - val_loss: 912860480.0000\n",
      "Epoch 991/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 69846120.0000 - val_loss: 901667200.0000\n",
      "Epoch 992/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 59278420.0000 - val_loss: 898682560.0000\n",
      "Epoch 993/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 51718432.0000 - val_loss: 886562816.0000\n",
      "Epoch 994/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 47394996.0000 - val_loss: 888663680.0000\n",
      "Epoch 995/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 44775956.0000 - val_loss: 880901568.0000\n",
      "Epoch 996/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 45849508.0000 - val_loss: 891012160.0000\n",
      "Epoch 997/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 58379956.0000 - val_loss: 896165376.0000\n",
      "Epoch 998/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 58459596.0000 - val_loss: 879206208.0000\n",
      "Epoch 999/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 51272472.0000 - val_loss: 899681536.0000\n",
      "Epoch 1000/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 67899312.0000 - val_loss: 897109824.0000\n",
      "Epoch 1001/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 65497600.0000 - val_loss: 883346112.0000\n",
      "Epoch 1002/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 51196528.0000 - val_loss: 877452736.0000\n",
      "Epoch 1003/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 44706780.0000 - val_loss: 877946688.0000\n",
      "Epoch 1004/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 43962684.0000 - val_loss: 882637632.0000\n",
      "Epoch 1005/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 46844956.0000 - val_loss: 884047744.0000\n",
      "Epoch 1006/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 55022820.0000 - val_loss: 902238528.0000\n",
      "Epoch 1007/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 69931032.0000 - val_loss: 883372672.0000\n",
      "Epoch 1008/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 47194192.0000 - val_loss: 878206656.0000\n",
      "Epoch 1009/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 42840928.0000 - val_loss: 883194944.0000\n",
      "Epoch 1010/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 43376412.0000 - val_loss: 885848768.0000\n",
      "Epoch 1011/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 45696048.0000 - val_loss: 900841856.0000\n",
      "Epoch 1012/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 67492848.0000 - val_loss: 928807552.0000\n",
      "Epoch 1013/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 70595344.0000 - val_loss: 904769344.0000\n",
      "Epoch 1014/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 48366792.0000 - val_loss: 892413760.0000\n",
      "Epoch 1015/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 45094040.0000 - val_loss: 887973120.0000\n",
      "Epoch 1016/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 42969852.0000 - val_loss: 888940032.0000\n",
      "Epoch 1017/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 48970844.0000 - val_loss: 911168768.0000\n",
      "Epoch 1018/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 71999472.0000 - val_loss: 919866560.0000\n",
      "Epoch 1019/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 61200748.0000 - val_loss: 891367232.0000\n",
      "Epoch 1020/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 49561880.0000 - val_loss: 895460736.0000\n",
      "Epoch 1021/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 48645028.0000 - val_loss: 891482176.0000\n",
      "Epoch 1022/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 45353892.0000 - val_loss: 895026048.0000\n",
      "Epoch 1023/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 50355228.0000 - val_loss: 911514880.0000\n",
      "Epoch 1024/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 71160304.0000 - val_loss: 906931648.0000\n",
      "Epoch 1025/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 50588948.0000 - val_loss: 888898752.0000\n",
      "Epoch 1026/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 40708244.0000 - val_loss: 885971072.0000\n",
      "Epoch 1027/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 39988516.0000 - val_loss: 881477120.0000\n",
      "Epoch 1028/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 40489388.0000 - val_loss: 888698752.0000\n",
      "Epoch 1029/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 50889528.0000 - val_loss: 927030528.0000\n",
      "Epoch 1030/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 91493720.0000 - val_loss: 914307136.0000\n",
      "Epoch 1031/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 50104016.0000 - val_loss: 889265216.0000\n",
      "Epoch 1032/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 41303048.0000 - val_loss: 893980160.0000\n",
      "Epoch 1033/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 46029200.0000 - val_loss: 902222784.0000\n",
      "Epoch 1034/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 50163608.0000 - val_loss: 904784192.0000\n",
      "Epoch 1035/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 58623612.0000 - val_loss: 930830208.0000\n",
      "Epoch 1036/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 75917280.0000 - val_loss: 902250688.0000\n",
      "Epoch 1037/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 52323468.0000 - val_loss: 896233664.0000\n",
      "Epoch 1038/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 40896076.0000 - val_loss: 888942208.0000\n",
      "Epoch 1039/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 39445052.0000 - val_loss: 893238848.0000\n",
      "Epoch 1040/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 39306848.0000 - val_loss: 887155200.0000\n",
      "Epoch 1041/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 38983764.0000 - val_loss: 885321280.0000\n",
      "Epoch 1042/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 40573236.0000 - val_loss: 911079616.0000\n",
      "Epoch 1043/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 65467468.0000 - val_loss: 923192960.0000\n",
      "Epoch 1044/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 78433208.0000 - val_loss: 904576192.0000\n",
      "Epoch 1045/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 60941792.0000 - val_loss: 893802688.0000\n",
      "Epoch 1046/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 42952124.0000 - val_loss: 888388096.0000\n",
      "Epoch 1047/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 47815412.0000 - val_loss: 919850432.0000\n",
      "Epoch 1048/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 59699228.0000 - val_loss: 902492480.0000\n",
      "Epoch 1049/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 40312964.0000 - val_loss: 892717824.0000\n",
      "Epoch 1050/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 37964240.0000 - val_loss: 893113728.0000\n",
      "Epoch 1051/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 38550472.0000 - val_loss: 895123392.0000\n",
      "Epoch 1052/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 43446196.0000 - val_loss: 898678144.0000\n",
      "Epoch 1053/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 64211788.0000 - val_loss: 911610688.0000\n",
      "Epoch 1054/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 71560288.0000 - val_loss: 906559168.0000\n",
      "Epoch 1055/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 55830936.0000 - val_loss: 896968960.0000\n",
      "Epoch 1056/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 38470644.0000 - val_loss: 893014208.0000\n",
      "Epoch 1057/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 37978892.0000 - val_loss: 894681600.0000\n",
      "Epoch 1058/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 40266404.0000 - val_loss: 899857152.0000\n",
      "Epoch 1059/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 43934900.0000 - val_loss: 916927936.0000\n",
      "Epoch 1060/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 57444588.0000 - val_loss: 914624896.0000\n",
      "Epoch 1061/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 47110980.0000 - val_loss: 908382848.0000\n",
      "Epoch 1062/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 42429948.0000 - val_loss: 908515264.0000\n",
      "Epoch 1063/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 47282568.0000 - val_loss: 911928960.0000\n",
      "Epoch 1064/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 55024564.0000 - val_loss: 911375168.0000\n",
      "Epoch 1065/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 53513540.0000 - val_loss: 913044800.0000\n",
      "Epoch 1066/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 50885944.0000 - val_loss: 910232576.0000\n",
      "Epoch 1067/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 40570304.0000 - val_loss: 901548736.0000\n",
      "Epoch 1068/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 36205756.0000 - val_loss: 897699328.0000\n",
      "Epoch 1069/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 38918388.0000 - val_loss: 902477952.0000\n",
      "Epoch 1070/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 53392224.0000 - val_loss: 942110080.0000\n",
      "Epoch 1071/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 83682928.0000 - val_loss: 917531456.0000\n",
      "Epoch 1072/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 53840932.0000 - val_loss: 895410304.0000\n",
      "Epoch 1073/2000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 42121340.0000 - val_loss: 897620160.0000\n",
      "Epoch 1074/2000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 42212476.0000 - val_loss: 897017280.0000\n",
      "Epoch 1075/2000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 36666020.0000 - val_loss: 892828672.0000\n",
      "Epoch 1076/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 34864596.0000 - val_loss: 889989696.0000\n",
      "Epoch 1077/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 34985604.0000 - val_loss: 886300800.0000\n",
      "Epoch 1078/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 35382192.0000 - val_loss: 893612992.0000\n",
      "Epoch 1079/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 43643424.0000 - val_loss: 919999232.0000\n",
      "Epoch 1080/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 64901336.0000 - val_loss: 932737472.0000\n",
      "Epoch 1081/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 72993048.0000 - val_loss: 900624064.0000\n",
      "Epoch 1082/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 47175368.0000 - val_loss: 895492032.0000\n",
      "Epoch 1083/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 36402468.0000 - val_loss: 892238592.0000\n",
      "Epoch 1084/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 34289852.0000 - val_loss: 894755264.0000\n",
      "Epoch 1085/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 35545880.0000 - val_loss: 901331072.0000\n",
      "Epoch 1086/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 42854036.0000 - val_loss: 919974528.0000\n",
      "Epoch 1087/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 56976468.0000 - val_loss: 926641728.0000\n",
      "Epoch 1088/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 51914388.0000 - val_loss: 903780288.0000\n",
      "Epoch 1089/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 35812748.0000 - val_loss: 898556032.0000\n",
      "Epoch 1090/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 34151716.0000 - val_loss: 892636096.0000\n",
      "Epoch 1091/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33712716.0000 - val_loss: 895504576.0000\n",
      "Epoch 1092/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 37570444.0000 - val_loss: 917651968.0000\n",
      "Epoch 1093/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 55358372.0000 - val_loss: 927445440.0000\n",
      "Epoch 1094/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 84029552.0000 - val_loss: 932991552.0000\n",
      "Epoch 1095/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 59272980.0000 - val_loss: 905614528.0000\n",
      "Epoch 1096/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 34946308.0000 - val_loss: 894839104.0000\n",
      "Epoch 1097/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 32808392.0000 - val_loss: 892803456.0000\n",
      "Epoch 1098/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 33010600.0000 - val_loss: 900721920.0000\n",
      "Epoch 1099/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 33114306.0000 - val_loss: 894994240.0000\n",
      "Epoch 1100/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 32838554.0000 - val_loss: 901139840.0000\n",
      "Epoch 1101/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 33418896.0000 - val_loss: 905136256.0000\n",
      "Epoch 1102/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 42295808.0000 - val_loss: 916912960.0000\n",
      "Epoch 1103/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 80234888.0000 - val_loss: 911166720.0000\n",
      "Epoch 1104/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 53419272.0000 - val_loss: 896906048.0000\n",
      "Epoch 1105/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 34569524.0000 - val_loss: 890596416.0000\n",
      "Epoch 1106/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 32005580.0000 - val_loss: 895471168.0000\n",
      "Epoch 1107/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 32855664.0000 - val_loss: 904985856.0000\n",
      "Epoch 1108/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 40302216.0000 - val_loss: 911869568.0000\n",
      "Epoch 1109/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 57475548.0000 - val_loss: 935247552.0000\n",
      "Epoch 1110/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 48839632.0000 - val_loss: 912287360.0000\n",
      "Epoch 1111/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 39358388.0000 - val_loss: 906153856.0000\n",
      "Epoch 1112/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 41286136.0000 - val_loss: 915132416.0000\n",
      "Epoch 1113/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 48830248.0000 - val_loss: 907560768.0000\n",
      "Epoch 1114/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 45092828.0000 - val_loss: 913200000.0000\n",
      "Epoch 1115/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 43278476.0000 - val_loss: 910887296.0000\n",
      "Epoch 1116/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 43080028.0000 - val_loss: 907012352.0000\n",
      "Epoch 1117/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 37495264.0000 - val_loss: 904045824.0000\n",
      "Epoch 1118/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 37584532.0000 - val_loss: 912095040.0000\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 55293552.0000 - val_loss: 931643072.0000\n",
      "Epoch 1120/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 59194276.0000 - val_loss: 920375744.0000\n",
      "Epoch 1121/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 38126568.0000 - val_loss: 904119552.0000\n",
      "Epoch 1122/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 33561044.0000 - val_loss: 904273024.0000\n",
      "Epoch 1123/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 42020760.0000 - val_loss: 914846592.0000\n",
      "Epoch 1124/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 35018700.0000 - val_loss: 907684992.0000\n",
      "Epoch 1125/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 30955348.0000 - val_loss: 901058752.0000\n",
      "Epoch 1126/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 31198138.0000 - val_loss: 905312640.0000\n",
      "Epoch 1127/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 31680826.0000 - val_loss: 909865152.0000\n",
      "Epoch 1128/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 44310716.0000 - val_loss: 980174464.0000\n",
      "Epoch 1129/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 89983152.0000 - val_loss: 909483648.0000\n",
      "Epoch 1130/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 37689896.0000 - val_loss: 904324288.0000\n",
      "Epoch 1131/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 31861370.0000 - val_loss: 901866880.0000\n",
      "Epoch 1132/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 30172702.0000 - val_loss: 902746112.0000\n",
      "Epoch 1133/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 29893456.0000 - val_loss: 903270592.0000\n",
      "Epoch 1134/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 36079840.0000 - val_loss: 917856576.0000\n",
      "Epoch 1135/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 47926396.0000 - val_loss: 918786944.0000\n",
      "Epoch 1136/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 48220764.0000 - val_loss: 915368896.0000\n",
      "Epoch 1137/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 58124912.0000 - val_loss: 919284992.0000\n",
      "Epoch 1138/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 49319172.0000 - val_loss: 909215552.0000\n",
      "Epoch 1139/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 34936004.0000 - val_loss: 906609408.0000\n",
      "Epoch 1140/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 31750888.0000 - val_loss: 902163264.0000\n",
      "Epoch 1141/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 30287584.0000 - val_loss: 910837504.0000\n",
      "Epoch 1142/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 31350946.0000 - val_loss: 909886464.0000\n",
      "Epoch 1143/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 34345268.0000 - val_loss: 924024512.0000\n",
      "Epoch 1144/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 51737312.0000 - val_loss: 950479168.0000\n",
      "Epoch 1145/2000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 56800768.0000 - val_loss: 929180032.0000\n",
      "Epoch 1146/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 46979080.0000 - val_loss: 913609216.0000\n",
      "Epoch 1147/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 40259404.0000 - val_loss: 915480896.0000\n",
      "Epoch 1148/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 46999248.0000 - val_loss: 926303744.0000\n",
      "Epoch 1149/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 40235156.0000 - val_loss: 915090944.0000\n",
      "Epoch 1150/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 33756780.0000 - val_loss: 917800768.0000\n",
      "Epoch 1151/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 38770240.0000 - val_loss: 920208448.0000\n",
      "Epoch 1152/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 41595116.0000 - val_loss: 918727872.0000\n",
      "Epoch 1153/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 42565284.0000 - val_loss: 916248960.0000\n",
      "Epoch 1154/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 41347136.0000 - val_loss: 917484160.0000\n",
      "Epoch 1155/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 42740092.0000 - val_loss: 923279552.0000\n",
      "Epoch 1156/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 50867536.0000 - val_loss: 919197952.0000\n",
      "Epoch 1157/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 41466748.0000 - val_loss: 901312960.0000\n",
      "Epoch 1158/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 31758566.0000 - val_loss: 907936704.0000\n",
      "Epoch 1159/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 29012662.0000 - val_loss: 902470400.0000\n",
      "Epoch 1160/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 28041840.0000 - val_loss: 902885184.0000\n",
      "Epoch 1161/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 28940256.0000 - val_loss: 914727552.0000\n",
      "Epoch 1162/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 30252944.0000 - val_loss: 917801152.0000\n",
      "Epoch 1163/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 36179920.0000 - val_loss: 944914240.0000\n",
      "Epoch 1164/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 75993928.0000 - val_loss: 934605184.0000\n",
      "Epoch 1165/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 47369672.0000 - val_loss: 904952384.0000\n",
      "Epoch 1166/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 30961732.0000 - val_loss: 905449024.0000\n",
      "Epoch 1167/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28634960.0000 - val_loss: 902161920.0000\n",
      "Epoch 1168/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 28782434.0000 - val_loss: 916463488.0000\n",
      "Epoch 1169/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 46552416.0000 - val_loss: 944027072.0000\n",
      "Epoch 1170/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 54642540.0000 - val_loss: 914831872.0000\n",
      "Epoch 1171/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 30910708.0000 - val_loss: 904190720.0000\n",
      "Epoch 1172/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 29451010.0000 - val_loss: 911657664.0000\n",
      "Epoch 1173/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 30985890.0000 - val_loss: 913251328.0000\n",
      "Epoch 1174/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 40762172.0000 - val_loss: 942590144.0000\n",
      "Epoch 1175/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 68429096.0000 - val_loss: 918482816.0000\n",
      "Epoch 1176/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 42850108.0000 - val_loss: 911035456.0000\n",
      "Epoch 1177/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 30665658.0000 - val_loss: 909486208.0000\n",
      "Epoch 1178/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 26969262.0000 - val_loss: 905664448.0000\n",
      "Epoch 1179/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 27144908.0000 - val_loss: 905278208.0000\n",
      "Epoch 1180/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 26907280.0000 - val_loss: 905087360.0000\n",
      "Epoch 1181/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 25763970.0000 - val_loss: 904068736.0000\n",
      "Epoch 1182/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 26752134.0000 - val_loss: 915005056.0000\n",
      "Epoch 1183/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 49652900.0000 - val_loss: 919591424.0000\n",
      "Epoch 1184/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 86921480.0000 - val_loss: 918747392.0000\n",
      "Epoch 1185/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 40724244.0000 - val_loss: 899235520.0000\n",
      "Epoch 1186/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 26072296.0000 - val_loss: 901099328.0000\n",
      "Epoch 1187/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 25644958.0000 - val_loss: 903793920.0000\n",
      "Epoch 1188/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 25655496.0000 - val_loss: 907893696.0000\n",
      "Epoch 1189/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 26268966.0000 - val_loss: 911643200.0000\n",
      "Epoch 1190/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 34867676.0000 - val_loss: 947438336.0000\n",
      "Epoch 1191/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 56928580.0000 - val_loss: 911317248.0000\n",
      "Epoch 1192/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 31945756.0000 - val_loss: 901278400.0000\n",
      "Epoch 1193/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 31909964.0000 - val_loss: 918637696.0000\n",
      "Epoch 1194/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 36664232.0000 - val_loss: 921391168.0000\n",
      "Epoch 1195/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 41020284.0000 - val_loss: 938031744.0000\n",
      "Epoch 1196/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 44114208.0000 - val_loss: 925477440.0000\n",
      "Epoch 1197/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 39061828.0000 - val_loss: 915222592.0000\n",
      "Epoch 1198/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 36985448.0000 - val_loss: 917062208.0000\n",
      "Epoch 1199/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33685380.0000 - val_loss: 919706432.0000\n",
      "Epoch 1200/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 26220102.0000 - val_loss: 909256512.0000\n",
      "Epoch 1201/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 24592770.0000 - val_loss: 907217024.0000\n",
      "Epoch 1202/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 26980978.0000 - val_loss: 918772800.0000\n",
      "Epoch 1203/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 41669260.0000 - val_loss: 953520896.0000\n",
      "Epoch 1204/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 65001128.0000 - val_loss: 931336576.0000\n",
      "Epoch 1205/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 39311968.0000 - val_loss: 904315712.0000\n",
      "Epoch 1206/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 26536388.0000 - val_loss: 907287552.0000\n",
      "Epoch 1207/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 26164778.0000 - val_loss: 910851200.0000\n",
      "Epoch 1208/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 27438056.0000 - val_loss: 917985600.0000\n",
      "Epoch 1209/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 40575040.0000 - val_loss: 945694848.0000\n",
      "Epoch 1210/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 53516168.0000 - val_loss: 924147648.0000\n",
      "Epoch 1211/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 36740988.0000 - val_loss: 917963712.0000\n",
      "Epoch 1212/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 31267652.0000 - val_loss: 915583296.0000\n",
      "Epoch 1213/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 27343072.0000 - val_loss: 912930240.0000\n",
      "Epoch 1214/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 27755492.0000 - val_loss: 915497472.0000\n",
      "Epoch 1215/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 41233956.0000 - val_loss: 935238144.0000\n",
      "Epoch 1216/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 51592532.0000 - val_loss: 936478400.0000\n",
      "Epoch 1217/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 42595348.0000 - val_loss: 915849024.0000\n",
      "Epoch 1218/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25970050.0000 - val_loss: 907672832.0000\n",
      "Epoch 1219/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 23765052.0000 - val_loss: 909240576.0000\n",
      "Epoch 1220/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 23998646.0000 - val_loss: 909810432.0000\n",
      "Epoch 1221/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28336258.0000 - val_loss: 917882944.0000\n",
      "Epoch 1222/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 45988704.0000 - val_loss: 930331648.0000\n",
      "Epoch 1223/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 70789016.0000 - val_loss: 899527104.0000\n",
      "Epoch 1224/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 39362172.0000 - val_loss: 909774784.0000\n",
      "Epoch 1225/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 27876932.0000 - val_loss: 904110272.0000\n",
      "Epoch 1226/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 23407392.0000 - val_loss: 906642496.0000\n",
      "Epoch 1227/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 27972304.0000 - val_loss: 909170816.0000\n",
      "Epoch 1228/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33157742.0000 - val_loss: 904383488.0000\n",
      "Epoch 1229/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 37547508.0000 - val_loss: 923610816.0000\n",
      "Epoch 1230/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 44659340.0000 - val_loss: 914089024.0000\n",
      "Epoch 1231/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 40798260.0000 - val_loss: 921308416.0000\n",
      "Epoch 1232/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 35931104.0000 - val_loss: 919157824.0000\n",
      "Epoch 1233/2000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 30453518.0000 - val_loss: 916976192.0000\n",
      "Epoch 1234/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 26157980.0000 - val_loss: 907618176.0000\n",
      "Epoch 1235/2000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 23179780.0000 - val_loss: 908030912.0000\n",
      "Epoch 1236/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 23323860.0000 - val_loss: 910247360.0000\n",
      "Epoch 1237/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 23916004.0000 - val_loss: 896735872.0000\n",
      "Epoch 1238/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 27103152.0000 - val_loss: 930378240.0000\n",
      "Epoch 1239/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 69412400.0000 - val_loss: 924126016.0000\n",
      "Epoch 1240/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 48079476.0000 - val_loss: 910824896.0000\n",
      "Epoch 1241/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 25193586.0000 - val_loss: 904422656.0000\n",
      "Epoch 1242/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 25453842.0000 - val_loss: 914810560.0000\n",
      "Epoch 1243/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 32590978.0000 - val_loss: 921929920.0000\n",
      "Epoch 1244/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 43798588.0000 - val_loss: 927695168.0000\n",
      "Epoch 1245/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 46014500.0000 - val_loss: 909129024.0000\n",
      "Epoch 1246/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 29368162.0000 - val_loss: 914358656.0000\n",
      "Epoch 1247/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 24856772.0000 - val_loss: 910571328.0000\n",
      "Epoch 1248/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 23648384.0000 - val_loss: 910842176.0000\n",
      "Epoch 1249/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 23156990.0000 - val_loss: 914728192.0000\n",
      "Epoch 1250/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 22118410.0000 - val_loss: 911877504.0000\n",
      "Epoch 1251/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 22068028.0000 - val_loss: 911567040.0000\n",
      "Epoch 1252/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 22847158.0000 - val_loss: 912888768.0000\n",
      "Epoch 1253/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 37668824.0000 - val_loss: 952324288.0000\n",
      "Epoch 1254/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 67384984.0000 - val_loss: 926024960.0000\n",
      "Epoch 1255/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 39703416.0000 - val_loss: 915365824.0000\n",
      "Epoch 1256/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 26477880.0000 - val_loss: 914160320.0000\n",
      "Epoch 1257/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 25865890.0000 - val_loss: 917602112.0000\n",
      "Epoch 1258/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 24693480.0000 - val_loss: 911445888.0000\n",
      "Epoch 1259/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step - loss: 26323284.0000 - val_loss: 919292928.0000\n",
      "Epoch 1260/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 38223776.0000 - val_loss: 937404800.0000\n",
      "Epoch 1261/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 56340432.0000 - val_loss: 913072704.0000\n",
      "Epoch 1262/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 38401128.0000 - val_loss: 918598400.0000\n",
      "Epoch 1263/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33579580.0000 - val_loss: 917562688.0000\n",
      "Epoch 1264/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 26740368.0000 - val_loss: 906705600.0000\n",
      "Epoch 1265/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 23092866.0000 - val_loss: 916481792.0000\n",
      "Epoch 1266/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 24790214.0000 - val_loss: 915080960.0000\n",
      "Epoch 1267/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 29892050.0000 - val_loss: 921904960.0000\n",
      "Epoch 1268/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 47070412.0000 - val_loss: 917195392.0000\n",
      "Epoch 1269/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 40194172.0000 - val_loss: 914088832.0000\n",
      "Epoch 1270/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 27304652.0000 - val_loss: 913660224.0000\n",
      "Epoch 1271/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 27987558.0000 - val_loss: 922478656.0000\n",
      "Epoch 1272/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 28120556.0000 - val_loss: 917654720.0000\n",
      "Epoch 1273/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 32089694.0000 - val_loss: 925843328.0000\n",
      "Epoch 1274/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 31310946.0000 - val_loss: 908308928.0000\n",
      "Epoch 1275/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 28871962.0000 - val_loss: 923865728.0000\n",
      "Epoch 1276/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 46629900.0000 - val_loss: 925625536.0000\n",
      "Epoch 1277/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 41931756.0000 - val_loss: 922371520.0000\n",
      "Epoch 1278/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 29535226.0000 - val_loss: 912588288.0000\n",
      "Epoch 1279/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 23095518.0000 - val_loss: 911257792.0000\n",
      "Epoch 1280/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 20079336.0000 - val_loss: 912607360.0000\n",
      "Epoch 1281/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 21804770.0000 - val_loss: 922198528.0000\n",
      "Epoch 1282/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 37384156.0000 - val_loss: 969786688.0000\n",
      "Epoch 1283/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 58761352.0000 - val_loss: 951957120.0000\n",
      "Epoch 1284/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 29627596.0000 - val_loss: 923939712.0000\n",
      "Epoch 1285/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 21588526.0000 - val_loss: 922041472.0000\n",
      "Epoch 1286/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 20659616.0000 - val_loss: 920108928.0000\n",
      "Epoch 1287/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 21731190.0000 - val_loss: 928609600.0000\n",
      "Epoch 1288/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 27789474.0000 - val_loss: 947594624.0000\n",
      "Epoch 1289/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 44074124.0000 - val_loss: 953549632.0000\n",
      "Epoch 1290/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 50470412.0000 - val_loss: 937866944.0000\n",
      "Epoch 1291/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 34003840.0000 - val_loss: 933817984.0000\n",
      "Epoch 1292/2000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 29064304.0000 - val_loss: 933225536.0000\n",
      "Epoch 1293/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 29561954.0000 - val_loss: 929352768.0000\n",
      "Epoch 1294/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 24088450.0000 - val_loss: 927379776.0000\n",
      "Epoch 1295/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 22062234.0000 - val_loss: 924862080.0000\n",
      "Epoch 1296/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 21640164.0000 - val_loss: 928126720.0000\n",
      "Epoch 1297/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 20952574.0000 - val_loss: 937094144.0000\n",
      "Epoch 1298/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28832852.0000 - val_loss: 971451392.0000\n",
      "Epoch 1299/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 71831096.0000 - val_loss: 959051392.0000\n",
      "Epoch 1300/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 46666308.0000 - val_loss: 934238336.0000\n",
      "Epoch 1301/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 29341986.0000 - val_loss: 925778432.0000\n",
      "Epoch 1302/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 23482568.0000 - val_loss: 926835264.0000\n",
      "Epoch 1303/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 21637322.0000 - val_loss: 924276480.0000\n",
      "Epoch 1304/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 19821892.0000 - val_loss: 926547584.0000\n",
      "Epoch 1305/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 20336780.0000 - val_loss: 933205760.0000\n",
      "Epoch 1306/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 25471110.0000 - val_loss: 950646464.0000\n",
      "Epoch 1307/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 42268792.0000 - val_loss: 948993088.0000\n",
      "Epoch 1308/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 40957004.0000 - val_loss: 946238784.0000\n",
      "Epoch 1309/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 34068568.0000 - val_loss: 936609920.0000\n",
      "Epoch 1310/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 28734720.0000 - val_loss: 934992896.0000\n",
      "Epoch 1311/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 23535974.0000 - val_loss: 928193600.0000\n",
      "Epoch 1312/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 23574326.0000 - val_loss: 936053504.0000\n",
      "Epoch 1313/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 30382236.0000 - val_loss: 944613696.0000\n",
      "Epoch 1314/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 34131108.0000 - val_loss: 940761088.0000\n",
      "Epoch 1315/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 30355572.0000 - val_loss: 924647232.0000\n",
      "Epoch 1316/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 24663152.0000 - val_loss: 935436288.0000\n",
      "Epoch 1317/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 23996696.0000 - val_loss: 939185792.0000\n",
      "Epoch 1318/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 27275004.0000 - val_loss: 948880576.0000\n",
      "Epoch 1319/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 38634064.0000 - val_loss: 942729984.0000\n",
      "Epoch 1320/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 26307352.0000 - val_loss: 933659136.0000\n",
      "Epoch 1321/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 24321010.0000 - val_loss: 939396288.0000\n",
      "Epoch 1322/2000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 32752750.0000 - val_loss: 956057920.0000\n",
      "Epoch 1323/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 45339500.0000 - val_loss: 952393152.0000\n",
      "Epoch 1324/2000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 30634024.0000 - val_loss: 930263040.0000\n",
      "Epoch 1325/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 21798014.0000 - val_loss: 935044608.0000\n",
      "Epoch 1326/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 20978288.0000 - val_loss: 931962368.0000\n",
      "Epoch 1327/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 22483274.0000 - val_loss: 945128960.0000\n",
      "Epoch 1328/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 30647428.0000 - val_loss: 965215744.0000\n",
      "Epoch 1329/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 51192992.0000 - val_loss: 954576064.0000\n",
      "Epoch 1330/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 27896148.0000 - val_loss: 932907776.0000\n",
      "Epoch 1331/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 21024366.0000 - val_loss: 931219968.0000\n",
      "Epoch 1332/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 22197566.0000 - val_loss: 934099904.0000\n",
      "Epoch 1333/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 24979512.0000 - val_loss: 946382784.0000\n",
      "Epoch 1334/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 39823396.0000 - val_loss: 969996032.0000\n",
      "Epoch 1335/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 51212988.0000 - val_loss: 942510464.0000\n",
      "Epoch 1336/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25520540.0000 - val_loss: 943164928.0000\n",
      "Epoch 1337/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 24751868.0000 - val_loss: 938568192.0000\n",
      "Epoch 1338/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 26438344.0000 - val_loss: 943608640.0000\n",
      "Epoch 1339/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 31902914.0000 - val_loss: 947301760.0000\n",
      "Epoch 1340/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25612230.0000 - val_loss: 938631360.0000\n",
      "Epoch 1341/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 23541120.0000 - val_loss: 946519424.0000\n",
      "Epoch 1342/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 23504012.0000 - val_loss: 937341760.0000\n",
      "Epoch 1343/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 19501834.0000 - val_loss: 935909888.0000\n",
      "Epoch 1344/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 21029632.0000 - val_loss: 955398720.0000\n",
      "Epoch 1345/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 41892136.0000 - val_loss: 985305728.0000\n",
      "Epoch 1346/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 57859416.0000 - val_loss: 952321920.0000\n",
      "Epoch 1347/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 29147938.0000 - val_loss: 937214592.0000\n",
      "Epoch 1348/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 24608464.0000 - val_loss: 932468544.0000\n",
      "Epoch 1349/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 20851810.0000 - val_loss: 932962752.0000\n",
      "Epoch 1350/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 18485522.0000 - val_loss: 931854592.0000\n",
      "Epoch 1351/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 19902194.0000 - val_loss: 941322752.0000\n",
      "Epoch 1352/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 25427666.0000 - val_loss: 945463296.0000\n",
      "Epoch 1353/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 30906722.0000 - val_loss: 967905216.0000\n",
      "Epoch 1354/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 51889752.0000 - val_loss: 953761600.0000\n",
      "Epoch 1355/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 35008472.0000 - val_loss: 939111872.0000\n",
      "Epoch 1356/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 27307718.0000 - val_loss: 935203648.0000\n",
      "Epoch 1357/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 19022574.0000 - val_loss: 926677760.0000\n",
      "Epoch 1358/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 16504199.0000 - val_loss: 928983168.0000\n",
      "Epoch 1359/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18950498.0000 - val_loss: 941558912.0000\n",
      "Epoch 1360/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 41962280.0000 - val_loss: 963631360.0000\n",
      "Epoch 1361/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 39681112.0000 - val_loss: 945951808.0000\n",
      "Epoch 1362/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 26247610.0000 - val_loss: 937437504.0000\n",
      "Epoch 1363/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 18946188.0000 - val_loss: 937466368.0000\n",
      "Epoch 1364/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 18217126.0000 - val_loss: 940508352.0000\n",
      "Epoch 1365/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 24058666.0000 - val_loss: 956175872.0000\n",
      "Epoch 1366/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 46397068.0000 - val_loss: 972290112.0000\n",
      "Epoch 1367/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 45141208.0000 - val_loss: 938199552.0000\n",
      "Epoch 1368/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 21157396.0000 - val_loss: 934784512.0000\n",
      "Epoch 1369/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 18464898.0000 - val_loss: 932594688.0000\n",
      "Epoch 1370/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 16695606.0000 - val_loss: 934054144.0000\n",
      "Epoch 1371/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 16527485.0000 - val_loss: 933529728.0000\n",
      "Epoch 1372/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 16496991.0000 - val_loss: 940926656.0000\n",
      "Epoch 1373/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 16611918.0000 - val_loss: 939595072.0000\n",
      "Epoch 1374/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 26373762.0000 - val_loss: 996561792.0000\n",
      "Epoch 1375/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 84854824.0000 - val_loss: 956269056.0000\n",
      "Epoch 1376/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 31283602.0000 - val_loss: 939049984.0000\n",
      "Epoch 1377/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 22340762.0000 - val_loss: 934340672.0000\n",
      "Epoch 1378/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 18912422.0000 - val_loss: 933019968.0000\n",
      "Epoch 1379/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 19551306.0000 - val_loss: 937233344.0000\n",
      "Epoch 1380/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 24197688.0000 - val_loss: 944574400.0000\n",
      "Epoch 1381/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 35698236.0000 - val_loss: 949505536.0000\n",
      "Epoch 1382/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 30267444.0000 - val_loss: 939233664.0000\n",
      "Epoch 1383/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 25208520.0000 - val_loss: 949360448.0000\n",
      "Epoch 1384/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 28833690.0000 - val_loss: 943319232.0000\n",
      "Epoch 1385/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 26118818.0000 - val_loss: 943880064.0000\n",
      "Epoch 1386/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 27574282.0000 - val_loss: 951141568.0000\n",
      "Epoch 1387/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 25510202.0000 - val_loss: 948140544.0000\n",
      "Epoch 1388/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 24473490.0000 - val_loss: 949610752.0000\n",
      "Epoch 1389/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 37257524.0000 - val_loss: 966370752.0000\n",
      "Epoch 1390/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 40372940.0000 - val_loss: 961564160.0000\n",
      "Epoch 1391/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 34090264.0000 - val_loss: 949328960.0000\n",
      "Epoch 1392/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 24748888.0000 - val_loss: 935974272.0000\n",
      "Epoch 1393/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 18086438.0000 - val_loss: 934889152.0000\n",
      "Epoch 1394/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16740762.0000 - val_loss: 936818048.0000\n",
      "Epoch 1395/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 18644612.0000 - val_loss: 949337600.0000\n",
      "Epoch 1396/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 26804650.0000 - val_loss: 961275392.0000\n",
      "Epoch 1397/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 41485004.0000 - val_loss: 946541888.0000\n",
      "Epoch 1398/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 24400574.0000 - val_loss: 940815616.0000\n",
      "Epoch 1399/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 31ms/step - loss: 20637450.0000 - val_loss: 940371776.0000\n",
      "Epoch 1400/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 19128690.0000 - val_loss: 941059968.0000\n",
      "Epoch 1401/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 17655156.0000 - val_loss: 945467200.0000\n",
      "Epoch 1402/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 23374718.0000 - val_loss: 963931776.0000\n",
      "Epoch 1403/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 58736984.0000 - val_loss: 975230656.0000\n",
      "Epoch 1404/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 38443188.0000 - val_loss: 940780352.0000\n",
      "Epoch 1405/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 17104214.0000 - val_loss: 933580736.0000\n",
      "Epoch 1406/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 14684842.0000 - val_loss: 930369408.0000\n",
      "Epoch 1407/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 14480677.0000 - val_loss: 931103488.0000\n",
      "Epoch 1408/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 14462431.0000 - val_loss: 931870656.0000\n",
      "Epoch 1409/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 17385748.0000 - val_loss: 956614720.0000\n",
      "Epoch 1410/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 49759420.0000 - val_loss: 990333120.0000\n",
      "Epoch 1411/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 59872568.0000 - val_loss: 959260608.0000\n",
      "Epoch 1412/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 21233526.0000 - val_loss: 933173120.0000\n",
      "Epoch 1413/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 14561593.0000 - val_loss: 936738880.0000\n",
      "Epoch 1414/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 14341189.0000 - val_loss: 934396352.0000\n",
      "Epoch 1415/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 14142785.0000 - val_loss: 934477760.0000\n",
      "Epoch 1416/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 14276170.0000 - val_loss: 928179584.0000\n",
      "Epoch 1417/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 15531560.0000 - val_loss: 945357312.0000\n",
      "Epoch 1418/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 48243892.0000 - val_loss: 964751424.0000\n",
      "Epoch 1419/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 65068788.0000 - val_loss: 938791360.0000\n",
      "Epoch 1420/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 29479558.0000 - val_loss: 932691584.0000\n",
      "Epoch 1421/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 22671764.0000 - val_loss: 932567424.0000\n",
      "Epoch 1422/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18147248.0000 - val_loss: 931969280.0000\n",
      "Epoch 1423/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 15437129.0000 - val_loss: 929097792.0000\n",
      "Epoch 1424/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 14993017.0000 - val_loss: 929279872.0000\n",
      "Epoch 1425/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16641932.0000 - val_loss: 934856448.0000\n",
      "Epoch 1426/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 28977934.0000 - val_loss: 943656320.0000\n",
      "Epoch 1427/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 47516020.0000 - val_loss: 949139584.0000\n",
      "Epoch 1428/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 40252648.0000 - val_loss: 931231232.0000\n",
      "Epoch 1429/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 22412832.0000 - val_loss: 933223872.0000\n",
      "Epoch 1430/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 21564756.0000 - val_loss: 933279040.0000\n",
      "Epoch 1431/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 21781400.0000 - val_loss: 936284992.0000\n",
      "Epoch 1432/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 25672758.0000 - val_loss: 937728960.0000\n",
      "Epoch 1433/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 20611780.0000 - val_loss: 934375360.0000\n",
      "Epoch 1434/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 24384640.0000 - val_loss: 946498112.0000\n",
      "Epoch 1435/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 31622044.0000 - val_loss: 940993600.0000\n",
      "Epoch 1436/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 29266358.0000 - val_loss: 942778432.0000\n",
      "Epoch 1437/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 30804492.0000 - val_loss: 941527232.0000\n",
      "Epoch 1438/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 24557910.0000 - val_loss: 936143168.0000\n",
      "Epoch 1439/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 17107544.0000 - val_loss: 928759616.0000\n",
      "Epoch 1440/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 14772573.0000 - val_loss: 933329920.0000\n",
      "Epoch 1441/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 14608975.0000 - val_loss: 935234816.0000\n",
      "Epoch 1442/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 14699442.0000 - val_loss: 928956352.0000\n",
      "Epoch 1443/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16605453.0000 - val_loss: 944591040.0000\n",
      "Epoch 1444/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 51004492.0000 - val_loss: 956892800.0000\n",
      "Epoch 1445/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 63871460.0000 - val_loss: 940826048.0000\n",
      "Epoch 1446/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 24316062.0000 - val_loss: 933250560.0000\n",
      "Epoch 1447/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13597013.0000 - val_loss: 936717888.0000\n",
      "Epoch 1448/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 13126462.0000 - val_loss: 936072064.0000\n",
      "Epoch 1449/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 12974180.0000 - val_loss: 936338624.0000\n",
      "Epoch 1450/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 12968770.0000 - val_loss: 937817024.0000\n",
      "Epoch 1451/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 13176801.0000 - val_loss: 942707712.0000\n",
      "Epoch 1452/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 17512430.0000 - val_loss: 965336256.0000\n",
      "Epoch 1453/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 44305268.0000 - val_loss: 997537024.0000\n",
      "Epoch 1454/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 65002040.0000 - val_loss: 956451200.0000\n",
      "Epoch 1455/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 25566950.0000 - val_loss: 945547136.0000\n",
      "Epoch 1456/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 16517781.0000 - val_loss: 938995328.0000\n",
      "Epoch 1457/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13698157.0000 - val_loss: 939294272.0000\n",
      "Epoch 1458/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 12870604.0000 - val_loss: 939367104.0000\n",
      "Epoch 1459/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 13184387.0000 - val_loss: 945486400.0000\n",
      "Epoch 1460/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 19640444.0000 - val_loss: 977777216.0000\n",
      "Epoch 1461/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 49200724.0000 - val_loss: 986762432.0000\n",
      "Epoch 1462/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 46941220.0000 - val_loss: 947659712.0000\n",
      "Epoch 1463/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 22820040.0000 - val_loss: 951583616.0000\n",
      "Epoch 1464/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 21671452.0000 - val_loss: 954407744.0000\n",
      "Epoch 1465/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 22030100.0000 - val_loss: 952076864.0000\n",
      "Epoch 1466/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 17726696.0000 - val_loss: 949870144.0000\n",
      "Epoch 1467/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 16174580.0000 - val_loss: 952682560.0000\n",
      "Epoch 1468/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 16816046.0000 - val_loss: 957551936.0000\n",
      "Epoch 1469/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 27403780.0000 - val_loss: 968404096.0000\n",
      "Epoch 1470/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 43251592.0000 - val_loss: 972240640.0000\n",
      "Epoch 1471/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 38374436.0000 - val_loss: 952297600.0000\n",
      "Epoch 1472/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 16153121.0000 - val_loss: 942000832.0000\n",
      "Epoch 1473/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 13239149.0000 - val_loss: 942832576.0000\n",
      "Epoch 1474/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 12797417.0000 - val_loss: 944737536.0000\n",
      "Epoch 1475/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14513711.0000 - val_loss: 963617088.0000\n",
      "Epoch 1476/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 29118354.0000 - val_loss: 997257024.0000\n",
      "Epoch 1477/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 60049640.0000 - val_loss: 976293824.0000\n",
      "Epoch 1478/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 37638988.0000 - val_loss: 960207936.0000\n",
      "Epoch 1479/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16600753.0000 - val_loss: 950097600.0000\n",
      "Epoch 1480/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13901254.0000 - val_loss: 949167616.0000\n",
      "Epoch 1481/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 13136904.0000 - val_loss: 950641728.0000\n",
      "Epoch 1482/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14723825.0000 - val_loss: 958773184.0000\n",
      "Epoch 1483/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 20919850.0000 - val_loss: 976665728.0000\n",
      "Epoch 1484/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 30650800.0000 - val_loss: 991622592.0000\n",
      "Epoch 1485/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 41287056.0000 - val_loss: 980472640.0000\n",
      "Epoch 1486/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 33417498.0000 - val_loss: 966651456.0000\n",
      "Epoch 1487/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 25160746.0000 - val_loss: 960639808.0000\n",
      "Epoch 1488/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 19347518.0000 - val_loss: 954666944.0000\n",
      "Epoch 1489/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 12867544.0000 - val_loss: 951789440.0000\n",
      "Epoch 1490/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 12046536.0000 - val_loss: 951401088.0000\n",
      "Epoch 1491/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 11966095.0000 - val_loss: 952203648.0000\n",
      "Epoch 1492/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 12337524.0000 - val_loss: 956128512.0000\n",
      "Epoch 1493/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 15971163.0000 - val_loss: 986169856.0000\n",
      "Epoch 1494/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 49986152.0000 - val_loss: 1027043456.0000\n",
      "Epoch 1495/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 67652416.0000 - val_loss: 959691392.0000\n",
      "Epoch 1496/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 15229428.0000 - val_loss: 948055040.0000\n",
      "Epoch 1497/2000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 11989731.0000"
     ]
    }
   ],
   "source": [
    "## train\n",
    "hist = model.fit(x=X_train,y=Y_train,batch_size=512, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc233623",
   "metadata": {},
   "source": [
    "## Visualize results and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec178190",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hist.history\n",
    "\n",
    "plt.plot(h['loss'], label=\"Training Loss\")\n",
    "plt.plot(h['val_loss'], label=\"Validation Loss\")\n",
    "plt.xlabel(\"No of epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.argmin(h['loss'])\n",
    "print(\"At index:\", train_idx, \"minimum training loss is: \",  h['loss'][train_idx])\n",
    "\n",
    "val_idx = np.argmin(h['val_loss'])\n",
    "print(\"At index:\", val_idx, \"minimum validation accuracy is: \", h['val_loss'][val_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148879a6",
   "metadata": {},
   "source": [
    "## Do data cleaning and Data Normalization on test data same as we did on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58135c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"./Test/Test_Data.csv\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## store ids for submission format(we need this column in submission file)\n",
    "ids = X_test['Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop useless columns\n",
    "X_test = X_test.drop(labels=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis=1)\n",
    "\n",
    "## convert strings to numeric data\n",
    "le = LabelEncoder()\n",
    "for i in X_test.columns:\n",
    "    if type(X_test[i].values[0])==str:  # check if 1st value of this column is string\n",
    "        X_test[i] = le.fit_transform(X_test[i].astype('str'))\n",
    "        X_test[i] = X_test[i].fillna(X_test[i].mode())\n",
    "    else:\n",
    "        X_test[i] = X_test[i].fillna(X_test[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cf9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to common dtype. i.e-float32\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "# data normalization\n",
    "X_test = (X_test - X_test.mean(axis=0)) / X_test.std(axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## see how X_test looks like \n",
    "pd.DataFrame(X_test, columns=df.columns[:-1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(y_pred)\n",
    "ids = pd.DataFrame(ids, columns=['Id'])\n",
    "df3 = pd.DataFrame({\"Id\":ids.values[:,0], \"SalePrice\":df2.values[:,0]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec845710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545af44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
