{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7869b3",
   "metadata": {},
   "source": [
    "### Try adding dropout layers also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fe4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d1fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 21:35:57.924274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-21 21:35:57.924320: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0f419",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f102f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Train/Train_Data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90addd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67c1d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35caea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1100 non-null   int64  \n",
      " 1   MSSubClass     1100 non-null   int64  \n",
      " 2   MSZoning       1100 non-null   object \n",
      " 3   LotFrontage    908 non-null    float64\n",
      " 4   LotArea        1100 non-null   int64  \n",
      " 5   Street         1100 non-null   object \n",
      " 6   Alley          69 non-null     object \n",
      " 7   LotShape       1100 non-null   object \n",
      " 8   LandContour    1100 non-null   object \n",
      " 9   Utilities      1100 non-null   object \n",
      " 10  LotConfig      1100 non-null   object \n",
      " 11  LandSlope      1100 non-null   object \n",
      " 12  Neighborhood   1100 non-null   object \n",
      " 13  Condition1     1100 non-null   object \n",
      " 14  Condition2     1100 non-null   object \n",
      " 15  BldgType       1100 non-null   object \n",
      " 16  HouseStyle     1100 non-null   object \n",
      " 17  OverallQual    1100 non-null   int64  \n",
      " 18  OverallCond    1100 non-null   int64  \n",
      " 19  YearBuilt      1100 non-null   int64  \n",
      " 20  YearRemodAdd   1100 non-null   int64  \n",
      " 21  RoofStyle      1100 non-null   object \n",
      " 22  RoofMatl       1100 non-null   object \n",
      " 23  Exterior1st    1100 non-null   object \n",
      " 24  Exterior2nd    1100 non-null   object \n",
      " 25  MasVnrType     1094 non-null   object \n",
      " 26  MasVnrArea     1094 non-null   float64\n",
      " 27  ExterQual      1100 non-null   object \n",
      " 28  ExterCond      1100 non-null   object \n",
      " 29  Foundation     1100 non-null   object \n",
      " 30  BsmtQual       1069 non-null   object \n",
      " 31  BsmtCond       1069 non-null   object \n",
      " 32  BsmtExposure   1068 non-null   object \n",
      " 33  BsmtFinType1   1069 non-null   object \n",
      " 34  BsmtFinSF1     1100 non-null   int64  \n",
      " 35  BsmtFinType2   1068 non-null   object \n",
      " 36  BsmtFinSF2     1100 non-null   int64  \n",
      " 37  BsmtUnfSF      1100 non-null   int64  \n",
      " 38  TotalBsmtSF    1100 non-null   int64  \n",
      " 39  Heating        1100 non-null   object \n",
      " 40  HeatingQC      1100 non-null   object \n",
      " 41  CentralAir     1100 non-null   object \n",
      " 42  Electrical     1100 non-null   object \n",
      " 43  1stFlrSF       1100 non-null   int64  \n",
      " 44  2ndFlrSF       1100 non-null   int64  \n",
      " 45  LowQualFinSF   1100 non-null   int64  \n",
      " 46  GrLivArea      1100 non-null   int64  \n",
      " 47  BsmtFullBath   1100 non-null   int64  \n",
      " 48  BsmtHalfBath   1100 non-null   int64  \n",
      " 49  FullBath       1100 non-null   int64  \n",
      " 50  HalfBath       1100 non-null   int64  \n",
      " 51  BedroomAbvGr   1100 non-null   int64  \n",
      " 52  KitchenAbvGr   1100 non-null   int64  \n",
      " 53  KitchenQual    1100 non-null   object \n",
      " 54  TotRmsAbvGrd   1100 non-null   int64  \n",
      " 55  Functional     1100 non-null   object \n",
      " 56  Fireplaces     1100 non-null   int64  \n",
      " 57  FireplaceQu    576 non-null    object \n",
      " 58  GarageType     1039 non-null   object \n",
      " 59  GarageYrBlt    1039 non-null   float64\n",
      " 60  GarageFinish   1039 non-null   object \n",
      " 61  GarageCars     1100 non-null   int64  \n",
      " 62  GarageArea     1100 non-null   int64  \n",
      " 63  GarageQual     1039 non-null   object \n",
      " 64  GarageCond     1039 non-null   object \n",
      " 65  PavedDrive     1100 non-null   object \n",
      " 66  WoodDeckSF     1100 non-null   int64  \n",
      " 67  OpenPorchSF    1100 non-null   int64  \n",
      " 68  EnclosedPorch  1100 non-null   int64  \n",
      " 69  3SsnPorch      1100 non-null   int64  \n",
      " 70  ScreenPorch    1100 non-null   int64  \n",
      " 71  PoolArea       1100 non-null   int64  \n",
      " 72  PoolQC         2 non-null      object \n",
      " 73  Fence          208 non-null    object \n",
      " 74  MiscFeature    46 non-null     object \n",
      " 75  MiscVal        1100 non-null   int64  \n",
      " 76  MoSold         1100 non-null   int64  \n",
      " 77  YrSold         1100 non-null   int64  \n",
      " 78  SaleType       1100 non-null   object \n",
      " 79  SaleCondition  1100 non-null   object \n",
      " 80  SalePrice      1100 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 696.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e2bc4",
   "metadata": {},
   "source": [
    "- Let us remove some useless columns. **The detailed description of the features is provided in a text file in train folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c8f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9317</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>176432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>70</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6882</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3696</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11880</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1095          20       RL         78.0     9317   Pave      IR1         Lvl   \n",
       "1096          70       RM         60.0     6882   Pave      Reg         Lvl   \n",
       "1097         120       RL          NaN     3696   Pave      Reg         Lvl   \n",
       "1098          50       RM         50.0     6000   Pave      Reg         Lvl   \n",
       "1099          20       RL         82.0    11880   Pave      IR1         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1       AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2       AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3       AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4       AllPub       FR2       Gtl  ...             0         0           0   \n",
       "...        ...       ...       ...  ...           ...       ...         ...   \n",
       "1095    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1096    AllPub    Inside       Gtl  ...           115         0           0   \n",
       "1097    AllPub    Inside       Gtl  ...           137         0           0   \n",
       "1098    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1099    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0           0       0       2    2008        WD         Normal    208500  \n",
       "1           0       0       5    2007        WD         Normal    181500  \n",
       "2           0       0       9    2008        WD         Normal    223500  \n",
       "3           0       0       2    2006        WD        Abnorml    140000  \n",
       "4           0       0      12    2008        WD         Normal    250000  \n",
       "...       ...     ...     ...     ...       ...            ...       ...  \n",
       "1095        0       0       3    2007        WD         Normal    176432  \n",
       "1096        0       0       3    2007        WD         Normal    127000  \n",
       "1097        0       0      10    2007        WD         Normal    170000  \n",
       "1098        0       0       7    2009        WD         Normal    128000  \n",
       "1099        0       0       4    2009       COD        Abnorml    157000  \n",
       "\n",
       "[1100 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(labels=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd38292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8f47fe",
   "metadata": {},
   "source": [
    "#### Convert all string columns to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e762dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652c7e1",
   "metadata": {},
   "source": [
    "- We can iterate over columns and will apply le.fit_transform() if type is str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51126042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[:5]:\n",
    "    print(type(df[i].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f653c",
   "metadata": {},
   "source": [
    "- **Here some columns may have different types of values in them. So we need to convert every column to `astype('str')`. LabelEncoder gives error otherwise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249582f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for i in df.columns:\n",
    "    if type(df[i].values[0])==str:  # check if 1st value of this column is string\n",
    "        df[i] = le.fit_transform(df[i].astype('str')) # convert to numeric first\n",
    "        df[i] = df[i].fillna(df[i].mode())  # for string case, fing mode\n",
    "    else:\n",
    "        df[i] = df[i].fillna(df[i].mean())  # for int case, fing mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde3ba66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
       "0          60         3         65.0     8450       1         3            3   \n",
       "1          20         3         80.0     9600       1         3            3   \n",
       "2          60         3         68.0    11250       1         0            3   \n",
       "3          70         3         60.0     9550       1         0            3   \n",
       "4          60         3         84.0    14260       1         0            3   \n",
       "\n",
       "   Utilities  LotConfig  LandSlope  ...  EnclosedPorch  3SsnPorch  \\\n",
       "0          0          4          0  ...              0          0   \n",
       "1          0          2          0  ...              0          0   \n",
       "2          0          4          0  ...              0          0   \n",
       "3          0          0          0  ...            272          0   \n",
       "4          0          2          0  ...              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \\\n",
       "0            0         0        0       2    2008         8              4   \n",
       "1            0         0        0       5    2007         8              4   \n",
       "2            0         0        0       9    2008         8              4   \n",
       "3            0         0        0       2    2006         8              0   \n",
       "4            0         0        0      12    2008         8              4   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b959c0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1081\n",
       "168       3\n",
       "180       2\n",
       "144       2\n",
       "320       1\n",
       "407       1\n",
       "130       1\n",
       "140       1\n",
       "508       1\n",
       "238       1\n",
       "245       1\n",
       "196       1\n",
       "182       1\n",
       "162       1\n",
       "23        1\n",
       "216       1\n",
       "Name: 3SsnPorch, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['3SsnPorch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90903415",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_cols = {}\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].value_counts().iloc[0] > 800:\n",
    "        useless_cols[i] = df[i].value_counts().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89389a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSZoning': 862, 'Street': 1095, 'LandContour': 991, 'Utilities': 1099, 'LandSlope': 1041, 'Condition1': 947, 'Condition2': 1087, 'BldgType': 914, 'RoofStyle': 867, 'RoofMatl': 1078, 'ExterCond': 964, 'BsmtCond': 979, 'BsmtFinType2': 939, 'BsmtFinSF2': 970, 'Heating': 1079, 'CentralAir': 1026, 'Electrical': 1003, 'LowQualFinSF': 1078, 'BsmtHalfBath': 1034, 'KitchenAbvGr': 1048, 'Functional': 1022, 'GarageQual': 993, 'GarageCond': 1002, 'PavedDrive': 1013, 'EnclosedPorch': 943, '3SsnPorch': 1081, 'ScreenPorch': 1013, 'PoolArea': 1098, 'MiscVal': 1055, 'SaleType': 948, 'SaleCondition': 899}\n"
     ]
    }
   ],
   "source": [
    "print(useless_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80269595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSZoning': 862, 'Street': 1095, 'LandContour': 991, 'Utilities': 1099, 'LandSlope': 1041, 'Condition1': 947, 'Condition2': 1087, 'BldgType': 914, 'RoofStyle': 867, 'RoofMatl': 1078, 'ExterCond': 964, 'BsmtCond': 979, 'BsmtFinType2': 939, 'BsmtFinSF2': 970, 'Heating': 1079, 'CentralAir': 1026, 'Electrical': 1003, 'LowQualFinSF': 1078, 'BsmtHalfBath': 1034, 'KitchenAbvGr': 1048, 'Functional': 1022, 'GarageQual': 993, 'GarageCond': 1002, 'PavedDrive': 1013, 'EnclosedPorch': 943, '3SsnPorch': 1081, 'ScreenPorch': 1013, 'PoolArea': 1098, 'MiscVal': 1055, 'SaleType': 948, 'SaleCondition': 899}\n"
     ]
    }
   ],
   "source": [
    "print(useless_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a8c91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MSZoning', 'Street', 'LandContour', 'Utilities', 'LandSlope',\n",
       "       'Condition1', 'Condition2', 'BldgType', 'RoofStyle', 'RoofMatl',\n",
       "       'ExterCond', 'BsmtCond', 'BsmtFinType2', 'BsmtFinSF2', 'Heating',\n",
       "       'CentralAir', 'Electrical', 'LowQualFinSF', 'BsmtHalfBath',\n",
       "       'KitchenAbvGr', 'Functional', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
       "       'PoolArea', 'MiscVal', 'SaleType', 'SaleCondition'], dtype='<U13')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless = np.array(list(useless_cols.keys()))\n",
    "useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc607dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning' 'Street' 'LandContour' 'Utilities' 'LandSlope' 'Condition1'\n",
      " 'Condition2' 'BldgType' 'RoofStyle' 'RoofMatl' 'ExterCond' 'BsmtCond'\n",
      " 'BsmtFinType2' 'BsmtFinSF2' 'Heating' 'CentralAir' 'Electrical'\n",
      " 'LowQualFinSF' 'BsmtHalfBath' 'KitchenAbvGr' 'Functional' 'GarageQual'\n",
      " 'GarageCond' 'PavedDrive' 'EnclosedPorch' '3SsnPorch' 'ScreenPorch'\n",
      " 'PoolArea' 'MiscVal' 'SaleType' 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "174115c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>9317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>176432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>6882</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>69.618943</td>\n",
       "      <td>3696</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>11880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  \\\n",
       "0             60         3    65.000000     8450       1         3   \n",
       "1             20         3    80.000000     9600       1         3   \n",
       "2             60         3    68.000000    11250       1         0   \n",
       "3             70         3    60.000000     9550       1         0   \n",
       "4             60         3    84.000000    14260       1         0   \n",
       "...          ...       ...          ...      ...     ...       ...   \n",
       "1095          20         3    78.000000     9317       1         0   \n",
       "1096          70         4    60.000000     6882       1         3   \n",
       "1097         120         3    69.618943     3696       1         3   \n",
       "1098          50         4    50.000000     6000       1         3   \n",
       "1099          20         3    82.000000    11880       1         0   \n",
       "\n",
       "      LandContour  Utilities  LotConfig  LandSlope  ...  EnclosedPorch  \\\n",
       "0               3          0          4          0  ...              0   \n",
       "1               3          0          2          0  ...              0   \n",
       "2               3          0          4          0  ...              0   \n",
       "3               3          0          0          0  ...            272   \n",
       "4               3          0          2          0  ...              0   \n",
       "...           ...        ...        ...        ...  ...            ...   \n",
       "1095            3          0          4          0  ...              0   \n",
       "1096            3          0          4          0  ...            115   \n",
       "1097            3          0          4          0  ...            137   \n",
       "1098            3          0          4          0  ...              0   \n",
       "1099            3          0          4          0  ...              0   \n",
       "\n",
       "      3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0             0            0         0        0       2    2008         8   \n",
       "1             0            0         0        0       5    2007         8   \n",
       "2             0            0         0        0       9    2008         8   \n",
       "3             0            0         0        0       2    2006         8   \n",
       "4             0            0         0        0      12    2008         8   \n",
       "...         ...          ...       ...      ...     ...     ...       ...   \n",
       "1095          0            0         0        0       3    2007         8   \n",
       "1096          0            0         0        0       3    2007         8   \n",
       "1097          0            0         0        0      10    2007         8   \n",
       "1098          0            0         0        0       7    2009         8   \n",
       "1099          0            0         0        0       4    2009         0   \n",
       "\n",
       "      SaleCondition  SalePrice  \n",
       "0                 4     208500  \n",
       "1                 4     181500  \n",
       "2                 4     223500  \n",
       "3                 0     140000  \n",
       "4                 4     250000  \n",
       "...             ...        ...  \n",
       "1095              4     176432  \n",
       "1096              4     127000  \n",
       "1097              4     170000  \n",
       "1098              4     128000  \n",
       "1099              0     157000  \n",
       "\n",
       "[1100 rows x 75 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39855905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96bed077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>8450</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9600</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>11250</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>14260</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>20</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>9317</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>176432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>70</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>6882</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1914</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1978.687199</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>120</td>\n",
       "      <td>69.618943</td>\n",
       "      <td>3696</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1986</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>50</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1936</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1936.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>20</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>11880</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1978</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  LotShape  LotConfig  Neighborhood  \\\n",
       "0             60    65.000000     8450         3          4             5   \n",
       "1             20    80.000000     9600         3          2            24   \n",
       "2             60    68.000000    11250         0          4             5   \n",
       "3             70    60.000000     9550         0          0             6   \n",
       "4             60    84.000000    14260         0          2            15   \n",
       "...          ...          ...      ...       ...        ...           ...   \n",
       "1095          20    78.000000     9317         0          4             5   \n",
       "1096          70    60.000000     6882         3          4             9   \n",
       "1097         120    69.618943     3696         3          4            22   \n",
       "1098          50    50.000000     6000         3          4             3   \n",
       "1099          20    82.000000    11880         0          4            14   \n",
       "\n",
       "      HouseStyle  OverallQual  OverallCond  YearBuilt  ...  GarageType  \\\n",
       "0              5            7            5       2003  ...           1   \n",
       "1              2            6            8       1976  ...           1   \n",
       "2              5            7            5       2001  ...           1   \n",
       "3              5            7            5       1915  ...           5   \n",
       "4              5            8            5       2000  ...           1   \n",
       "...          ...          ...          ...        ...  ...         ...   \n",
       "1095           2            6            5       2006  ...           1   \n",
       "1096           5            6            7       1914  ...           6   \n",
       "1097           2            8            5       1986  ...           1   \n",
       "1098           0            4            6       1936  ...           5   \n",
       "1099           2            7            5       1978  ...           1   \n",
       "\n",
       "      GarageYrBlt  GarageFinish  GarageCars  GarageArea  WoodDeckSF  \\\n",
       "0     2003.000000             1           2         548           0   \n",
       "1     1976.000000             1           2         460         298   \n",
       "2     2001.000000             1           2         608           0   \n",
       "3     1998.000000             2           3         642           0   \n",
       "4     2000.000000             1           3         836         192   \n",
       "...           ...           ...         ...         ...         ...   \n",
       "1095  2006.000000             1           2         440           0   \n",
       "1096  1978.687199             3           0           0         136   \n",
       "1097  1987.000000             1           2         461           0   \n",
       "1098  1936.000000             2           1         240           0   \n",
       "1099  1978.000000             1           2         478           0   \n",
       "\n",
       "      OpenPorchSF  MoSold  YrSold  SalePrice  \n",
       "0              61       2    2008     208500  \n",
       "1               0       5    2007     181500  \n",
       "2              42       9    2008     223500  \n",
       "3              35       2    2006     140000  \n",
       "4              84      12    2008     250000  \n",
       "...           ...     ...     ...        ...  \n",
       "1095           22       3    2007     176432  \n",
       "1096            0       3    2007     127000  \n",
       "1097           74      10    2007     170000  \n",
       "1098            0       7    2009     128000  \n",
       "1099            0       4    2009     157000  \n",
       "\n",
       "[1100 rows x 44 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(labels=useless, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4db2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8bb47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 44 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   MSSubClass    1100 non-null   int64  \n",
      " 1   LotFrontage   1100 non-null   float64\n",
      " 2   LotArea       1100 non-null   int64  \n",
      " 3   LotShape      1100 non-null   int64  \n",
      " 4   LotConfig     1100 non-null   int64  \n",
      " 5   Neighborhood  1100 non-null   int64  \n",
      " 6   HouseStyle    1100 non-null   int64  \n",
      " 7   OverallQual   1100 non-null   int64  \n",
      " 8   OverallCond   1100 non-null   int64  \n",
      " 9   YearBuilt     1100 non-null   int64  \n",
      " 10  YearRemodAdd  1100 non-null   int64  \n",
      " 11  Exterior1st   1100 non-null   int64  \n",
      " 12  Exterior2nd   1100 non-null   int64  \n",
      " 13  MasVnrType    1100 non-null   int64  \n",
      " 14  MasVnrArea    1100 non-null   float64\n",
      " 15  ExterQual     1100 non-null   int64  \n",
      " 16  Foundation    1100 non-null   int64  \n",
      " 17  BsmtQual      1100 non-null   int64  \n",
      " 18  BsmtExposure  1100 non-null   int64  \n",
      " 19  BsmtFinType1  1100 non-null   int64  \n",
      " 20  BsmtFinSF1    1100 non-null   int64  \n",
      " 21  BsmtUnfSF     1100 non-null   int64  \n",
      " 22  TotalBsmtSF   1100 non-null   int64  \n",
      " 23  HeatingQC     1100 non-null   int64  \n",
      " 24  1stFlrSF      1100 non-null   int64  \n",
      " 25  2ndFlrSF      1100 non-null   int64  \n",
      " 26  GrLivArea     1100 non-null   int64  \n",
      " 27  BsmtFullBath  1100 non-null   int64  \n",
      " 28  FullBath      1100 non-null   int64  \n",
      " 29  HalfBath      1100 non-null   int64  \n",
      " 30  BedroomAbvGr  1100 non-null   int64  \n",
      " 31  KitchenQual   1100 non-null   int64  \n",
      " 32  TotRmsAbvGrd  1100 non-null   int64  \n",
      " 33  Fireplaces    1100 non-null   int64  \n",
      " 34  GarageType    1100 non-null   int64  \n",
      " 35  GarageYrBlt   1100 non-null   float64\n",
      " 36  GarageFinish  1100 non-null   int64  \n",
      " 37  GarageCars    1100 non-null   int64  \n",
      " 38  GarageArea    1100 non-null   int64  \n",
      " 39  WoodDeckSF    1100 non-null   int64  \n",
      " 40  OpenPorchSF   1100 non-null   int64  \n",
      " 41  MoSold        1100 non-null   int64  \n",
      " 42  YrSold        1100 non-null   int64  \n",
      " 43  SalePrice     1100 non-null   int64  \n",
      "dtypes: float64(3), int64(41)\n",
      "memory usage: 378.2 KB\n"
     ]
    }
   ],
   "source": [
    "## now check data after some data preprocessing\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8349b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c811ff8c",
   "metadata": {},
   "source": [
    "#### Divide df in X_train and y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "183ebf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100, 43), (1100,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df.values[:,:-1]\n",
    "Y_train = df.values[:,-1]\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23b7e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype('int')\n",
    "Y_train = np.asarray(Y_train).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37095922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>8450</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>9600</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>11250</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>9550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>14260</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "      <td>9317</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>6882</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1914</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>3696</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1986</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1936</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1936</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>20</td>\n",
       "      <td>82</td>\n",
       "      <td>11880</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1978</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1      2   3   4   5   6   7   8     9   ...  33  34    35  36  37  \\\n",
       "0      60  65   8450   3   4   5   5   7   5  2003  ...   0   1  2003   1   2   \n",
       "1      20  80   9600   3   2  24   2   6   8  1976  ...   1   1  1976   1   2   \n",
       "2      60  68  11250   0   4   5   5   7   5  2001  ...   1   1  2001   1   2   \n",
       "3      70  60   9550   0   0   6   5   7   5  1915  ...   1   5  1998   2   3   \n",
       "4      60  84  14260   0   2  15   5   8   5  2000  ...   1   1  2000   1   3   \n",
       "...   ...  ..    ...  ..  ..  ..  ..  ..  ..   ...  ...  ..  ..   ...  ..  ..   \n",
       "1095   20  78   9317   0   4   5   2   6   5  2006  ...   1   1  2006   1   2   \n",
       "1096   70  60   6882   3   4   9   5   6   7  1914  ...   0   6  1978   3   0   \n",
       "1097  120  69   3696   3   4  22   2   8   5  1986  ...   0   1  1987   1   2   \n",
       "1098   50  50   6000   3   4   3   0   4   6  1936  ...   0   5  1936   2   1   \n",
       "1099   20  82  11880   0   4  14   2   7   5  1978  ...   1   1  1978   1   2   \n",
       "\n",
       "       38   39  40  41    42  \n",
       "0     548    0  61   2  2008  \n",
       "1     460  298   0   5  2007  \n",
       "2     608    0  42   9  2008  \n",
       "3     642    0  35   2  2006  \n",
       "4     836  192  84  12  2008  \n",
       "...   ...  ...  ..  ..   ...  \n",
       "1095  440    0  22   3  2007  \n",
       "1096    0  136   0   3  2007  \n",
       "1097  461    0  74  10  2007  \n",
       "1098  240    0   0   7  2009  \n",
       "1099  478    0   0   4  2009  \n",
       "\n",
       "[1100 rows x 43 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5f1538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 170000, 128000, 157000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cb1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1947ea",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c8e378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 43)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "681e44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c323d1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/Machine_learning/ML_virtual_env/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAFKCAYAAAB7BdRAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOeklEQVR4nO3dW4hX5d7A8d8c9pSalcZogl1Eb3TCDqYZSYZSdiJpXyi5txe17ThWXkghZuiVlUnQW3vTSUnifamMdhhRQWQQNJUmSCewiKLUatQpdZpxdFrvxcsMe9Jm/Dkzrf8/Pp+rWbPGtZ7n/6BfnjX+Z2qKoigCADhitWUPAACqjXgCQJJ4AkCSeAJAkngCQJJ4AkBS/ZF+YUvL3t89N2rU8Ght/WVQBlQ2c6lM5lKZzKUymcvgaGwc+bvnBmXnWV9fNxiXqQjmUpnMpTKZS2Uyl6HnsS0AJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAk1Zdx0xUrlkdr6+4ybt2vurra6Or6tdQxtLW1RUTEiBEjBnSdMucyatToWLJkeSn3BhhqpcSztXV37Nq1K2r+MqyM21e84kBHRETs76opeSRHpzjQXvYQAIZUKfGMiKj5y7A47r9mlXX7irbvy/UREVX7+nSPH+DPyvc8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIKm+jJu2tbVF0XWgjFsDA/Dii/8TERFz5vy95JFAuUrZeXZ27o/4tauMWwMDsHHjB7Fx4wdlDwNK57EtACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJIknACSJJwAkiScAJNWXPQAA+vePf/yt5+M1a/63xJEcnXXrno/XX18f1113ffz1r3MG/fpNTfOjo6M9hg0bEf/859ODfv3fsvMEYMi9/vr6iIh49dVXhuT6HR3tERHR3t42JNf/LfEEqHD/ues83HGlW7fu+V7H//73i4N6/aam+b2OFyy4ZVCvfzge2zLoiq7OaG3tiHvuuXvQrllXVxtdXb8O2vXKVM1zaW3dHQ0Nx5Q9DKpM966z26uvvjKoj267d53d/ojdp50nACTZeTLoauoaYtTxw+Phh/970K7Z2DgyWlr2Dtr1ylTNcxnMpwlQzew8ARhSV189q9fxddddP6jXP/bYYb2Ohw0bMajXPxzxBKhwv31rSrW9VWX27Bt6HQ/2W1X+9a/VvY69VQWAP4Xu3edg7zq7de8+/4hdZ4TveQJUhWrbbf7W7Nk3HLIDHUy/3X0ONTtPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASKov46YNDcdER+eBMm4NDMDkyVPKHgJUhFLiOWLEiNjf9UsZtwYGYM6cv5c9BKgIHtsCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAkngCQJJ4AkCSeAJAUn1ZNy4OtMe+L9eXdfuKVhxoj4io2tfn/8c/vOxhAAyZUuI5atToMm57ROrqaqOr69dSx9DWVkRExIgRAwtQeXMZXtFrDDBQpcRzyZLlZdz2iDQ2joyWlr1lD2NQ/JnmAlBJfM8TAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJLEEwCSxBMAksQTAJJqiqIoyh4EAFQTO08ASBJPAEgSTwBIEk8ASBJPAEgSTwBIqj/aP/jhhx/GwoULY8WKFTF9+vRDzq9fvz7Wrl0btbW1MWfOnJg9e/aABjpUDhw4EIsXL47t27dHXV1dPPDAA3HKKaf0+ppzzjknJk6c2HP87LPPRl1d3R891D6tWLEitmzZEjU1NbFkyZI499xze86999578cgjj0RdXV1MmzYtFixYUOJI+9fXXGbMmBEnn3xyz+u/atWqGDt2bFlD7dfWrVujqakpbrzxxpg3b16vc9W2Ln3NpdrWZeXKlfHRRx/FwYMH47bbbouZM2f2nKu2delrLtW0Lu3t7bF48eLYtWtX7N+/P5qamnq1peLWpTgK33zzTXH77bcXTU1Nxdtvv33I+ba2tmLmzJnFnj17ivb29uLaa68tWltbj+ZWQ+7ll18uli9fXhRFUbz77rvFwoULD/maiy666A8eVc4HH3xQ3HrrrUVRFMWXX35ZzJkzp9f5q6++uti+fXvR1dVVzJ07t/jiiy/KGOYR6W8u06dPL/bt21fG0NLa2tqKefPmFUuXLi2ee+65Q85X07r0N5dqWpfm5ubi5ptvLoqiKHbv3l1cdtllvc5X07r0N5dqWpfXXnuteOqpp4qiKIrvvvuumDlzZq/zlbYuR/XYtrGxMR5//PEYOXLkYc9v2bIlJkyYECNHjoxjjz02Jk6cGJs3bx5Q5IdKc3NzXHHFFRERcckll1TsOPvS3Nwcl19+eUREnHbaafHzzz/Hvn37IiLi22+/jRNOOCHGjRsXtbW1cdlll0Vzc3OZw+1TX3OpNg0NDfH000/HmDFjDjlXbevS11yqzeTJk+PRRx+NiIjjjz8+2tvbo6urKyKqb136mku1ueaaa+KWW26JiIgdO3b02iFX4roc1WPbYcOG9Xl+586dMXr06J7j0aNHR0tLy9Hcasj951hra2ujpqYmOjs7o6GhoedrOjs7Y9GiRbFt27a48sor46abbipruIe1c+fOOOecc3qOu1/v4447LlpaWg5Zi2+//baMYR6RvubSbdmyZbFt27a48MILY9GiRVFTU1PGUPtVX18f9fWH/ytWbevS11y6Vcu61NXVxfDhwyMi4qWXXopp06b1PNastnXpay7dqmVdut1www3x/fffxxNPPNHzuUpcl37juW7duli3bl2vz911111x6aWXHvFNigr5CYCHm8uWLVt6HR9urPfee2/MmjUrampqYt68eTFp0qSYMGHCkI51ICrl9R4Mv53L3XffHZdeemmccMIJsWDBgnjzzTfjqquuKml0dKvGdXnrrbfipZdeijVr1pQ9lAH7vblU47o8//zz8fnnn8c999wT69evr9jY9xvP2bNnp/+zz5gxY2Lnzp09xz/++GOcf/756cENtsPNZfHixdHS0hJnnnlmHDhwIIqi6LXrjIiYO3duz8cXX3xxbN26taLiebjXu7Gx8bDnfvjhh4p+9NbXXCIirr/++p6Pp02bFlu3bq34fwwOp9rWpT/Vti7vvvtuPPHEE/HMM8/0+vZTNa7L780lorrW5ZNPPomTTjopxo0bF2eddVZ0dXXF7t2746STTqrIdRmSt6qcd9558fHHH8eePXuira0tNm/eHJMmTRqKWw3Y1KlT44033oiIiA0bNsSUKVN6nf/qq69i0aJFURRFHDx4MDZv3hynn356GUP9XVOnTo0333wzIiI+/fTTGDNmTM9jzvHjx8e+ffviu+++i4MHD8aGDRti6tSpZQ63T33NZe/evTF//vzo7OyMiIiNGzdW3FocqWpbl75U27rs3bs3Vq5cGU8++WSceOKJvc5V27r0NZdqW5dNmzb17Jx37twZv/zyS4waNSoiKnNdjuq3qrzzzjuxevXq+Oqrr2L06NHR2NgYa9asiaeeeiomT54cF1xwQbzxxhuxevXqnkeds2bNGorxD1hXV1csXbo0vv7662hoaIgHH3wwxo0b12suDz/8cLz//vtRW1sbM2bMiDvuuKPsYR9i1apVsWnTpqipqYlly5bFZ599FiNHjowrrrgiNm7cGKtWrYqIiJkzZ8b8+fNLHm3f+prL2rVr45VXXoljjjkmzj777Lj//vsr9rHOJ598Eg899FBs27Yt6uvrY+zYsTFjxowYP3581a1Lf3OppnV54YUX4rHHHotTTz2153NTpkyJM844o+rWpb+5VNO6dHR0xH333Rc7duyIjo6OuPPOO+Onn36q2H/H/EoyAEjyE4YAIEk8ASBJPAEgSTwBIEk8ASBJPAEgSTwBIEk8ASDp/wA0ralT4VMmhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.boxplot(X_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189a69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7de1ad1",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4a07fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85289b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 21:36:08.655000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-21 21:36:08.655060: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-21 21:36:08.655097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (harsh): /proc/driver/nvidia/version does not exist\n",
      "2022-03-21 21:36:08.661766: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(50,activation='relu', input_shape=((X_train.shape[1],))))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1)) # by default linear_value z is activation of function if not passed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7424c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80a939c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f65b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile model\n",
    "\n",
    "# from keras.optimizer_v2.adam import Adam\n",
    "# opt = Adam(learning_rate=0.1)\n",
    "# model.compile(optimizer=opt, loss='log-mse')\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# try opt='adam' also\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_logarithmic_error')\n",
    "# 'accuracy' in keras is only for classification not for regression. Use other metrics\n",
    "# for regression, r2_score is best. But that isn't available here. So we need MSE or root_MSE\n",
    "# So leave that, bcoz that is sMe to log_MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "135f50db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 1s 215ms/step - loss: 142.4639 - val_loss: 139.3904\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 139.6619 - val_loss: 136.8307\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 137.1026 - val_loss: 134.5480\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 134.8181 - val_loss: 132.4379\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 132.7015 - val_loss: 130.5044\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 130.7308 - val_loss: 128.6380\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 128.8197 - val_loss: 126.7718\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 126.9009 - val_loss: 124.9336\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 125.0302 - val_loss: 123.1551\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 123.2181 - val_loss: 121.4354\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 121.4778 - val_loss: 119.7637\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 119.7883 - val_loss: 118.1323\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 118.1483 - val_loss: 116.5258\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 116.5413 - val_loss: 114.9283\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 114.9525 - val_loss: 113.3509\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 113.3691 - val_loss: 111.7818\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 111.8075 - val_loss: 110.2299\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 110.2626 - val_loss: 108.6835\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 108.7312 - val_loss: 107.1572\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 107.2060 - val_loss: 105.6274\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 105.6636 - val_loss: 104.1004\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 104.1325 - val_loss: 102.6051\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 102.6361 - val_loss: 101.1484\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 101.1784 - val_loss: 99.7353\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 99.7641 - val_loss: 98.3625\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 98.3875 - val_loss: 97.0229\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 97.0456 - val_loss: 95.7182\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 95.7340 - val_loss: 94.4414\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 94.4476 - val_loss: 93.1857\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 93.1862 - val_loss: 91.9489\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 91.9447 - val_loss: 90.7374\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 90.7267 - val_loss: 89.5451\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 89.5237 - val_loss: 88.3656\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 88.3349 - val_loss: 87.2066\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 87.1630 - val_loss: 86.0645\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 86.0083 - val_loss: 84.9388\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 84.8632 - val_loss: 83.8280\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 83.7309 - val_loss: 82.7385\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 82.6244 - val_loss: 81.6772\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 81.5486 - val_loss: 80.6428\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 80.5002 - val_loss: 79.6318\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 79.4772 - val_loss: 78.6464\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 78.4785 - val_loss: 77.6818\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 77.4988 - val_loss: 76.7350\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 76.5394 - val_loss: 75.8094\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 75.6005 - val_loss: 74.9001\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 74.6789 - val_loss: 74.0073\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 73.7742 - val_loss: 73.1287\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 72.8868 - val_loss: 72.2670\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 72.0140 - val_loss: 71.4202\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 71.1556 - val_loss: 70.5870\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 70.3111 - val_loss: 69.7664\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 69.4803 - val_loss: 68.9583\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 68.6634 - val_loss: 68.1620\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 67.8600 - val_loss: 67.3796\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 67.0686 - val_loss: 66.6082\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 66.2892 - val_loss: 65.8480\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 65.5206 - val_loss: 65.0977\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 64.7629 - val_loss: 64.3588\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 64.0185 - val_loss: 63.6317\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 63.2825 - val_loss: 62.9127\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 62.5573 - val_loss: 62.2043\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 61.8422 - val_loss: 61.5054\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 61.1367 - val_loss: 60.8156\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 60.4389 - val_loss: 60.1349\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 59.7525 - val_loss: 59.4638\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 59.0746 - val_loss: 58.8015\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 58.4067 - val_loss: 58.1482\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 57.7467 - val_loss: 57.5015\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 57.0956 - val_loss: 56.8654\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 56.4530 - val_loss: 56.2370\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 55.8198 - val_loss: 55.6171\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 55.1953 - val_loss: 55.0061\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 54.5787 - val_loss: 54.4027\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 53.9713 - val_loss: 53.8061\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 53.3706 - val_loss: 53.2191\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 52.7798 - val_loss: 52.6393\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 52.1965 - val_loss: 52.0672\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 51.6211 - val_loss: 51.5038\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 51.0541 - val_loss: 50.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 50.4943 - val_loss: 50.3978\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 49.9424 - val_loss: 49.8560\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 49.3980 - val_loss: 49.3218\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 48.8613 - val_loss: 48.7947\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 48.3311 - val_loss: 48.2736\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 47.8075 - val_loss: 47.7594\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 47.2910 - val_loss: 47.2522\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 46.7819 - val_loss: 46.7513\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 46.2784 - val_loss: 46.2566\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 45.7816 - val_loss: 45.7686\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 45.2922 - val_loss: 45.2859\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 44.8082 - val_loss: 44.8097\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 44.3311 - val_loss: 44.3399\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 43.8594 - val_loss: 43.8755\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 43.3944 - val_loss: 43.4176\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 42.9349 - val_loss: 42.9649\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 42.4818 - val_loss: 42.5181\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 42.0335 - val_loss: 42.0772\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 41.5912 - val_loss: 41.6413\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 41.1539 - val_loss: 41.2110\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 40.7226 - val_loss: 40.7859\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 40.2957 - val_loss: 40.3651\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 39.8745 - val_loss: 39.9500\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 39.4590 - val_loss: 39.5400\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 39.0480 - val_loss: 39.1346\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 38.6413 - val_loss: 38.7338\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 38.2404 - val_loss: 38.3372\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 37.8440 - val_loss: 37.9462\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 37.4515 - val_loss: 37.5585\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 37.0633 - val_loss: 37.1756\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 36.6801 - val_loss: 36.7971\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 36.3005 - val_loss: 36.4224\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 35.9261 - val_loss: 36.0517\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 35.5557 - val_loss: 35.6859\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 35.1900 - val_loss: 35.3246\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 34.8282 - val_loss: 34.9664\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 34.4703 - val_loss: 34.6123\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 34.1166 - val_loss: 34.2614\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 33.7664 - val_loss: 33.9151\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 33.4206 - val_loss: 33.5728\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 33.0788 - val_loss: 33.2340\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 32.7401 - val_loss: 32.8987\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 32.4055 - val_loss: 32.5678\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 32.0746 - val_loss: 32.2399\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 31.7472 - val_loss: 31.9159\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 31.4236 - val_loss: 31.5956\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 31.1030 - val_loss: 31.2783\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 30.7864 - val_loss: 30.9646\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 30.4731 - val_loss: 30.6538\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 30.1631 - val_loss: 30.3464\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 29.8569 - val_loss: 30.0432\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 29.5547 - val_loss: 29.7432\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 29.2545 - val_loss: 29.4456\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 28.9583 - val_loss: 29.1524\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 28.6652 - val_loss: 28.8615\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 28.3748 - val_loss: 28.5735\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 28.0878 - val_loss: 28.2885\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 27.8037 - val_loss: 28.0067\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 27.5229 - val_loss: 27.7278\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 27.2447 - val_loss: 27.4517\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 26.9699 - val_loss: 27.1793\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 26.6983 - val_loss: 26.9096\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 26.4294 - val_loss: 26.6424\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 26.1631 - val_loss: 26.3781\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 25.8998 - val_loss: 26.1163\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 25.6393 - val_loss: 25.8575\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 25.3816 - val_loss: 25.6012\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25.1264 - val_loss: 25.3473\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 24.8737 - val_loss: 25.0963\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 24.6233 - val_loss: 24.8476\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 24.3759 - val_loss: 24.6014\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 24.1312 - val_loss: 24.3577\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 23.8887 - val_loss: 24.1163\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 23.6485 - val_loss: 23.8776\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 23.4110 - val_loss: 23.6410\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 23.1758 - val_loss: 23.4072\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 22.9437 - val_loss: 23.1754\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 22.7132 - val_loss: 22.9463\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 22.4855 - val_loss: 22.7196\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 22.2603 - val_loss: 22.4951\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 22.0367 - val_loss: 22.2730\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 21.8159 - val_loss: 22.0530\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 21.5969 - val_loss: 21.8352\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 21.3802 - val_loss: 21.6190\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 21.1654 - val_loss: 21.4056\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 20.9531 - val_loss: 21.1936\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 20.7425 - val_loss: 20.9839\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 20.5342 - val_loss: 20.7762\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 20.3284 - val_loss: 20.5709\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 20.1239 - val_loss: 20.3678\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 19.9220 - val_loss: 20.1665\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 19.7220 - val_loss: 19.9671\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 19.5239 - val_loss: 19.7698\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 19.3277 - val_loss: 19.5737\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 19.1334 - val_loss: 19.3804\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 18.9411 - val_loss: 19.1884\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18.7509 - val_loss: 18.9986\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 18.5623 - val_loss: 18.8100\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 18.3754 - val_loss: 18.6238\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 18.1903 - val_loss: 18.4391\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 18.0072 - val_loss: 18.2561\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 17.8259 - val_loss: 18.0753\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 17.6466 - val_loss: 17.8966\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 17.4687 - val_loss: 17.7188\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 17.2926 - val_loss: 17.5427\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 17.1180 - val_loss: 17.3682\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 16.9449 - val_loss: 17.1950\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16.7734 - val_loss: 17.0239\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 16.6037 - val_loss: 16.8541\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16.4356 - val_loss: 16.6866\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 16.2692 - val_loss: 16.5203\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 16.1046 - val_loss: 16.3554\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 15.9411 - val_loss: 16.1924\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 15.7797 - val_loss: 16.0309\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 15.6194 - val_loss: 15.8709\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 15.4607 - val_loss: 15.7121\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 15.3036 - val_loss: 15.5550\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 15.1478 - val_loss: 15.3993\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 14.9938 - val_loss: 15.2450\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.8409 - val_loss: 15.0924\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 14.6899 - val_loss: 14.9413\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.5399 - val_loss: 14.7911\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 14.3915 - val_loss: 14.6429\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 14.2443 - val_loss: 14.4957\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.0985 - val_loss: 14.3498\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 13.9542 - val_loss: 14.2050\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 13.8109 - val_loss: 14.0618\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 13.6692 - val_loss: 13.9201\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 13.5291 - val_loss: 13.7796\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 13.3898 - val_loss: 13.6404\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 13.2520 - val_loss: 13.5024\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 13.1155 - val_loss: 13.3659\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 12.9804 - val_loss: 13.2303\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 12.8465 - val_loss: 13.0961\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 12.7137 - val_loss: 12.9628\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 12.5822 - val_loss: 12.8311\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12.4518 - val_loss: 12.7005\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.3228 - val_loss: 12.5713\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12.1950 - val_loss: 12.4431\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 12.0681 - val_loss: 12.3156\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 11.9424 - val_loss: 12.1900\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 11.8180 - val_loss: 12.0651\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 11.6945 - val_loss: 11.9412\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11.5726 - val_loss: 11.8190\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 11.4514 - val_loss: 11.6972\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11.3316 - val_loss: 11.5772\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11.2127 - val_loss: 11.4579\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 11.0951 - val_loss: 11.3401\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10.9785 - val_loss: 11.2230\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 10.8628 - val_loss: 11.1070\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 10.7481 - val_loss: 10.9917\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10.6346 - val_loss: 10.8782\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 10.5223 - val_loss: 10.7652\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10.4108 - val_loss: 10.6534\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10.3003 - val_loss: 10.5421\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 10.1905 - val_loss: 10.4320\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10.0821 - val_loss: 10.3233\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9.9746 - val_loss: 10.2151\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 41ms/step - loss: 9.8679 - val_loss: 10.1077\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9.7622 - val_loss: 10.0019\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 9.6576 - val_loss: 9.8967\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 9.5540 - val_loss: 9.7925\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 9.4513 - val_loss: 9.6895\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 9.3496 - val_loss: 9.5872\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9.2490 - val_loss: 9.4859\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9.1491 - val_loss: 9.3854\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9.0499 - val_loss: 9.2858\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 8.9519 - val_loss: 9.1872\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 8.8549 - val_loss: 9.0894\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 8.7586 - val_loss: 8.9927\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 8.6632 - val_loss: 8.8968\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 8.5687 - val_loss: 8.8018\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 8.4751 - val_loss: 8.7076\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 8.3823 - val_loss: 8.6143\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.2904 - val_loss: 8.5218\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.1993 - val_loss: 8.4302\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.1090 - val_loss: 8.3393\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 8.0194 - val_loss: 8.2489\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 7.9306 - val_loss: 8.1598\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 7.8428 - val_loss: 8.0709\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 7.7556 - val_loss: 7.9834\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 7.6695 - val_loss: 7.8966\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 7.5839 - val_loss: 7.8104\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.4994 - val_loss: 7.7249\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 7.4152 - val_loss: 7.6405\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.3323 - val_loss: 7.5570\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 7.2500 - val_loss: 7.4740\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 7.1683 - val_loss: 7.3917\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.0876 - val_loss: 7.3102\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 7.0074 - val_loss: 7.2293\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.9279 - val_loss: 7.1493\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.8493 - val_loss: 7.0701\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.7714 - val_loss: 6.9915\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.6942 - val_loss: 6.9135\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.6178 - val_loss: 6.8363\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.5417 - val_loss: 6.7597\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6.4666 - val_loss: 6.6839\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 6.3921 - val_loss: 6.6086\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.3184 - val_loss: 6.5342\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.2453 - val_loss: 6.4604\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.1729 - val_loss: 6.3873\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.1011 - val_loss: 6.3148\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.0301 - val_loss: 6.2431\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.9597 - val_loss: 6.1723\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 5.8901 - val_loss: 6.1017\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.8210 - val_loss: 6.0321\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.7525 - val_loss: 5.9630\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 5.6848 - val_loss: 5.8942\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 5.6175 - val_loss: 5.8265\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 5.5509 - val_loss: 5.7591\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 5.4850 - val_loss: 5.6923\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.4197 - val_loss: 5.6263\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.3551 - val_loss: 5.5606\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.2907 - val_loss: 5.4957\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 5.2271 - val_loss: 5.4315\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 5.1644 - val_loss: 5.3681\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 5.1022 - val_loss: 5.3051\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.0404 - val_loss: 5.2425\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 4.9792 - val_loss: 5.1806\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 4.9186 - val_loss: 5.1192\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.8586 - val_loss: 5.0585\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.7992 - val_loss: 4.9983\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 4.7403 - val_loss: 4.9385\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.6819 - val_loss: 4.8794\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.6240 - val_loss: 4.8210\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 4.5669 - val_loss: 4.7631\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 4.5104 - val_loss: 4.7058\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.4544 - val_loss: 4.6488\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.3987 - val_loss: 4.5925\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.3437 - val_loss: 4.5367\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4.2892 - val_loss: 4.4815\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.2352 - val_loss: 4.4266\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 4.1819 - val_loss: 4.3726\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.1291 - val_loss: 4.3190\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.0767 - val_loss: 4.2658\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.0248 - val_loss: 4.2130\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.9735 - val_loss: 4.1608\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.9226 - val_loss: 4.1093\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.8723 - val_loss: 4.0582\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.8225 - val_loss: 4.0075\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7731 - val_loss: 3.9572\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.7239 - val_loss: 3.9075\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.6754 - val_loss: 3.8582\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.6275 - val_loss: 3.8094\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.5799 - val_loss: 3.7611\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.5329 - val_loss: 3.7133\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.4864 - val_loss: 3.6659\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.4402 - val_loss: 3.6191\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.3947 - val_loss: 3.5728\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.3496 - val_loss: 3.5269\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.3048 - val_loss: 3.4814\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.2606 - val_loss: 3.4363\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.2168 - val_loss: 3.3918\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.1736 - val_loss: 3.3475\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.1307 - val_loss: 3.3039\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.0883 - val_loss: 3.2605\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.0462 - val_loss: 3.2177\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.0046 - val_loss: 3.1753\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9634 - val_loss: 3.1332\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.9227 - val_loss: 3.0918\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8825 - val_loss: 3.0509\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.8427 - val_loss: 3.0102\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.8031 - val_loss: 2.9698\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.7641 - val_loss: 2.9298\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.7253 - val_loss: 2.8903\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.6871 - val_loss: 2.8513\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.6495 - val_loss: 2.8125\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.6120 - val_loss: 2.7744\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.5751 - val_loss: 2.7367\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.5387 - val_loss: 2.6994\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.5027 - val_loss: 2.6626\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.4669 - val_loss: 2.6258\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.4314 - val_loss: 2.5896\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.3964 - val_loss: 2.5539\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.3617 - val_loss: 2.5182\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.3274 - val_loss: 2.4832\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.2934 - val_loss: 2.4483\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2.2598 - val_loss: 2.4139\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2267 - val_loss: 2.3799\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1939 - val_loss: 2.3463\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1614 - val_loss: 2.3130\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1294 - val_loss: 2.2800\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.0976 - val_loss: 2.2475\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0662 - val_loss: 2.2153\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0351 - val_loss: 2.1833\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2.0045 - val_loss: 2.1520\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.9742 - val_loss: 2.1209\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.9442 - val_loss: 2.0900\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.9146 - val_loss: 2.0597\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.8854 - val_loss: 2.0297\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.8565 - val_loss: 1.9998\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.8278 - val_loss: 1.9704\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.7996 - val_loss: 1.9412\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.7716 - val_loss: 1.9125\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.7441 - val_loss: 1.8842\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.7170 - val_loss: 1.8561\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.6900 - val_loss: 1.8283\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.6634 - val_loss: 1.8009\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6372 - val_loss: 1.7739\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.6113 - val_loss: 1.7470\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.5856 - val_loss: 1.7205\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.5604 - val_loss: 1.6945\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5354 - val_loss: 1.6687\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.5107 - val_loss: 1.6430\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.4862 - val_loss: 1.6177\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.4621 - val_loss: 1.5929\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.4383 - val_loss: 1.5682\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.4148 - val_loss: 1.5439\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.3917 - val_loss: 1.5199\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.3688 - val_loss: 1.4961\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.3461 - val_loss: 1.4726\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.3238 - val_loss: 1.4495\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3017 - val_loss: 1.4267\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.2800 - val_loss: 1.4039\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2584 - val_loss: 1.3816\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.2374 - val_loss: 1.3597\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.2166 - val_loss: 1.3381\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1961 - val_loss: 1.3168\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1759 - val_loss: 1.2957\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1560 - val_loss: 1.2750\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1363 - val_loss: 1.2543\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1169 - val_loss: 1.2342\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0978 - val_loss: 1.2140\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0787 - val_loss: 1.1941\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0601 - val_loss: 1.1747\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.0418 - val_loss: 1.1556\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0236 - val_loss: 1.1366\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0058 - val_loss: 1.1179\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9883 - val_loss: 1.0996\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.9709 - val_loss: 1.0812\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.9536 - val_loss: 1.0630\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.9366 - val_loss: 1.0454\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9201 - val_loss: 1.0281\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9038 - val_loss: 1.0109\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8877 - val_loss: 0.9940\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.8720 - val_loss: 0.9774\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8565 - val_loss: 0.9611\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8412 - val_loss: 0.9449\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8261 - val_loss: 0.9290\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8111 - val_loss: 0.9132\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7964 - val_loss: 0.8978\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7820 - val_loss: 0.8824\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7678 - val_loss: 0.8675\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7539 - val_loss: 0.8527\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7402 - val_loss: 0.8381\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7267 - val_loss: 0.8239\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7135 - val_loss: 0.8098\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7004 - val_loss: 0.7958\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6875 - val_loss: 0.7822\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6749 - val_loss: 0.7687\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6626 - val_loss: 0.7555\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6504 - val_loss: 0.7425\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6384 - val_loss: 0.7298\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6267 - val_loss: 0.7171\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6151 - val_loss: 0.7047\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6038 - val_loss: 0.6926\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5927 - val_loss: 0.6806\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5818 - val_loss: 0.6690\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5712 - val_loss: 0.6574\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5606 - val_loss: 0.6461\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5504 - val_loss: 0.6351\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5404 - val_loss: 0.6241\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5304 - val_loss: 0.6134\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5206 - val_loss: 0.6029\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5111 - val_loss: 0.5925\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5018 - val_loss: 0.5824\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4927 - val_loss: 0.5725\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4837 - val_loss: 0.5627\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4749 - val_loss: 0.5530\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4663 - val_loss: 0.5437\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4578 - val_loss: 0.5344\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4496 - val_loss: 0.5254\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4414 - val_loss: 0.5164\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4334 - val_loss: 0.5076\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4257 - val_loss: 0.4992\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4182 - val_loss: 0.4909\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4108 - val_loss: 0.4828\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4036 - val_loss: 0.4749\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3966 - val_loss: 0.4669\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3896 - val_loss: 0.4593\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3829 - val_loss: 0.4518\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3763 - val_loss: 0.4444\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3698 - val_loss: 0.4373\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3636 - val_loss: 0.4304\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3575 - val_loss: 0.4236\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3516 - val_loss: 0.4170\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3458 - val_loss: 0.4103\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3400 - val_loss: 0.4040\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3346 - val_loss: 0.3978\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3292 - val_loss: 0.3916\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3238 - val_loss: 0.3856\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3187 - val_loss: 0.3798\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3137 - val_loss: 0.3741\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3088 - val_loss: 0.3686\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3041 - val_loss: 0.3632\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2995 - val_loss: 0.3579\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2951 - val_loss: 0.3529\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2908 - val_loss: 0.3480\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2866 - val_loss: 0.3430\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2824 - val_loss: 0.3382\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2784 - val_loss: 0.3336\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2745 - val_loss: 0.3291\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2707 - val_loss: 0.3247\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2671 - val_loss: 0.3204\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2635 - val_loss: 0.3162\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2600 - val_loss: 0.3122\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2567 - val_loss: 0.3082\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2534 - val_loss: 0.3043\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2502 - val_loss: 0.3006\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2472 - val_loss: 0.2970\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2442 - val_loss: 0.2935\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2413 - val_loss: 0.2900\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2385 - val_loss: 0.2866\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2357 - val_loss: 0.2833\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2330 - val_loss: 0.2801\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2305 - val_loss: 0.2769\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2280 - val_loss: 0.2739\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2254 - val_loss: 0.2709\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2231 - val_loss: 0.2680\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2207 - val_loss: 0.2652\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2184 - val_loss: 0.2624\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2162 - val_loss: 0.2598\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2141 - val_loss: 0.2571\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2120 - val_loss: 0.2545\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2100 - val_loss: 0.2520\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2079 - val_loss: 0.2495\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2060 - val_loss: 0.2472\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2042 - val_loss: 0.2449\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2024 - val_loss: 0.2427\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2007 - val_loss: 0.2405\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1989 - val_loss: 0.2384\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1972 - val_loss: 0.2363\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1956 - val_loss: 0.2342\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1940 - val_loss: 0.2322\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1925 - val_loss: 0.2303\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1911 - val_loss: 0.2286\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1895 - val_loss: 0.2267\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1881 - val_loss: 0.2249\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.1867 - val_loss: 0.2232\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1853 - val_loss: 0.2215\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1840 - val_loss: 0.2199\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1827 - val_loss: 0.2182\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1814 - val_loss: 0.2166\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1801 - val_loss: 0.2151\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1789 - val_loss: 0.2135\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1776 - val_loss: 0.2120\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1764 - val_loss: 0.2106\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1753 - val_loss: 0.2092\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1741 - val_loss: 0.2077\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1729 - val_loss: 0.2062\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1718 - val_loss: 0.2048\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1706 - val_loss: 0.2035\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1695 - val_loss: 0.2023\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1684 - val_loss: 0.2011\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1673 - val_loss: 0.1999\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1663 - val_loss: 0.1985\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1652 - val_loss: 0.1974\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1641 - val_loss: 0.1960\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1631 - val_loss: 0.1948\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1620 - val_loss: 0.1937\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1610 - val_loss: 0.1926\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1599 - val_loss: 0.1914\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1589 - val_loss: 0.1903\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1579 - val_loss: 0.1892\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1569 - val_loss: 0.1880\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1560 - val_loss: 0.1870\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1549 - val_loss: 0.1859\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1539 - val_loss: 0.1848\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1530 - val_loss: 0.1838\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1520 - val_loss: 0.1826\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1511 - val_loss: 0.1814\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1501 - val_loss: 0.1804\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1491 - val_loss: 0.1794\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1482 - val_loss: 0.1782\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1472 - val_loss: 0.1772\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1463 - val_loss: 0.1761\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1453 - val_loss: 0.1751\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1444 - val_loss: 0.1742\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1435 - val_loss: 0.1732\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1425 - val_loss: 0.1721\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1418 - val_loss: 0.1710\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1408 - val_loss: 0.1701\n",
      "Epoch 563/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1398 - val_loss: 0.1692\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1389 - val_loss: 0.1682\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1380 - val_loss: 0.1671\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1371 - val_loss: 0.1662\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1363 - val_loss: 0.1653\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1354 - val_loss: 0.1643\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1346 - val_loss: 0.1632\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1337 - val_loss: 0.1623\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1328 - val_loss: 0.1613\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1321 - val_loss: 0.1604\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.1312 - val_loss: 0.1595\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1303 - val_loss: 0.1586\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1295 - val_loss: 0.1577\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1287 - val_loss: 0.1567\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1278 - val_loss: 0.1559\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1270 - val_loss: 0.1550\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1262 - val_loss: 0.1541\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1254 - val_loss: 0.1533\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1246 - val_loss: 0.1524\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1237 - val_loss: 0.1515\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1229 - val_loss: 0.1507\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1222 - val_loss: 0.1499\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1214 - val_loss: 0.1491\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1205 - val_loss: 0.1481\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1197 - val_loss: 0.1473\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1190 - val_loss: 0.1465\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1182 - val_loss: 0.1456\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1174 - val_loss: 0.1448\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1167 - val_loss: 0.1439\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1159 - val_loss: 0.1430\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1151 - val_loss: 0.1421\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1143 - val_loss: 0.1413\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1136 - val_loss: 0.1405\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1128 - val_loss: 0.1396\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1121 - val_loss: 0.1389\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1113 - val_loss: 0.1382\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1106 - val_loss: 0.1375\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1099 - val_loss: 0.1367\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1091 - val_loss: 0.1357\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1085 - val_loss: 0.1349\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1077 - val_loss: 0.1341\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1070 - val_loss: 0.1333\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1063 - val_loss: 0.1326\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1056 - val_loss: 0.1318\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1049 - val_loss: 0.1312\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1042 - val_loss: 0.1305\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1035 - val_loss: 0.1298\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1029 - val_loss: 0.1292\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1021 - val_loss: 0.1283\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1015 - val_loss: 0.1276\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1008 - val_loss: 0.1268\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1001 - val_loss: 0.1260\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0995 - val_loss: 0.1254\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0988 - val_loss: 0.1248\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0982 - val_loss: 0.1239\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0975 - val_loss: 0.1232\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0969 - val_loss: 0.1225\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0962 - val_loss: 0.1218\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0955 - val_loss: 0.1211\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0949 - val_loss: 0.1204\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0943 - val_loss: 0.1198\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0936 - val_loss: 0.1190\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0930 - val_loss: 0.1184\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0924 - val_loss: 0.1177\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0918 - val_loss: 0.1169\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0912 - val_loss: 0.1163\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0905 - val_loss: 0.1156\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0900 - val_loss: 0.1151\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0893 - val_loss: 0.1144\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0888 - val_loss: 0.1138\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0882 - val_loss: 0.1130\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0877 - val_loss: 0.1123\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0870 - val_loss: 0.1118\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0865 - val_loss: 0.1112\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0859 - val_loss: 0.1106\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0853 - val_loss: 0.1099\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0847 - val_loss: 0.1092\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0842 - val_loss: 0.1086\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0836 - val_loss: 0.1080\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0831 - val_loss: 0.1075\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0825 - val_loss: 0.1068\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0820 - val_loss: 0.1062\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0814 - val_loss: 0.1057\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0809 - val_loss: 0.1050\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0803 - val_loss: 0.1045\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0798 - val_loss: 0.1038\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0793 - val_loss: 0.1032\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0787 - val_loss: 0.1026\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0782 - val_loss: 0.1020\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0777 - val_loss: 0.1015\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0772 - val_loss: 0.1009\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0767 - val_loss: 0.1004\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0762 - val_loss: 0.0999\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0757 - val_loss: 0.0993\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0752 - val_loss: 0.0987\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0747 - val_loss: 0.0982\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0742 - val_loss: 0.0977\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0737 - val_loss: 0.0971\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0733 - val_loss: 0.0966\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0728 - val_loss: 0.0960\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0724 - val_loss: 0.0955\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0719 - val_loss: 0.0950\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0715 - val_loss: 0.0946\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0710 - val_loss: 0.0941\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0705 - val_loss: 0.0935\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0701 - val_loss: 0.0930\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0696 - val_loss: 0.0925\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0693 - val_loss: 0.0921\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0688 - val_loss: 0.0917\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0683 - val_loss: 0.0912\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0680 - val_loss: 0.0907\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0675 - val_loss: 0.0902\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0671 - val_loss: 0.0898\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0667 - val_loss: 0.0893\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0663 - val_loss: 0.0889\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0659 - val_loss: 0.0885\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0655 - val_loss: 0.0880\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0651 - val_loss: 0.0876\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0647 - val_loss: 0.0871\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0644 - val_loss: 0.0866\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0639 - val_loss: 0.0861\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0636 - val_loss: 0.0857\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0632 - val_loss: 0.0853\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0628 - val_loss: 0.0849\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0624 - val_loss: 0.0844\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0621 - val_loss: 0.0840\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0617 - val_loss: 0.0836\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0614 - val_loss: 0.0832\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0610 - val_loss: 0.0828\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0606 - val_loss: 0.0825\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0603 - val_loss: 0.0821\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0600 - val_loss: 0.0817\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0596 - val_loss: 0.0813\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0593 - val_loss: 0.0809\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0589 - val_loss: 0.0805\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0586 - val_loss: 0.0801\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0583 - val_loss: 0.0798\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0579 - val_loss: 0.0793\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0577 - val_loss: 0.0790\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0573 - val_loss: 0.0786\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0570 - val_loss: 0.0783\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0567 - val_loss: 0.0779\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0565 - val_loss: 0.0776\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0562 - val_loss: 0.0772\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0559 - val_loss: 0.0769\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0555 - val_loss: 0.0765\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0552 - val_loss: 0.0762\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0550 - val_loss: 0.0759\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0547 - val_loss: 0.0756\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0544 - val_loss: 0.0752\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0542 - val_loss: 0.0749\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0539 - val_loss: 0.0746\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0536 - val_loss: 0.0743\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0533 - val_loss: 0.0740\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0530 - val_loss: 0.0737\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0528 - val_loss: 0.0734\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0525 - val_loss: 0.0731\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0523 - val_loss: 0.0728\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0520 - val_loss: 0.0725\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0518 - val_loss: 0.0723\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0515 - val_loss: 0.0720\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0513 - val_loss: 0.0717\n",
      "Epoch 725/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0510 - val_loss: 0.0714\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0508 - val_loss: 0.0711\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0505 - val_loss: 0.0708\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0503 - val_loss: 0.0706\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0500 - val_loss: 0.0703\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0498 - val_loss: 0.0700\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0496 - val_loss: 0.0698\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0493 - val_loss: 0.0695\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0491 - val_loss: 0.0692\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0488 - val_loss: 0.0690\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0487 - val_loss: 0.0687\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0484 - val_loss: 0.0685\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0482 - val_loss: 0.0682\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0480 - val_loss: 0.0680\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0478 - val_loss: 0.0677\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0475 - val_loss: 0.0675\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0474 - val_loss: 0.0673\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0471 - val_loss: 0.0670\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0469 - val_loss: 0.0668\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0467 - val_loss: 0.0666\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0465 - val_loss: 0.0663\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0464 - val_loss: 0.0661\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0462 - val_loss: 0.0659\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0459 - val_loss: 0.0657\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0459 - val_loss: 0.0655\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0455 - val_loss: 0.0652\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0454 - val_loss: 0.0650\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0452 - val_loss: 0.0648\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0451 - val_loss: 0.0646\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0448 - val_loss: 0.0644\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0447 - val_loss: 0.0643\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0445 - val_loss: 0.0641\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0443 - val_loss: 0.0639\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0441 - val_loss: 0.0637\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0440 - val_loss: 0.0635\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0438 - val_loss: 0.0633\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0437 - val_loss: 0.0632\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0435 - val_loss: 0.0630\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0433 - val_loss: 0.0628\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0432 - val_loss: 0.0626\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0430 - val_loss: 0.0625\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0428 - val_loss: 0.0623\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0426 - val_loss: 0.0621\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0424 - val_loss: 0.0619\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0423 - val_loss: 0.0618\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0421 - val_loss: 0.0616\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0420 - val_loss: 0.0614\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0418 - val_loss: 0.0613\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0416 - val_loss: 0.0611\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0415 - val_loss: 0.0610\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0415 - val_loss: 0.0608\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0412 - val_loss: 0.0607\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0411 - val_loss: 0.0605\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0409 - val_loss: 0.0604\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0407 - val_loss: 0.0602\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0407 - val_loss: 0.0601\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0405 - val_loss: 0.0600\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0403 - val_loss: 0.0599\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0402 - val_loss: 0.0597\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0402 - val_loss: 0.0596\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0399 - val_loss: 0.0594\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0398 - val_loss: 0.0593\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0397 - val_loss: 0.0591\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0395 - val_loss: 0.0590\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0394 - val_loss: 0.0589\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0393 - val_loss: 0.0588\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0391 - val_loss: 0.0586\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0390 - val_loss: 0.0585\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0389 - val_loss: 0.0584\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0387 - val_loss: 0.0582\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0386 - val_loss: 0.0581\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0385 - val_loss: 0.0580\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0384 - val_loss: 0.0578\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0382 - val_loss: 0.0577\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0381 - val_loss: 0.0576\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0380 - val_loss: 0.0575\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0378 - val_loss: 0.0573\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0377 - val_loss: 0.0572\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0376 - val_loss: 0.0571\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0375 - val_loss: 0.0570\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0374 - val_loss: 0.0569\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0372 - val_loss: 0.0567\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0371 - val_loss: 0.0566\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0370 - val_loss: 0.0565\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0369 - val_loss: 0.0563\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0368 - val_loss: 0.0562\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0367 - val_loss: 0.0562\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0365 - val_loss: 0.0560\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0364 - val_loss: 0.0559\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0363 - val_loss: 0.0558\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0362 - val_loss: 0.0558\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0361 - val_loss: 0.0557\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0360 - val_loss: 0.0556\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0359 - val_loss: 0.0554\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0358 - val_loss: 0.0553\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0357 - val_loss: 0.0552\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0355 - val_loss: 0.0551\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0354 - val_loss: 0.0550\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0354 - val_loss: 0.0549\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0352 - val_loss: 0.0548\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0351 - val_loss: 0.0546\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0350 - val_loss: 0.0545\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0349 - val_loss: 0.0544\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0348 - val_loss: 0.0543\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0347 - val_loss: 0.0542\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0346 - val_loss: 0.0541\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0345 - val_loss: 0.0540\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0344 - val_loss: 0.0540\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0343 - val_loss: 0.0538\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0342 - val_loss: 0.0537\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0341 - val_loss: 0.0537\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0340 - val_loss: 0.0536\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0340 - val_loss: 0.0535\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0338 - val_loss: 0.0534\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0533\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0532\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0336 - val_loss: 0.0532\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0335 - val_loss: 0.0530\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0334 - val_loss: 0.0529\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0333 - val_loss: 0.0528\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0332 - val_loss: 0.0527\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0331 - val_loss: 0.0526\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0330 - val_loss: 0.0525\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0329 - val_loss: 0.0524\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0328 - val_loss: 0.0523\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0328 - val_loss: 0.0523\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0326 - val_loss: 0.0522\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0326 - val_loss: 0.0520\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0325 - val_loss: 0.0520\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0324 - val_loss: 0.0519\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0324 - val_loss: 0.0518\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.0517\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0322 - val_loss: 0.0516\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0321 - val_loss: 0.0515\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0320 - val_loss: 0.0515\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0319 - val_loss: 0.0514\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0318 - val_loss: 0.0514\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0318 - val_loss: 0.0513\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0317 - val_loss: 0.0512\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0316 - val_loss: 0.0511\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0315 - val_loss: 0.0510\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0314 - val_loss: 0.0510\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0313 - val_loss: 0.0508\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0313 - val_loss: 0.0508\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0312 - val_loss: 0.0506\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0311 - val_loss: 0.0506\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0311 - val_loss: 0.0506\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0310 - val_loss: 0.0504\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0309 - val_loss: 0.0503\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0309 - val_loss: 0.0503\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0307 - val_loss: 0.0502\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0307 - val_loss: 0.0501\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0306 - val_loss: 0.0500\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0305 - val_loss: 0.0499\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0304 - val_loss: 0.0499\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0304 - val_loss: 0.0498\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0303 - val_loss: 0.0497\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0302 - val_loss: 0.0497\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0302 - val_loss: 0.0497\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0301 - val_loss: 0.0496\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0300 - val_loss: 0.0495\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0299 - val_loss: 0.0494\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0298 - val_loss: 0.0493\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0298 - val_loss: 0.0492\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0297 - val_loss: 0.0492\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0297 - val_loss: 0.0491\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0296 - val_loss: 0.0490\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0295 - val_loss: 0.0490\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0294 - val_loss: 0.0489\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0293 - val_loss: 0.0488\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0293 - val_loss: 0.0487\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0292 - val_loss: 0.0487\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0292 - val_loss: 0.0487\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0291 - val_loss: 0.0486\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0291 - val_loss: 0.0486\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0290 - val_loss: 0.0485\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0289 - val_loss: 0.0484\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0288 - val_loss: 0.0483\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0288 - val_loss: 0.0482\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0287 - val_loss: 0.0481\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0286 - val_loss: 0.0481\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0286 - val_loss: 0.0480\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0285 - val_loss: 0.0479\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0285 - val_loss: 0.0478\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0284 - val_loss: 0.0479\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0283 - val_loss: 0.0478\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0282 - val_loss: 0.0477\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0282 - val_loss: 0.0477\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0281 - val_loss: 0.0476\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0281 - val_loss: 0.0476\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0280 - val_loss: 0.0475\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0279 - val_loss: 0.0474\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0279 - val_loss: 0.0473\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0278 - val_loss: 0.0473\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0277 - val_loss: 0.0472\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0277 - val_loss: 0.0471\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0277 - val_loss: 0.0470\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0276 - val_loss: 0.0470\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0275 - val_loss: 0.0469\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0275 - val_loss: 0.0468\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0274 - val_loss: 0.0468\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0273 - val_loss: 0.0468\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0273 - val_loss: 0.0467\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0272 - val_loss: 0.0466\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0272 - val_loss: 0.0467\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0271 - val_loss: 0.0465\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0270 - val_loss: 0.0464\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0270 - val_loss: 0.0463\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0269 - val_loss: 0.0464\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0268 - val_loss: 0.0462\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0268 - val_loss: 0.0462\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0267 - val_loss: 0.0461\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0267 - val_loss: 0.0461\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0266 - val_loss: 0.0461\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0266 - val_loss: 0.0461\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0265 - val_loss: 0.0459\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0264 - val_loss: 0.0459\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0264 - val_loss: 0.0458\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0263 - val_loss: 0.0457\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0263 - val_loss: 0.0456\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0262 - val_loss: 0.0456\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0262 - val_loss: 0.0456\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0261 - val_loss: 0.0455\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0261 - val_loss: 0.0454\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0260 - val_loss: 0.0454\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0259 - val_loss: 0.0453\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0259 - val_loss: 0.0453\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0258 - val_loss: 0.0452\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0259 - val_loss: 0.0452\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0257 - val_loss: 0.0451\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0257 - val_loss: 0.0450\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0256 - val_loss: 0.0449\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0256 - val_loss: 0.0449\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0255 - val_loss: 0.0448\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0255 - val_loss: 0.0448\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0254 - val_loss: 0.0447\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0254 - val_loss: 0.0446\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0253 - val_loss: 0.0445\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0252 - val_loss: 0.0445\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0252 - val_loss: 0.0445\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0251 - val_loss: 0.0445\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0251 - val_loss: 0.0443\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0251 - val_loss: 0.0442\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0250 - val_loss: 0.0443\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0249 - val_loss: 0.0442\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0249 - val_loss: 0.0441\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0248 - val_loss: 0.0440\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0248 - val_loss: 0.0441\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0247 - val_loss: 0.0440\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0248 - val_loss: 0.0440\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0247 - val_loss: 0.0440\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0246 - val_loss: 0.0438\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0246 - val_loss: 0.0439\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0246 - val_loss: 0.0437\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0245 - val_loss: 0.0437\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0244 - val_loss: 0.0436\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0244 - val_loss: 0.0436\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0244 - val_loss: 0.0435\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0243 - val_loss: 0.0435\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0242 - val_loss: 0.0434\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0242 - val_loss: 0.0433\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0241 - val_loss: 0.0433\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0242 - val_loss: 0.0432\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0241 - val_loss: 0.0431\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0240 - val_loss: 0.0431\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0240 - val_loss: 0.0431\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0239 - val_loss: 0.0431\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0239 - val_loss: 0.0431\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0238 - val_loss: 0.0429\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0238 - val_loss: 0.0429\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0237 - val_loss: 0.0429\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0237 - val_loss: 0.0428\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0236 - val_loss: 0.0428\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0236 - val_loss: 0.0426\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0236 - val_loss: 0.0427\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0235 - val_loss: 0.0426\n"
     ]
    }
   ],
   "source": [
    "## train\n",
    "hist = model.fit(x=X_train,y=Y_train,batch_size=512, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc233623",
   "metadata": {},
   "source": [
    "## Visualize results and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20a5871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec178190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0d44a93280>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = hist.history\n",
    "\n",
    "plt.plot(h['loss'], label=\"Training Loss\")\n",
    "plt.plot(h['val_loss'], label=\"Validation Loss\")\n",
    "plt.xlabel(\"No of epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a703134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index: 999 minimum training loss is:  0.023500656709074974\n",
      "At index: 997 minimum validation accuracy is:  0.042637765407562256\n"
     ]
    }
   ],
   "source": [
    "train_idx = np.argmin(h['loss'])\n",
    "print(\"At index:\", train_idx, \"minimum training loss is: \",  h['loss'][train_idx])\n",
    "\n",
    "val_idx = np.argmin(h['val_loss'])\n",
    "print(\"At index:\", val_idx, \"minimum validation accuracy is: \", h['val_loss'][val_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148879a6",
   "metadata": {},
   "source": [
    "## Do data cleaning and Data Normalization on test data same as we did on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e58135c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9758</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnWw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>79.0</td>\n",
       "      <td>8910</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1101          30       RL         60.0     8400   Pave   NaN      Reg   \n",
       "1  1102          20       RL         61.0     9758   Pave   NaN      IR1   \n",
       "2  1103          20       RL         70.0     7000   Pave   NaN      Reg   \n",
       "3  1104          20       RL         79.0     8910   Pave   NaN      Reg   \n",
       "4  1105         160       RM         24.0     2016   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Bnk    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnWw         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      1    2009        WD         Normal  \n",
       "1       0      7    2007        WD         Normal  \n",
       "2       0      4    2007        WD         Family  \n",
       "3       0      7    2006        WD         Normal  \n",
       "4       0      4    2007        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"./Test/Test_Data.csv\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23ed0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## store ids for submission format(we need this column in submission file)\n",
    "ids = X_test['Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "178a8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop useless columns\n",
    "X_test = X_test.drop(labels=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis=1)\n",
    "X_test = X_test.drop(labels=useless, axis=1)\n",
    "\n",
    "## convert strings to numeric data\n",
    "le = LabelEncoder()\n",
    "for i in X_test.columns:\n",
    "    if type(X_test[i].values[0])==str:  # check if 1st value of this column is string\n",
    "        X_test[i] = le.fit_transform(X_test[i].astype('str'))\n",
    "        X_test[i] = X_test[i].fillna(X_test[i].mode())\n",
    "    else:\n",
    "        X_test[i] = X_test[i].fillna(X_test[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d3cf9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 43)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert to common dtype. i.e-float32\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "# data normalization\n",
    "X_test = (X_test - X_test.mean(axis=0)) / X_test.std(axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cde20ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>...</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.632028</td>\n",
       "      <td>-0.457582</td>\n",
       "      <td>-0.322361</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>0.593589</td>\n",
       "      <td>1.024518</td>\n",
       "      <td>-0.520334</td>\n",
       "      <td>-2.948923</td>\n",
       "      <td>-0.537830</td>\n",
       "      <td>-1.605652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972153</td>\n",
       "      <td>1.277763</td>\n",
       "      <td>-1.985910</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>-1.008265</td>\n",
       "      <td>-1.010717</td>\n",
       "      <td>-0.685776</td>\n",
       "      <td>-0.709366</td>\n",
       "      <td>-1.967739</td>\n",
       "      <td>0.913148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.877079</td>\n",
       "      <td>-0.417393</td>\n",
       "      <td>-0.097021</td>\n",
       "      <td>-1.406616</td>\n",
       "      <td>0.593589</td>\n",
       "      <td>-0.003809</td>\n",
       "      <td>-0.520334</td>\n",
       "      <td>-0.767528</td>\n",
       "      <td>-0.537830</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972153</td>\n",
       "      <td>1.277763</td>\n",
       "      <td>0.126187</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>-1.008265</td>\n",
       "      <td>-0.859902</td>\n",
       "      <td>-0.685776</td>\n",
       "      <td>-0.709366</td>\n",
       "      <td>0.187594</td>\n",
       "      <td>-0.587907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.877079</td>\n",
       "      <td>-0.055689</td>\n",
       "      <td>-0.554671</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>0.593589</td>\n",
       "      <td>-0.003809</td>\n",
       "      <td>-0.520334</td>\n",
       "      <td>-0.767528</td>\n",
       "      <td>1.246673</td>\n",
       "      <td>-0.320632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972153</td>\n",
       "      <td>-0.794285</td>\n",
       "      <td>-0.743500</td>\n",
       "      <td>-0.323536</td>\n",
       "      <td>-1.008265</td>\n",
       "      <td>-0.975231</td>\n",
       "      <td>-0.685776</td>\n",
       "      <td>-0.470380</td>\n",
       "      <td>-0.890072</td>\n",
       "      <td>-0.587907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.877079</td>\n",
       "      <td>0.306015</td>\n",
       "      <td>-0.237734</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>-1.935312</td>\n",
       "      <td>-0.003809</td>\n",
       "      <td>-0.520334</td>\n",
       "      <td>-0.040396</td>\n",
       "      <td>0.354422</td>\n",
       "      <td>-0.352757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576409</td>\n",
       "      <td>0.241739</td>\n",
       "      <td>-0.991982</td>\n",
       "      <td>-1.454343</td>\n",
       "      <td>0.288076</td>\n",
       "      <td>0.288950</td>\n",
       "      <td>-0.685776</td>\n",
       "      <td>-0.709366</td>\n",
       "      <td>0.187594</td>\n",
       "      <td>-1.338435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.553638</td>\n",
       "      <td>-1.904397</td>\n",
       "      <td>-1.381694</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>0.593589</td>\n",
       "      <td>-1.717687</td>\n",
       "      <td>0.970277</td>\n",
       "      <td>-0.767528</td>\n",
       "      <td>-0.537830</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972153</td>\n",
       "      <td>1.277763</td>\n",
       "      <td>-0.329363</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.288076</td>\n",
       "      <td>-0.150186</td>\n",
       "      <td>-0.685776</td>\n",
       "      <td>-0.709366</td>\n",
       "      <td>-0.890072</td>\n",
       "      <td>-0.587907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  LotShape  LotConfig  Neighborhood  \\\n",
       "0   -0.632028    -0.457582 -0.322361  0.733025   0.593589      1.024518   \n",
       "1   -0.877079    -0.417393 -0.097021 -1.406616   0.593589     -0.003809   \n",
       "2   -0.877079    -0.055689 -0.554671  0.733025   0.593589     -0.003809   \n",
       "3   -0.877079     0.306015 -0.237734  0.733025  -1.935312     -0.003809   \n",
       "4    2.553638    -1.904397 -1.381694  0.733025   0.593589     -1.717687   \n",
       "\n",
       "   HouseStyle  OverallQual  OverallCond  YearBuilt  ...  Fireplaces  \\\n",
       "0   -0.520334    -2.948923    -0.537830  -1.605652  ...   -0.972153   \n",
       "1   -0.520334    -0.767528    -0.537830   0.032749  ...   -0.972153   \n",
       "2   -0.520334    -0.767528     1.246673  -0.320632  ...   -0.972153   \n",
       "3   -0.520334    -0.040396     0.354422  -0.352757  ...    0.576409   \n",
       "4    0.970277    -0.767528    -0.537830   0.000624  ...   -0.972153   \n",
       "\n",
       "   GarageType  GarageYrBlt  GarageFinish  GarageCars  GarageArea  WoodDeckSF  \\\n",
       "0    1.277763    -1.985910      0.807271   -1.008265   -1.010717   -0.685776   \n",
       "1    1.277763     0.126187      0.807271   -1.008265   -0.859902   -0.685776   \n",
       "2   -0.794285    -0.743500     -0.323536   -1.008265   -0.975231   -0.685776   \n",
       "3    0.241739    -0.991982     -1.454343    0.288076    0.288950   -0.685776   \n",
       "4    1.277763    -0.329363      0.807271    0.288076   -0.150186   -0.685776   \n",
       "\n",
       "   OpenPorchSF    MoSold    YrSold  \n",
       "0    -0.709366 -1.967739  0.913148  \n",
       "1    -0.709366  0.187594 -0.587907  \n",
       "2    -0.470380 -0.890072 -0.587907  \n",
       "3    -0.709366  0.187594 -1.338435  \n",
       "4    -0.709366 -0.890072 -0.587907  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see how X_test looks like \n",
    "pd.DataFrame(X_test, columns=df.columns[:-1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "369c1ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90965.445],\n",
       "       [103831.84 ],\n",
       "       [123157.81 ],\n",
       "       [156175.88 ],\n",
       "       [125405.57 ],\n",
       "       [310570.44 ],\n",
       "       [229797.31 ],\n",
       "       [238716.12 ],\n",
       "       [186931.78 ],\n",
       "       [320964.12 ],\n",
       "       [162786.08 ],\n",
       "       [204454.88 ],\n",
       "       [141177.66 ],\n",
       "       [143726.   ],\n",
       "       [111807.125],\n",
       "       [280759.16 ],\n",
       "       [191678.69 ],\n",
       "       [150025.98 ],\n",
       "       [ 89763.33 ],\n",
       "       [111154.27 ],\n",
       "       [128444.4  ],\n",
       "       [218622.1  ],\n",
       "       [ 95832.54 ],\n",
       "       [101667.95 ],\n",
       "       [174206.6  ],\n",
       "       [ 82724.07 ],\n",
       "       [201696.48 ],\n",
       "       [316811.12 ],\n",
       "       [196757.62 ],\n",
       "       [128012.234],\n",
       "       [ 88533.37 ],\n",
       "       [ 83302.45 ],\n",
       "       [133644.44 ],\n",
       "       [245287.61 ],\n",
       "       [155708.25 ],\n",
       "       [103936.04 ],\n",
       "       [112916.03 ],\n",
       "       [119686.445],\n",
       "       [258936.34 ],\n",
       "       [143679.31 ],\n",
       "       [152599.69 ],\n",
       "       [197505.28 ],\n",
       "       [332865.   ],\n",
       "       [ 86198.26 ],\n",
       "       [ 57650.   ],\n",
       "       [160828.55 ],\n",
       "       [165105.11 ],\n",
       "       [146756.45 ],\n",
       "       [ 97514.38 ],\n",
       "       [153981.02 ],\n",
       "       [ 90917.91 ],\n",
       "       [191445.4  ],\n",
       "       [208087.77 ],\n",
       "       [114943.07 ],\n",
       "       [175691.75 ],\n",
       "       [225921.55 ],\n",
       "       [182875.94 ],\n",
       "       [210233.22 ],\n",
       "       [248493.25 ],\n",
       "       [187698.61 ],\n",
       "       [155874.97 ],\n",
       "       [159135.84 ],\n",
       "       [127555.43 ],\n",
       "       [185740.2  ],\n",
       "       [230571.95 ],\n",
       "       [210642.   ],\n",
       "       [261832.38 ],\n",
       "       [204494.86 ],\n",
       "       [217311.34 ],\n",
       "       [485770.8  ],\n",
       "       [145111.94 ],\n",
       "       [156533.28 ],\n",
       "       [176797.4  ],\n",
       "       [187382.53 ],\n",
       "       [222331.81 ],\n",
       "       [280034.94 ],\n",
       "       [122635.6  ],\n",
       "       [150069.03 ],\n",
       "       [143069.97 ],\n",
       "       [103007.8  ],\n",
       "       [278175.7  ],\n",
       "       [275831.16 ],\n",
       "       [539862.8  ],\n",
       "       [115347.37 ],\n",
       "       [179908.16 ],\n",
       "       [175020.72 ],\n",
       "       [ 84703.77 ],\n",
       "       [266089.53 ],\n",
       "       [186491.28 ],\n",
       "       [188699.14 ],\n",
       "       [208817.97 ],\n",
       "       [168995.92 ],\n",
       "       [128716.305],\n",
       "       [179442.03 ],\n",
       "       [124103.71 ],\n",
       "       [164391.4  ],\n",
       "       [225581.47 ],\n",
       "       [126375.63 ],\n",
       "       [169346.81 ],\n",
       "       [146152.08 ],\n",
       "       [ 94016.305],\n",
       "       [183684.66 ],\n",
       "       [138642.45 ],\n",
       "       [198483.05 ],\n",
       "       [154754.05 ],\n",
       "       [264973.84 ],\n",
       "       [112006.96 ],\n",
       "       [196106.86 ],\n",
       "       [132659.4  ],\n",
       "       [281913.75 ],\n",
       "       [210311.06 ],\n",
       "       [216802.72 ],\n",
       "       [ 97918.32 ],\n",
       "       [176556.47 ],\n",
       "       [126084.8  ],\n",
       "       [103021.46 ],\n",
       "       [130464.99 ],\n",
       "       [205617.84 ],\n",
       "       [ 96915.57 ],\n",
       "       [106677.46 ],\n",
       "       [107523.79 ],\n",
       "       [106963.13 ],\n",
       "       [122885.6  ],\n",
       "       [162025.86 ],\n",
       "       [216969.6  ],\n",
       "       [125652.055],\n",
       "       [233650.53 ],\n",
       "       [126291.49 ],\n",
       "       [317847.9  ],\n",
       "       [133643.6  ],\n",
       "       [228360.94 ],\n",
       "       [159645.1  ],\n",
       "       [ 81903.62 ],\n",
       "       [119782.945],\n",
       "       [ 86121.68 ],\n",
       "       [151625.06 ],\n",
       "       [179777.33 ],\n",
       "       [219463.6  ],\n",
       "       [122478.99 ],\n",
       "       [238836.11 ],\n",
       "       [198253.56 ],\n",
       "       [242067.4  ],\n",
       "       [156449.16 ],\n",
       "       [415767.28 ],\n",
       "       [141858.03 ],\n",
       "       [215996.6  ],\n",
       "       [196631.25 ],\n",
       "       [123728.62 ],\n",
       "       [136321.12 ],\n",
       "       [143265.16 ],\n",
       "       [253630.66 ],\n",
       "       [201018.84 ],\n",
       "       [129170.914],\n",
       "       [228206.72 ],\n",
       "       [184918.9  ],\n",
       "       [137662.1  ],\n",
       "       [305528.6  ],\n",
       "       [ 95576.39 ],\n",
       "       [207392.56 ],\n",
       "       [166777.39 ],\n",
       "       [181029.88 ],\n",
       "       [115059.82 ],\n",
       "       [139104.55 ],\n",
       "       [149123.86 ],\n",
       "       [155549.9  ],\n",
       "       [180405.38 ],\n",
       "       [ 95140.74 ],\n",
       "       [339985.56 ],\n",
       "       [359871.12 ],\n",
       "       [124330.945],\n",
       "       [223847.64 ],\n",
       "       [167722.62 ],\n",
       "       [144212.67 ],\n",
       "       [181179.69 ],\n",
       "       [134347.5  ],\n",
       "       [103403.64 ],\n",
       "       [114816.81 ],\n",
       "       [186389.03 ],\n",
       "       [252451.05 ],\n",
       "       [ 84707.086],\n",
       "       [203598.03 ],\n",
       "       [221136.22 ],\n",
       "       [ 97675.445],\n",
       "       [116342.62 ],\n",
       "       [176597.94 ],\n",
       "       [139636.98 ],\n",
       "       [146546.69 ],\n",
       "       [160039.78 ],\n",
       "       [249165.62 ],\n",
       "       [281699.97 ],\n",
       "       [166966.16 ],\n",
       "       [139412.5  ],\n",
       "       [167702.69 ],\n",
       "       [183210.47 ],\n",
       "       [116471.87 ],\n",
       "       [171479.25 ],\n",
       "       [159043.64 ],\n",
       "       [179929.28 ],\n",
       "       [887414.   ],\n",
       "       [151357.02 ],\n",
       "       [222126.16 ],\n",
       "       [145697.17 ],\n",
       "       [302995.44 ],\n",
       "       [227616.6  ],\n",
       "       [157582.28 ],\n",
       "       [346827.66 ],\n",
       "       [184919.08 ],\n",
       "       [137006.31 ],\n",
       "       [143455.56 ],\n",
       "       [169884.6  ],\n",
       "       [255386.1  ],\n",
       "       [192386.06 ],\n",
       "       [305968.44 ],\n",
       "       [326596.94 ],\n",
       "       [123195.586],\n",
       "       [206417.33 ],\n",
       "       [277042.25 ],\n",
       "       [228597.69 ],\n",
       "       [264395.7  ],\n",
       "       [119153.99 ],\n",
       "       [152360.81 ],\n",
       "       [115626.945],\n",
       "       [199807.44 ],\n",
       "       [ 64170.32 ],\n",
       "       [276831.8  ],\n",
       "       [ 89689.72 ],\n",
       "       [109967.76 ],\n",
       "       [136381.6  ],\n",
       "       [176283.55 ],\n",
       "       [178118.62 ],\n",
       "       [238054.67 ],\n",
       "       [ 94449.445],\n",
       "       [138856.17 ],\n",
       "       [116133.4  ],\n",
       "       [105147.445],\n",
       "       [137214.88 ],\n",
       "       [ 97697.14 ],\n",
       "       [ 84348.6  ],\n",
       "       [204691.97 ],\n",
       "       [132622.97 ],\n",
       "       [101940.04 ],\n",
       "       [147434.84 ],\n",
       "       [253557.4  ],\n",
       "       [173560.23 ],\n",
       "       [194014.14 ],\n",
       "       [ 70691.39 ],\n",
       "       [242259.48 ],\n",
       "       [302999.56 ],\n",
       "       [259281.78 ],\n",
       "       [129350.69 ],\n",
       "       [247896.33 ],\n",
       "       [166602.12 ],\n",
       "       [103043.086],\n",
       "       [336579.84 ],\n",
       "       [252434.33 ],\n",
       "       [201236.22 ],\n",
       "       [115255.33 ],\n",
       "       [168703.78 ],\n",
       "       [153158.86 ],\n",
       "       [366315.44 ],\n",
       "       [211193.   ],\n",
       "       [306549.75 ],\n",
       "       [136545.6  ],\n",
       "       [159555.06 ],\n",
       "       [184808.73 ],\n",
       "       [211962.25 ],\n",
       "       [199281.17 ],\n",
       "       [158368.5  ],\n",
       "       [157732.31 ],\n",
       "       [255566.02 ],\n",
       "       [ 68492.44 ],\n",
       "       [172978.75 ],\n",
       "       [228445.62 ],\n",
       "       [436521.78 ],\n",
       "       [267144.7  ],\n",
       "       [249294.78 ],\n",
       "       [ 75718.664],\n",
       "       [ 93022.31 ],\n",
       "       [102807.38 ],\n",
       "       [139415.38 ],\n",
       "       [ 85270.01 ],\n",
       "       [247368.58 ],\n",
       "       [132028.81 ],\n",
       "       [131881.62 ],\n",
       "       [ 97000.02 ],\n",
       "       [130399.26 ],\n",
       "       [323667.75 ],\n",
       "       [216559.23 ],\n",
       "       [343793.03 ],\n",
       "       [111052.305],\n",
       "       [231486.34 ],\n",
       "       [120388.445],\n",
       "       [146585.06 ],\n",
       "       [133452.88 ],\n",
       "       [246296.05 ],\n",
       "       [282620.   ],\n",
       "       [163594.45 ],\n",
       "       [175584.02 ],\n",
       "       [ 89083.37 ],\n",
       "       [144414.31 ],\n",
       "       [159191.62 ],\n",
       "       [194284.84 ],\n",
       "       [176506.42 ],\n",
       "       [268224.06 ],\n",
       "       [ 87022.6  ],\n",
       "       [256193.1  ],\n",
       "       [115779.19 ],\n",
       "       [120492.77 ],\n",
       "       [108063.625],\n",
       "       [201059.06 ],\n",
       "       [190600.97 ],\n",
       "       [170327.77 ],\n",
       "       [ 79417.97 ],\n",
       "       [281189.6  ],\n",
       "       [213951.   ],\n",
       "       [218736.03 ],\n",
       "       [150957.98 ],\n",
       "       [317407.25 ],\n",
       "       [112465.92 ],\n",
       "       [173392.19 ],\n",
       "       [183366.67 ],\n",
       "       [100252.18 ],\n",
       "       [164341.53 ],\n",
       "       [167499.88 ],\n",
       "       [135601.47 ],\n",
       "       [ 64575.734],\n",
       "       [256416.56 ],\n",
       "       [134715.78 ],\n",
       "       [123237.34 ],\n",
       "       [159757.62 ],\n",
       "       [157476.42 ],\n",
       "       [ 89399.81 ],\n",
       "       [131911.6  ],\n",
       "       [177254.33 ],\n",
       "       [186324.25 ],\n",
       "       [163174.6  ],\n",
       "       [126142.13 ],\n",
       "       [338846.38 ],\n",
       "       [155734.53 ],\n",
       "       [191889.56 ],\n",
       "       [160077.97 ],\n",
       "       [165058.12 ],\n",
       "       [364376.3  ],\n",
       "       [111740.89 ],\n",
       "       [173675.34 ],\n",
       "       [ 81064.79 ],\n",
       "       [148469.03 ],\n",
       "       [243799.81 ],\n",
       "       [108283.02 ],\n",
       "       [ 92771.48 ],\n",
       "       [142181.17 ],\n",
       "       [248099.55 ],\n",
       "       [166625.16 ],\n",
       "       [ 91002.85 ],\n",
       "       [182594.3  ],\n",
       "       [179908.3  ],\n",
       "       [219857.33 ],\n",
       "       [220626.6  ],\n",
       "       [129323.68 ],\n",
       "       [141514.2  ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4485a163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360,), (360, 1))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c3a1a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>90965.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>103831.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>123157.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>156175.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>125405.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1456</td>\n",
       "      <td>179908.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1457</td>\n",
       "      <td>219857.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1458</td>\n",
       "      <td>220626.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1459</td>\n",
       "      <td>129323.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1460</td>\n",
       "      <td>141514.203125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id      SalePrice\n",
       "0    1101   90965.445312\n",
       "1    1102  103831.843750\n",
       "2    1103  123157.812500\n",
       "3    1104  156175.875000\n",
       "4    1105  125405.570312\n",
       "..    ...            ...\n",
       "355  1456  179908.296875\n",
       "356  1457  219857.328125\n",
       "357  1458  220626.593750\n",
       "358  1459  129323.679688\n",
       "359  1460  141514.203125\n",
       "\n",
       "[360 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(y_pred)\n",
    "ids = pd.DataFrame(ids, columns=['Id'])\n",
    "df3 = pd.DataFrame({\"Id\":ids.values[:,0], \"SalePrice\":df2.values[:,0]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec845710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('Output.csv', index=False)\n",
    "df3.to_csv('/home/harsh/Shared_folder/Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0545af44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[198748.47],\n",
       "       [202260.44],\n",
       "       [212961.75],\n",
       "       ...,\n",
       "       [ 98278.88],\n",
       "       [151234.75],\n",
       "       [168831.17]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df53393b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8447413770505454"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_train)\n",
    "acc = r2_score(Y_train, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fce7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2278aac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 170000, 128000, 157000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2c6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12099994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
